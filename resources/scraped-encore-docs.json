[
  {
    "url": "https://encore.dev/docs",
    "text": "Quickstart Guide\nWrite your first microservice with Encore and deploy it to the cloud.\nWhy Encore?\nLearn about what problems Encore solves and the philosophy behind it.\nWatch a demo video\nSee how to build a fully-fledged cloud backend with Encore, in 5 minutes.\nTypeScript SDK\nExplore the TypeScript SDK and learn how to develop with Encore.\nGo SDK\nExplore the Go SDK and learn how to develop with Encore.\nTutorials\nTutorials to learn how to build applications with Encore.\nTemplates\nReady-made starters and bits to inspire your development.\nCloud Deployment\nLearn how Encore automatically provisions infrastructure in your cloud.\nJoin Discord\nFind answers, ask questions, and chat with other Encore developers.\nStar on GitHub\nGet involved and star Encore on GitHub.\nFollow on Twitter\nKeep up with the latest news and updates"
  },
  {
    "url": "https://encore.dev/docs/deploy/custom-domains",
    "text": "By default, all application environments are accessible as subdomains of the shared Encore domain encr.app. When exposing APIs publicly, you often want to provide a URL endpoint branded with your own domain.\nFollow these instructions to serve your backend using your own custom domain name. This also has the benefit of providing a built-in Web Application Firewall (WAF) using Cloudflare WAF.\nAdding a domain\nModify the DNS records for your domain, adding a CNAME record pointing at: custom-domain.encr.app It's recommended to set a TTL (Time-To-Live) of 30 minutes for the CNAME record.\nTake care\nEncore requires that you add a CNAME record for each domain you wish to serve traffic from. CNAME record using wildcards, e.g. *.example.com, are not currently supported.\nOnce you've added the CNAME record, go to the Custom Domains settings page by opening Your apps > (Select your app) > Settings > Custom Domains. Click on Add Domain on the top right of the page.\nEnter the domain name you configured the CNAME on and select which environment you wish to serve on that domain, then click Add.\nEncore will now set up your domain and issue SSL certificates to serve traffic through.\nPlease note\nIf you configure multiple domains against a single environment, Encore will serve traffic through all configured domains. The encr.app subdomain which was created when you originally created an environment will always be configured to serve traffic to that environment.\nThis allows you to migrate to a custom domain safely without risking cutting traffic off to older clients which may be hard coded to access your applications via the default subdomain.\nDomain statuses\nOn the Custom Domains settings page, you can see the various statuses throughout the lifecycle of a custom domain.\nStatusDescription\nPending\tThe domain is currently queued to be provisioned by Encore.\t\nWaiting for CNAME\tEncore is waiting for the CNAME to become active and for the SSL certificate to be issued for the domain.\t\nConfiguring Edge Routers\tThe SSL certificate has been issued and the Encore edge routers are being configured to route traffic on the domain.\t\nActive\tThe domain is serving traffic to your Encore application.\t\nNot Working\tA non-recoverable problem has occurred. This could be a result of the CNAME record being removed or pointed elsewhere. If you see this error, please contact support."
  },
  {
    "url": "https://encore.dev/docs/deploy/own-cloud",
    "text": "Encore lets you deploy your application to any of the major cloud providers, using your own cloud account. This lets you use Encore to improve your experience and productivity, while keeping the reliability of a major cloud provider.\nEach environment can be configured to use a different cloud provider, and you can have as many environments as you wish. This also lets you easily deploy a hybrid or multi-cloud application, as you see fit.\nPlease note\nEncore will provision infrastructure in your cloud account, but for safety reasons Encore does not destroy infrastructure once it's no longer required.\nThis means if you disconnect your app from your cloud provider, or delete the environment within Encore, you need to manually remove the infrastructure that was created by Encore.\nGoogle Cloud Platform (GCP)\nEncore provides a GCP Service Account for each Encore application, letting you grant Encore access to provision all the necessary infrastructure directly in your own GCP Organization account.\nTo find your app's Service Account email and configure GCP deployments, head over to the Connect Cloud page by going to Encore's Cloud Dashboard > (Select your app) > App Settings > Integrations > Connect Cloud.\nAmazon Web Services (AWS)\nTo configure your Encore app to deploy to your AWS account, head over to the Connect Cloud page by going to Encore's Cloud Dashboard > (Select your app) > App Settings > Integrations > Connect Cloud.\nFollow the instructions to create an IAM Role, and then connect the role with Encore. Learn more in the AWS docs.\nLook out!\nFor your security, make sure to check Require external ID and specify the external ID provided in the instructions.\nAfter connecting your app to AWS, you will be asked to choose which region you want Encore to provision resources in. Learn more about AWS regions here."
  },
  {
    "url": "https://encore.dev/docs/deploy/neon",
    "text": "You can configure Encore to provision a Neon Postgres database instead of the default offering for any Cloud.\nNeon is a serverless database provider that offers a fully managed and autoscalable Postgres database. \nConnect your Neon account\nTo start using Neon with Encore, you need to add your Neon API key to your Encore application. You can sign up for a Neon account at neon.tech. Once you have an account, you can find your API key in the Neon Console\nThen, head over to the Neon settings page by going to Encore's Cloud Dashboard > (Select your app) > App Settings > Integrations > Neon.\nClick the \"Connect Account\" button, give it a name, and enter your API key.\nCreate an environment with Neon\nNeon organizes databases in projects. A project consist of a main branch and any number of feature branches. Branches in Neon works the same way as branches in your code. This allows you to create a new branch for each feature or bug fix, and test your changes in isolation.\nWhen configuring your Encore environment to use Neon, you can choose which project and branch to use. To get started, head to Encore's Cloud Dashboard > (Select your app) > Environments > Create Environment. In the Database section, select Neon database.\nCreate a new Neon project and branch\nIf you're starting off a blank slate, you can let Encore create a new Neon project and branch for you. Select New Neon project and choose a Neon account and region. We recommend picking a region close to your compute and that you use the suggested project and branch names, but you're free to choose any configuration you like. \nBranch from an existing Encore environment\nIf you already have an Encore environment with Neon, you can branch your database from that environment. Simply select Branch from Encore environment and choose the environment you want to branch from. This option will be disabled if you don't have any environments using Neon.\nBranch from an existing Neon branch\nYou can also choose to manually select a Neon branch to branch from. This is useful if you have an existing Neon project, but it's not currently being used by any Encore environments. Select Branch from Neon project, then choose the account, project and branch you want to use. \nImport an existing Neon branch\nThe final option is to import an existing Neon branch. This is useful if you have an existing database you want to use. Be wary that this option will not create a new branch but operate on the existing data. Select Import Neon branch, then choose the account, project and branch you want to use. \nEdit your Neon environment\nOnce the environment is created, you can edit the Neon settings by going to Encore's Cloud Dashboard > (Select your app) > Environments > (Select your environment) > Infrastructure. Here you can view and edit your Neon account resources. As a saftety precaution, we've disabled editing of imported resources to prevent accidental changes to shared data.\nNeon project\nThe retention history specifies how long Neon will keep changes to your data. The default is 1 day, but depending on your Neon plan, you can increase this to up to 30 days.\nNeon endpoint\nEach branch is assigned a unique endpoint which essentially is the serverless compute handling your database. You can edit the endpoint to set the CPU limits and the suspend timeout. The suspend timeout is the time Neon will wait before suspending the compute when it's not in use. The default is 5 minutes, but you can increase this to up to a week (depending on your Neon plan).\nUse Neon for PR environments\nNeon is not yet supported for PR environments, but we're working on it."
  },
  {
    "url": "https://encore.dev/docs/deploy/security",
    "text": "The security practices implemented by Encore are informed by our team's decades-long experience working with banking, payments, and other sensitive systems, at companies like Google, Spotify, and Monzo.\nWe have designed Encore to make building secure applications an effortless task, rather than an inconvenience, allowing you to focus on functionality instead of laborious security concerns.\nFor example, Encore's secrets management gives you a simple way of using secret keys, while at the same time providing state of the art security behind the scenes.\nFurthermore, thanks to the API framework and Infrastructure SDK, Encore understands which services require access to specific resources. Encore automatically manages IAM policies based on the principle of least privilege by default. This ensures each service only has the minimum necessary permissions.\nWhen your application is running, all communication to Encore uses mutual TLSv1.3 connections, and all database access is encrypted with certificate validation and strong security credentials.\nFor cloud environments, Encore automatically provisions infrastructure using security best practises for each of the supported cloud providers (GCP, AWS). Learn more in the infrastructure documentation."
  },
  {
    "url": "https://encore.dev/docs/deploy/webhooks",
    "text": "Webhooks provide a way for notifications to be delivered to an HTTP endpoint of your choice whenever certain events happen within Encore. For example, you can set up a webhook to be notified whenever a deployment starts or finishes.\nWebhooks are defined on a per-application basis, and are configured under Settings -> Webhooks in Encore's Cloud Dashboard.\nTo simplify using webhooks, Encore provides a Go module, go.encore.dev/webhooks, that provides type definitions and documentation of all supported webhook events. This module is kept up to date as new events are added.\nWebhook Deliveries\nEach time an event occurs that matches one of your defined webhooks, Encore will send a HTTP POST request to the webhook's configured URL with information about the event.\nIf the HTTP request fails, the delivery is marked as failed and won't be retried.\nEach event is given a unique event id, which is shared across all webhooks.\nWithin each webhook, each event is given a sequence number, which is incremented for each event that matches that webhook. The sequence number allows for a linear ordering of events within a webhook, making it easy to determine if an event was missed.\nThese are provided in the X-Encore-Event-Id and X-Encore-Sequence-Id headers respectively, and are also part of the event payload itself.\nParsing webhook events\nTo parse a webhook event, use the webhooks.ParseEvent function.\nAs you'll see in the example below, to parse the webhook event you'll need access to the webhook secret. This is a secret value that is generated by Encore and is used to sign each webhook request. More about this in the next section.\nFor example, to process rollout started and completed webhook events, you could do something like this:\npackage service import ( \"net/http\" \"go.encore.dev/webhooks\" ) var secrets struct { EncoreWebhookSecret string } //encore:api public raw func Webhook(w http.ResponseWriter, req *http.Request) { payload, err := io.ReadAll(req.Body) if err != nil { // ... handle error } event, err := webhooks.ParseEvent(payload, req.Header.Get(\"X-Encore-Signature\"), secrets.EncoreWebhookSecret) if err != nil { // ... handle error } switch data := event.Data.(type) { case *webhooks.RolloutCreatedEvent: // ... handle rollout created event case *webhooks.RolloutCompletedEvent: // ... handle rollout completed event } } \nPlease note\nNote that the example above is written as an Encore API endpoint, but that's not required. The same code works in any Go HTTP server, and the go.encore.dev/webhooks library does not depend on any Encore-specific functionality.\nChecking webhook signatures\nSince the webhook endpoint is publicly accessible, it is important to validate that the request is coming from Encore. To do so, Encore generates a secret for each webhook, which is used to sign each request.\nThe webhook secret can be found on the webhook details page by admins.\nIf you use the go.encore.dev/webhooks library then signature validation is handled automatically, but it's also possible to verify the signature manually (see below).\nPreventing replay attacks\nA replay attack occurs when an attacker intercepts a valid request, including the payload and signature, and re-transmits it one or more times, causing unintended side effects.\nTo mitigate such attacks, Encore includes a timestamp in the X-Encore-Signature header. This timestamp is part of the the signed payload, which means that it can't be changed by the attacker without invalidating the signature. This makes it possible to mitigate replay attacks by ensuring the timestamp isn't older than a certain threshold (the go.encore.dev/webhooks library defaults to 5 minutes).\nVerifying signatures manually\nThe X-Encore-Signature header included in each webhook event contains a timestamp and one or more schemes. The timestamp is prefixed with t=, and each scheme is prefixed by a v and a version number. Currently only the v1 scheme is supported.\nFor example, a valid signature header might look like this:\nX-Encore-Signature: t=1623345600,v1=0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b \nThe v1 scheme is using a hash-based message authentication code (HMAC) with SHA-256. To prevent downgrade attacks, ignore all schemes that are not v1.\nIt's possible the signature contains multiple signatures, for example if the webhook secret has been rotated recently.\nWhen rotating the webhook secret, Encore lets you define for how long the old secret should continue to be valid for. During that window, each webhook event will be signed with the new and the old secret.\nTo validate the webhook signature, follow the algorithm below:\nStep 1: Extract the timestamp and signatures from the header Split the header on , to get a list of fields, then split each field on = to get the key and value.\nThe value of the t key is the timestamp, and represents the UNIX timestamp (in seconds) when the signature was created. The fields with the v1 key (possibly several, in case of secret rotation) are the signatures.\nDiscard any other fields.\nStep 2: Prepare the payload to sign Create the payload to sign by concatenating the timestamp (as a string) and the request body, separated by . like so:\npayloadToSign := timestamp + \".\" + string(payload) \nStep 3: Compute the expected signature Compute the HMAC with the SHA256 hash function, using the webhook secret as the key and the payloadToSign as the message.\nThen, encode the resulting HMAC using the base64 URL encoding, and trim any trailing = characters. In Go, this can be done like so:\nh := hmac.New(sha256.New, []byte(webhookSecret)) h.Write([]byte(payloadToSign)) digest := h.Sum(nil) expectedSignature := base64.RawURLEncoding.EncodeToString(digest) \nStep 4: Compare the signatures Compare each signature with the v1 field in the header with the expected signature. To protect against timing attacks, use a constant-time comparison function (like crypto/hmac.Equal in Go).\nIf none of the signatures match, reject the request.\nIf a match is found, compare the timestamp with the current time. If the difference is greater than the allowed threshold (5 minutes is a reasonable default), reject the request.\nOtherwise, accept the request."
  },
  {
    "url": "https://encore.dev/docs/deploy/terraform",
    "text": "Encore makes it simple to deploy and manage cloud applications. When you're dealing with a large and complex system, you may want to integrate Encore-provisioned resources with an existing infrastructure landscape. For this purpose, Encore maintains a Terraform Provider with data sources for all Encore-provisioned resources.\nUnderstanding Encore Terraform Data Sources\nEncore Terraform data sources act as read-only references to resources Encore has already provisioned on your behalf. Unlike Terraform resources (which create or modify infrastructure), data sources only retrieve information. The Encore data sources let's you retrieve cloud identifiers for resources managed by Encore, such as databases, caches, and more. To do this, you only need to provide the name of the resource and the environment it's in.\nConfiguring the Encore Terraform Provider\nTo use Encore data sources, you need to declare the Encore Terraform provider in the required_providers of your Terraform configuration file. Here's an example of how to declare the provider:\nterraform { required_providers { encore = { source = \"registry.terraform.io/encoredev/encore\" } } } \nOnce you've declared the provider, Terraform will automatically download the provider plugin when initializing the working directory using terraform init.\nTo authenticate with the Encore API, the provider need an Encore Auth Key. You can generate an auth key from Encore's Cloud Dashboard. Once you have the auth key, you can configure the provider in your Terraform configuration file like this:\nprovider \"encore\" { env = \"your-env\" auth_key = \"your-auth-key\" } \nYou can also set the ENCORE_AUTH_KEY environment variable to avoid hardcoding the auth key in your configuration file.\nUsing Encore Terraform Data Sources\nOnce you have the provider configured, you can use the Encore data sources to retrieve information about resources. There are several data sources available, such as encore_database, encore_cache, and encore_pubsub_topic. Each data source has its own set of attributes that you can use to retrieve information about the resource. The full documentation for each data source is available in the Terraform Registry.\nHere's an example of how to use the encore_pubsub_topic data source to connect AWS IOT Core to an Encore PubSub topic:\ndata \"encore_pubsub_topic\" \"topic\" { name = \"my-topic\" env = \"my-env\" } resource \"aws_iot_topic_rule\" \"rule\" { name = \"my-rule\" sql = \"SELECT * FROM 'my-topic'\" sns { message_format = \"RAW\" role_arn = aws_iam_role.role.arn target_arn = data.encore_pubsub_topic.topic.aws_sns.arn } }"
  },
  {
    "url": "https://encore.dev/docs/community/contribute",
    "text": "We’re so excited that you are interested in contributing to Encore! All contributions are welcome, and there are several valuable ways to contribute.\nOpen Source Project\nIf you want to contribute to the Encore Open Source project, you can submit a pull request on GitHub.\nReport issues\nIf you have run into an issue or think you’ve found a bug, please report it via the issue tracker.\nAdd or update docs\nIf there’s something you think would be helpful to add to the docs or if there’s something that seems out of date, we appreciate your input. You can view the docs and contribute fixes or improvements directly in GitHub.\nYou can also email your feedback to us at hello@encore.dev.\nBlog posts\nIf you’ve built something cool using Encore, we’d really like you to talk about it! We love it when developers share their projects on blogs and on Twitter.\nUse the hashtag #builtwithencore and we’ll have easier time finding your work. – We might also showcase it on the Encore Twitter account!\nMeetups & Workshops\nOrganizing a meetup or workshop is a great way to connect with other developers using Encore. It can also be a great first step in trying out Encore for development in your company or other professional organization.\nIf you want help with organizing or planning an event, please don’t hesitate to reach out to us via email at hello@encore.dev."
  },
  {
    "url": "https://encore.dev/docs/community",
    "text": "Developers building with Encore are forward-thinkers, who are working on exciting and innovative applications.\nWe rely on this group's feedback, and contributions to the Open Source project, to improve Encore for developers everywhere. Getting involved is a fantastic way of finding support and inspiration among peers.\nEveryone is welcome in the Encore community, and we hope you to get involved too!\nGet involved\nThere are many ways to get involved. Here's where you can start straight away.\nContribute on GitHub\nUse GitHub to report bugs, feedback on proposals, or contribute your ideas.\nJoin Discord\nConnect with fellow Encore developers, ask questions, or just hang out!\nFollow on Twitter\nFollow Encore on Twitter to keep up with the latest. Share what you've built to help spread the word about the project.\nContribute to the project\nWant to make a contribution to Encore? Great, start by reading about the different ways to contribute.\nFeedback on the Roadmap\nThe Encore Roadmap is public. It's open to your comments, feature requests, and you can vote on existing entries.\nWe recommend everyone read the Community Principles.\nIf you need assistance, have concerns, or have questions for the Community team, please email us at support@encore.dev."
  },
  {
    "url": "https://encore.dev/docs/community/open-source",
    "text": "We believe Open Source is key to a long-term sustainable and prosperous technology community. Encore builds on Open Source software, and is largely Open Source itself.\nLicense\nThe Encore Infrastructure SDK, parser, and compiler are Open Source under Mozilla Public License 2.0.\nThe MPL is a simple copyleft license. The MPL's \"file-level\" copyleft is designed to encourage contributors to share modifications they make to your code, while still allowing them to combine your code with code under other licenses (open or proprietary) with minimal restrictions.\nYou can learn more about MPL 2.0 on the official website.\nContribute\nContributions to improve Encore are very welcome. Contribute to Encore on GitHub."
  },
  {
    "url": "https://encore.dev/docs/about/compliance",
    "text": "Last updated: 16 May, 2023\nAs an organization or engineer who creates applications, your applications, code, and data are among your most important assets. Encore highly prioritizes the security of these assets, allowing you to concentrate on your goal: designing exceptional applications.\nWe are arranging for an external review of our security measures and thus, we are preparing for a SOC 2 Type 1 audit. This document presents a summary of our self-evaluation of the current implementation of the SOC 2 trust service criteria at Encore.\nSOC 2\nSOC is short for \"System and Organization Controls\" – it is the de facto industry standard for software security and privacy. During the SOC 2 audit, an external auditor will carry out an extensive review of our processes (e.g. employee onboarding and offboarding, access review, various policies, disaster recovery exercises, software architecture, physical access, etc.) and ensure that they meet the mark.\nThe Type 1 audit is a point-in-time audit where the auditor verifies that the controls are satisfied at a specific point in time. We are planning to proceed to Type 2 afterward which is based on continuous monitoring during time periods of varying lengths.\nTrust Service Criteria\nThe five SOC 2 trust service criteria are: security, availability, confidentiality, processing integrity, and privacy.\n1. Security\nProtecting systems against unauthorized access.\n2. Availability\nEnsuring that the system remains functional and usable.\n3. Confidentiality\nRestricting the access of data to a specified set of persons or organizations. Ensuring that network communication is encrypted and cannot be intercepted by unauthorized personnel.\n4. Processing integrity\nEnsuring that a system fulfills its purpose and delivers correct data.\n5. Privacy\nMinimal processing and use of personal data in accordance with the law.\nThe following sections describe in detail how Encore implements each trust service principle.\nSecurity\nEncore believes that the best way to achieve a secure system is to follow best practices and industry standards, and not with obscurity (i.e. attempting to \"secure\" a system only by making it \"difficult to understand\") or homegrown technology (e.g. custom encryption algorithms).\nWe have a designated individual (Security Officer) responsible for all aspects of security, such as infrastructure, software, and data.\nInfrastructure security\nEncore's core production infrastructure is hosted on GCP (Google Cloud Platform), an ISO27001/SOC 2 compliant vendor. Auxiliary services are provided by Hetzner, an ISO27001 compliant vendor. Tailscale, a SOC 2 compliant vendor, provides VPN (Virtual Private Network) services used to secure communication between all servers.\nAll core data processing is carried out in the US East region (us-east-1), and backups are kept in multiple separate regions in the US. Each region is composed of at least three \"availability zones\" (AZs) which are isolated locations, designed to take over in case of a catastrophic failure at one location. AZs are separated by a significant distance such that it is unlikely that they are affected by the same issues such as power outages, earthquakes, etc. Physical access to GCP is restricted by GCP's security controls. Furthermore, GCP monitors and immediately responds to power, temperature, fire, water leaks, etc.\nAccess to Encore's production infrastructure is restricted to Encore employees. All systems have controlled access and only a limited number of employees have privileged access. Access is only possible through a VPN over Tailscale.\nThe production environment is separated from testing environments, using separate accounts and VPCs (Virtual Private Cloud) in GCP. This ensures that any defect in a test environment cannot impact the production system. The connection to the internet is controlled by dedicated gateways.\nOrganizational security\nSince an organization is only as good as its people, Encore takes great care when selecting and training its staff. All employees undergo a thorough selection process that has been designed to identify the best talent in the world for the job. Many of Encore's employees have extensive experience working in regulated environments such as Online Banking and large-scale Online Payments.\nIndividual performance monitoring is carried out by managers on a bi-weekly cadence. Overall organizational performance is tracked continuously and reviewed by management on a monthly cadence using Key Performance Indicators determined by management.\nEmployees are required to complete yearly security awareness training. The training is designed to increase sensitivity to physical security (hardware and media handling, office access control, etc.), digital security (e.g. secure passwords, two-factor authentication), social engineering attacks (\"phishing\"), and other security-related topics.\nEncore employment policy mandates that all hard drives must be encrypted.\nProduct security\nEncore is aware of how important it is to its customers that all data is handled securely. Therefore, several layers of protection ensure that the data is not accessible to unauthorized persons.\nAn essential part of software security is \"defense in depth\" which means that there are multiple layers of protection. In case one layer is breached, the next layer helps to contain the breach and mitigate its consequences. This can be achieved by isolating software components from each other, such that the breach of one component does not affect adjacent software.\nEncore's service-based architecture provides natural isolation between components, and we have adopted a zero-trust security model with the use of Tailscale. All server-to-server communication is authenticated and end-to-end encrypted with WireGuard. GCP's VPC (Virtual Private Cloud) provides another layer of isolation from the internet on the network level. None of Encore's servers are publicly accessible on the internet.\nAs a general principle, all of Encore's data is encrypted while being transported across networks and when stored (\"in transit and at rest\"). In case of unauthorized access to the data, an attacker would only see undecipherable garbage which cannot be decrypted without the corresponding keys. The encryption methods employed by Encore are industry standard and deemed unbreakable by contemporary standards. Data at rest (virtual filesystems, relational databases, and object storage) is encrypted using GCP's industry-standard AES-256, while data in transit is encrypted with TLS ≥ 1.2 (for Encore's REST API) or WireGuard (for internal communication).\nAll customer secret information is further encrypted using GCP's Key Management Service (KMS). Any access to encrypted data by Encore employees requires elevated access and approval by multiple parties, and all such activity is audited.\nUser account authentication is provided by Auth0, a SOC 2 compliant vendor.\nThere are two ways for a user to log in to Encore: Single sign-on (SSO) and username plus password. Single sign-on can be used by organizations to fully manage access to Encore and, for example, ensure that former employees no longer have access after the offboarding period. Encore supports Google and GitHub SSO using OAuth.\nIf no SSO is used, the default login method is username and password, also handled by Auth0. Encore does not store or in any way handle passwords, neither in plaintext nor cryptographic hash form. This means that Encore does not know the passwords of any users, and no passwords can be reconstructed from our databases.\nEncore offers bug bounty incentives to individuals who discover any security discrepancies. The objective of offering bug bounty incentives is to receive security-related bug reports from trusted \"white hat hackers\" before the vulnerability is actively exploited in a malicious way. This contributes to maintaining Encore's product security.\nAll security issues undergo a triaging process by Encore's designated Security Officer and are escalated based on their criticality.\nEncore uses automated scans to detect software vulnerabilities. All teams are continuously monitoring their services for vulnerabilities and are committed to pro-actively reducing them. The progress is supervised by the Security Officer.\nAccess control\nWe regularly keep track of and review the list of employees who have access to which systems and remove access where applicable to ensure least access principles apply.\nOffboarding processes ensure that former employees cannot access internal systems anymore after the termination of their contract. Thanks to the VPN, Encore can centrally restrict access to internal networks.\nMFA\nMulti-factor authentication (MFA) adds another layer of security on top of classic password authentication. In addition to username and password, the user requires another individual token of access.\nStealing or guessing the password is not enough for an attacker to gain access to a system, because the second factor would also need to be stolen.\nUsually, the second factor is a physical device, such as a mobile phone which has been paired with the authentication system. Encore employs MFA to protect access to the infrastructure provider (GCP) and the version control systems (GitHub), among other systems.\nAvailability\nHosted on a cloud infrastructure, Encore implements a service-based architecture where many dedicated software components operate isolated from one another, but in a coordinated way, much like a complex machine where individual parts can be replaced independently from one another.\nDuring the release of a new version of Encore services, Encore's engineers take great care during the preparation of the update so that in case of an unexpected problem, the system can be restored to the previous state in a manner that minimizes user impact.\nPerformance monitoring\nEncore uses a number of performance monitoring systems, such as Sentry, Cronitor, Grafana, and Google Cloud Monitoring. Grafana, a SOC 2 compliant vendor, is used to monitor application performance, such as server response times and user interface speed. Grafana also collects server-side metrics like CPU and RAM usage. Additionally, Encore monitors the performance of databases with GCP tooling.\nSlack, a SOC 2 compliant vendor, is used as the alerting channel to notify the developers in case the performance of the system has regressed, for example, due to increased response times, or increased error rates. To enable the root cause analysis of bugs, Encore collects system logs from all parts of the system. These logs can only be accessed by authorized users.\nEncore is planning to offer a public status page as part of the SOC 2 certification\nprocess.\nBackups and disaster recovery\nTo reduce the risk of simultaneous failure, Encore backs up data to multiple US regions in GCP, with very limited access. Relational databases are backed up on a daily schedule.\nEncore is currently planning a rehearsal of disaster recovery in Q4 of 2023. In this exercise, a clone of the production environment will be recovered from scratch using backups and tested for soundness.\nIncident handling\nWhenever an incident occurs, Encore's designated on-call engineer initiates an investigation and escalates to the broader engineering team as necessary based on severity. For issues deemed critical, they follow an iterative response process to identify and contain errors, recover systems and services, and remediate vulnerabilities.\nCustomers and users can report outages via regular support channels (for example via email, or using the Discord chat group). Encore's internal communication systems have dedicated channels for incident escalation.\nConfidentiality\nWhen you use Encore, other users won't be able to see your content, unless you grant access explicitly by inviting them to your application. Encore engineers may use your data to provide support and when necessary to fix bugs.\nAccess controls\nAll employees and contractors are contractually bound to confidentiality, which persists after the termination of the work contract.\nAs part of a \"clean screen\" policy, all computers used by Encore staff must be set to automatically lock the screen after 1 minute of inactivity.\nAll systems access is subject to the \"principle of least privilege\", meaning that every employee only has access to the systems necessary to perform their official duties.\nDeletion\nUser data will be stored by Encore after the termination of a subscription term, according to Encore's Terms of Service. When a user requests the deletion of data, the data is made inaccessible or physically deleted, depending on the data type and storage location. For technical reasons, data may remain in backups after this point.\nProcessing integrity\nQuality assurance\nProduct quality is very important to Encore. There are many different facets, including:\nAccuracy and usability of services provided\nHigh performance of the user interface and Encore services\nAlmost zero downtime\nSeveral measures are put into place in order to keep product quality high:\nCode review: Every single code change is reviewed by a peer of the developer before it is accepted into the main code branch (for critical systems) or in a weekly post-hoc review process (for auxiliary systems). For critical systems code can only be merged if the reviewer agrees. For auxiliary systems any requested changes by reviewers are made as part of the review process. It is often necessary to add a test alongside, and the code review process ensures that this has been done as well.\nContinuous integration: Before code is accepted, it is built by our continuous integration environment and tests are executed. If the build fails, the developer is notified immediately and a fix is required before the code can be merged.\nManual testing: Once the code has been merged, the change is deployed and in most cases tested manually post-release to verify quality in the production environment.\nAutomated integration testing: A large battery of automated tests is executed against the local and production environments and checks many common workflows for regressions of any kind. In case the tests fail, the engineer will address the issues before proceeding with attempting to merge again.\nTesting of Open-Source libraries: Encore uses Open-Source libraries to provide certain functionality. Overnight tests run daily to discover potential issues, and manual testing is performed when any Open-Source libraries are version updated.\nAny code change is released only if all these steps succeed. Furthermore, access to the code base is protected via multi-factor authentication (MFA), which poses another layer of defense against the malicious injection of code.\nSince Encore depends on third-party software, we regularly contribute to the quality assurance of our suppliers. Whenever Encore becomes aware of regressions or bugs, they are reported upstream. In this way, Encore is contributing to the quality, stability, and accuracy of other software in the space.\nProcess monitoring\nWhere possible, Encore uses software to enforce processes. For example, code review and having tests passed are enforced by the source control management tool GitHub.\nRegular reviews on different levels (individual, team, company) foster alignment between all individuals and the company objectives.\nPrivacy\nEncore takes data privacy very seriously and complies with the rules of the European Union's GDPR (General Data Protection Regulation). GDPR grants a wide range of rights to Encore's users, such as the right to be informed, the right to access, the right to rectification, the right to erasure, and others.\nOne fundamental rule of the GDPR is the principle of \"data minimization\", which ensures that we are not processing more personal data than necessary. As a result, the Encore platform uses only minimal personal data for user authentication and essential communication (which is a name, contact email, and a password hash).\nPrivacy policy\nWe are aware that confidential handling of your data is essential to establishing trust. Therefore, Encore's Privacy Policy ensures that the data of our users is protected according to the high standards of GDPR.\nQuestions and clarifications\nIf you have any questions regarding Encore's security or compliance strategy, please feel free to contact us via email (hello@encore.dev)."
  },
  {
    "url": "https://encore.dev/docs/community/principles",
    "text": "Everyone is welcome in the Encore community, and it is of utmost importance to us that everyone is able to feel at home and contribute.\nTherefore we as maintainers, and you as a contributor, must pledge to make participation in our community a harassment-free experience for everyone, regardless of: age, body size, disability, ethnicity, gender identity, level of experience, nationality, personal appearance, race, religion, or sexual identity.\nCode of Conduct\nTo this end, the Encore community is guided by the Contributor Covenant 2.0 Code of Conduct to ensure everyone is welcome and able to participate."
  },
  {
    "url": "https://encore.dev/docs/about/billing",
    "text": "Encore offers a Free plan for teams that want a simple development workflow and collaboration features. If you want access to all features and want to use Encore's DevOps automation tools for AWS & GCP, there's a paid Pro plan available at $39 per member / month.\nSee the pricing page for a feature comparison between each plan and more information.\nWhen do I need to upgrade to a paid plan?\nThe Free plan comes with certain limitations, and should your needs exceed one or more of them, you may wish to upgrade to a paid plan:\nWhen you need more than 2 cloud environments\nWhen you want to automate DevOps in your cloud on AWS/GCP\nWhen you want Preview Environments for each Pull Request\nWhen you want to use a Custom Domain\nWhen you need multiple concurrent builds\nWhen you need guaranteed logs & tracing retention\nWhen you want access to private support & onboarding assistance\nWhen you want custom configuration for environments hosted on Encore Cloud\nThere is a free 14-day trial of the Pro plan, available to all new Encore users. It's a great way to try out all the features and learn if the Pro plan suits your needs. You can activate your trial from the pricing page.\nDo I need to pay for hosting?\nAll plans come with free use of Encore Cloud, subject to Fair Use limits. Encore Cloud is intended for development environments and limited scale professional use that does not require specific SLAs.\nFor production use, you can connect your own cloud account on AWS/GCP and use Encore to deploy there, including provisioning infrastructure and managing IAM. When you connect your own cloud account, you pay for usage directly to your cloud provider.\nIf you prefer to manage deployment yourself, you can export your application as a standalone Docker image and deploy in any way you prefer. (Learn more)\nPayments & Billing FAQ\nWhat is the price of the paid plan?\nThe Pro plan is $39/month per member. If you use Encore for DevOps automation in your cloud, the price is $99/month per environment on AWS/GCP + $1.7/month per resource in each AWS/GCP environment. Resources are your app's services, databases, Pub/Sub topics and subscriptions, cron jobs, caches, and secrets, in each environment.\n(Learn more)\nSee the pricing page for more details.\nIf you are a large organization with specific needs, please email us or book a 1:1 to discuss your needs and get a custom price quote.\nCan I pay with a credit card?\nYes, we offer payments via Stripe using all major credit cards. You can upgrade your account via the pricing page.\nWhat happens if my payment fails?\nIf your payment fails, everything will keep working as normal! We will reach out to you with instructions on how to update your payment information so that we can try to process your payment again. We will not downgrade your account without prior notice."
  },
  {
    "url": "https://encore.dev/docs/about/permissions",
    "text": "Encore applications have three membership roles with different permissions: Admins, Members, and Viewers. Here is a breakdown of the key differences between each role:\nAdminsMembersViewers\nManage team members\tY\tN\tN\t\nConnect/Disconnect cloud accounts\tY\tN\tN\t\nIntegrate with GitHub\tY\tN\tN\t\nConfigure custom domains\tY\tN\tN\t\nManage environments\tY\tN\tN\t\nCreate auth keys\tY\tN\tN\t\nApprove infrastructure provisioning\tY\tN\tN\t\nDelete applications\tY\tN\tN\t\nPush code changes\tY\tY\tN\t\nCreate builds & deployments\tY\tY\tN\t\nConfigure secrets\tY\tY\tN\t\nPull secrets\tY\tY\tY\t\nRun locally\tY\tY\tY\t\nView API documentation\tY\tY\tY\t\nView Encore Flow\tY\tY\tY\t\nAdmins\nAdmins have full privileges and can administer your entire application.\nMembers\nMembers are active contributors to your applications. They are able to do everything that is not limited to Admins.\nViewers\nViewers are read-only members. They can view the Cloud Dashboard and run your application locally.\nThis role is intended for any team members not contributing directly to your Encore application, but who still get value from certain access. In a bigger team, this role is often appropriate for e.g. Frontend developers and Product Managers.\nCustom roles & permissions\nCustom roles & permissions is an optional add-on to the Pro plan, please contact us to discuss your requirements."
  },
  {
    "url": "https://encore.dev/docs/about/usage",
    "text": "Encore comes with a built-in development cloud, Encore Cloud, that is free to use for development and limited scale commercial projects without any specific SLA requirements. Encore Cloud is subject to Fair Use guidelines and comes without warranty, as it's not intended for large-scale business-critical use cases.\nFor production use cases, Encore is designed to be used together with your cloud on the major cloud providers (AWS/GCP), and provides full DevOps automation for deployments to your own cloud account. This means Encore has no incentive to increase your usage – rather we can focus on building tools to help you minimize your cloud spending! (Should you wish to use Encore Cloud instead of your own cloud account, please contact us.)\nWhen you use Encore together with AWS/GCP, you can still use Encore Cloud to host Preview Environments and development environments.\nExamples of Fair Use\nPrototyping & development\nHobby projects\nCommercial use cases that have limited load and do not require any SLAs\nNever Fair Use\nProxies and VPNs\nMedia hosting for hot-linking\nScrapers\nCrypto Mining\nCPU-intensive APIs (e.g.: Machine Learning)\nLoad Testing\nUsage guidelines\nWe expect most users to fall within the usage limits below. We want to be as flexible and permissive as possible, and will wherever possible reach out and work with you to find a good solution should we notice that you are exceeding these limits.\nFor users on a paid plan, we can change these limits to support your needs. If you have significantly higher requirements, this may come with an additional charge (at cost) to cover the extra capacity. Please contact us for more information.\nWe will never charge you for usage of Encore Cloud unless expressly agreed in advance.\nUsage limits\nPer application\nRequests\t100,000 / day\t\nDatabase Storage\t1 GB\t\nPubSub Messages\t100,000 / day\t\nCron Jobs\tOnce every hour\t\nWhat happens if I reach a usage limit?\nIf your application reaches a usage limit, we will not automatically stop it. Our team will reach out to you, and work with you to find a solution that does not cause any undue disruption to your application."
  },
  {
    "url": "https://encore.dev/docs/introduction",
    "text": "Cloud services enable us to build highly scalable applications, but offer a poor developer experience. They force developers to manage a lot of added complexity during development and commonly introduce repetitive work that steals time away from the real goal of building your product. Launching a new app, migrating to the cloud, or breaking apart a monolith into microservices, can therefore be a daunting task.\nEncore is purpose-built to solve this problem, restoring creativity for developers and productivity for teams.\nA simplified cloud backend development workflow\nEncore provides a complete toolset for backend development, from local development and testing, to cloud infrastructure management and DevOps.\nMuch of Encore's functionality is enabled by the Open Source declarative Infrastructure SDK, which lets you define resources like services, databases, cron jobs, and Pub/Sub, as type-safe objects in your application code.\nWith the SDK you only define infrastructure semantics — the things that matter to your application's behavior — not configuration for specific cloud services. Encore then automatically generates boilerplate and orchestrates the relevant infrastructure for each environment. This means your application code can be used to run locally, test in preview environments, and provision and deploy to cloud environments on AWS and GCP. \nWhen your application is deployed to your cloud, there are no runtime dependencies on Encore and there is no proprietary code running in your cloud.\nLocal Development\nWhen you run your app locally using the Encore CLI, Encore parses your code and automatically sets up the necessary local infrastructure on the fly. No more messing around with Docker Compose!\nAside from managing infrastructure, Encore's local development workflow comes with a lot of tools to make building distributed systems easier:\nLocal environment matches cloud: Encore automatically handles the semantics of service communication and interfacing with different types of infrastructure services, so that the local environment is a 1:1 representation of your cloud environment.\nCross-service type-safety: When building microservices applications with Encore, you get type-safety and auto-complete in your IDE when making cross-service API calls.\nType-aware infrastructure: With Encore, infrastructure like Pub/Sub queues are type-aware objects in your program. This enables full end-to-end type-safety when building event-driven applications.\nSecrets management: Built-in secrets management for all environments.\nTracing: The local development dashboard provides local tracing to help understand application behavior and find bugs.\nAutomatic API docs & clients: Encore generates API docs and API clients in Go, TypeScript, JavaScript, and OpenAPI specification.\nTesting\nEncore comes with several built-in tools to help with testing:\nBuilt-in service/API mocking: Encore provides built-in support for mocking API calls, and interfaces for automatically generating mock objects for your services.\nLocal test infra: When running tests locally, Encore automatically provides dedicated test infrastructure to isolate individual tests.\nLocal test tracing: The local dev dashboard provides distributed tracing for tests, providing great visibility into what's happening and making it easier to understand why a test failed.\nPreview Environments: Encore automatically provisions a Preview Environment for each Pull Request, an effective tool when doing end-to-end testing.\nDevOps\nOur goal is that when you use Encore, you can focus your engineering effort on your product and completely avoid investing time in building a developer platform. You also get built-in tools that automate >90% of the normal day-to-day DevOps work.\nTo achieve this, the headline feature Encore provides is automatic infrastructure provisioning in your cloud. Instead of writing Terraform, YAML, or clicking in cloud consoles, you connect your cloud account and hit deploy. At deployment Encore automatically provisions infrastructure using battle-tested cloud services on AWS or GCP. Such as Cloud Run, Fargate, Kubernetes, CloudSQL, RDS, Pub/Sub, Redis, Cron Jobs, and more.\nThis is enabled by Encore's Open-Source Infrastructure SDK, which lets you declare infrastructure semantics in application code. This approach lets you modify and swap out your infrastructure over time, without needing to make code changes or manually update infrastructure config files.\nHere are some of the other benefits and DevOps tools provided by Encore:\nNo IaC or YAML needed: Encore removes the need for manual infrastructure configuration, the application code is the source of truth for both business logic and infrastructure semantics.\nAutomatic least-privilege IAM: Encore parses your application code and sets up least-privilege IAM to match the requirements of the application.\nInfra tracking & approvals workflow: Encore keeps track of all the infrastructure it provisions and provides an approval workflow as part of the deployment process, so Admins can verify and approve all infra changes.\nCloud config 2-way sync: Encore provides a simple UI to make configuration changes, and also supports syncing changes you make in your cloud console on AWS/GCP.\nCost analytics: A simple overview to monitor costs for all infrastructure provisioned by Encore in your cloud.\nLogging & Metrics: Encore automatically provides logging, metrics, and integrates with 3rd party tools like Datadog and Grafana.\nService Catalog: Encore automatically generates a service catalog with complete API documentation.\nArchitecture diagrams: To help with onboarding and collaboration, Encore generates architecture diagrams for your application, including infrastructure dependencies.\nWhy choose Encore?\nWe believe Encore's end-to-end workflow is an unfair advantage for teams that want to focus on their product, and avoid investing engineering time in building yet another developer platform.\nEncore is designed to provide engineering teams with all the tools they need to build production-ready cloud backends:\nFaster Development: Encore streamlines the development process with its infrastructure SDK, clear abstractions, and built-in development tools, enabling you to build and deploy applications more quickly.\nReduced Costs: Encore's infrastructure management minimizes wasteful cloud expenses and reduces DevOps workload, allowing you to work more efficiently.\nScalability & Performance: Encore simplifies building microservices applications that can handle growing user bases and demands, without the normal boilerplate and complexity.\nControl & Standardization: Encore enforces standardization and provisions infrastructure consistently according to best practices for each cloud provider.\nQuality through understandability: Built-in tools like automated architecture diagrams, generated API docs, and distributed tracing make it simple for teams to get an overview of their system and understand its behavior.\nSecurity: Encore ensures your application is secure by implementing cloud security best practices and principle of least privilege security by default.\nCommon use cases\nEncore is designed to give teams a productive and less complex experience when solving most backend use cases. Many teams use Encore to build things like:\nHigh-performance B2B Platforms\nFintech & Consumer apps\nGlobal E-commerce marketplaces\nMicroservices backends and event-driven systems for SaaS applications and mobile apps\nAnd much more...\nSee the users stories section for more on how teams are using Encore to power their development.\nGetting started\nSign up and install the Encore CLI\nFollow a tutorial and start building\nBook a 1:1 or join Discord to discuss your use case or how to begin adopting Encore\nFollow and star the project on GitHub to stay up to date\nExplore the Documentation to learn about Encore's features\n...or keep reading to learn more about how Encore works.\nMeet the Encore application model\nEncore works by using static analysis to understand your application. This is a fancy term for parsing and analyzing the code you write and creating a graph of how your application works. This graph closely represents your own mental model of the system: boxes and arrows that represent systems and services that communicate with other systems, pass data and connect to infrastructure. We call it the Encore Application Model.\nBecause Encore's Open Source Infrastructure SDK, parser, and compiler, are all designed together, Encore can ensure 100% accuracy when creating the application model. Any deviation is caught as a compilation error.\nUsing this model, Encore can provide tools to solve problems that normally would be up to the developer to do manually. From creating architecture diagrams and API documentation to provisioning cloud infrastructure.\nWe're continuously expanding on Encore's capabilities and are building a new generation of developer tools that are enabled by Encore's understanding of your application.\nThe infrastructure SDK, parser, and compiler that enable this are all Open Source.\nStandardization brings clarity\nDevelopers make dozens of decisions when creating a backend application. Deciding how to structure the codebase, defining API schemas, picking underlying infrastructure, etc. The decisions often come down to personal preferences, not technical rationale. This creates a huge problem in the form of fragmentation! When every stack looks different, all tools have to be general purpose.\nWhen you adopt Encore, many of these stylistic decisions are already made for you. Encore's Infrastructure SDK ensures your application follows modern best practices. And when you run your application, Encore's Open Source parser and compiler check that you're sticking to the standard. This means you're free to focus your energy on what matters: writing your application's business logic."
  },
  {
    "url": "https://encore.dev/docs/install",
    "text": "If you are new to Encore, we recommend following the quick start guide.\nInstall the Encore CLI\nTo develop locally with Encore, you first need to install the Encore CLI. This is what provisions your local development environment, and runs your Local Development Dashboard complete with logs, tracing, and API documentation.\n$ brew install encoredev/tap/encore\nPlease note\nTo locally run Encore apps with databases, you also need to have Docker installed and running.\nBuild from source\nIf you prefer to build from source, follow these instructions.\nUpdate to the latest version\nCheck which version of Encore you have installed by running encore version in your terminal. It should print something like:\nencore version v1.28.0\nIf you think you're on an older version of Encore, you can easily update to the latest version by running encore version update from your terminal."
  },
  {
    "url": "https://encore.dev/docs/quick-start",
    "text": "1. Install the Encore CLI\nTo develop with Encore, you need the Encore CLI. It provisions your local environment, and runs your local development dashboard complete with tracing and API documentation.\n🥐 Install by running the appropriate command for your system:\n$ brew install encoredev/tap/encore\n2. Create your app\n🥐 Create your app by running:\n$ encore app create\n🥐 Continue by picking a name for your app and select the Hello World template.\nSince this is the first time you're using Encore, you'll be asked to create a free account. This is needed so that Encore can orchestrate functionality like tracing, secrets, and manage cloud deployments. You can use your account with GitHub, Google, or create an account using your email.\nLet's take a look at the code\nPart of what makes Encore different is the simple developer experience when building distributed systems. Let's look at the code to better understand how to build applications with Encore.\n🥐 Open the hello.ts file in your code editor. It's located in the folder: your-app-name/hello/.\nYou should see this:\nimport { api } from \"encore.dev/api\"; export const world = api( { method: \"GET\", path: \"/hello/:name\", expose: true }, async ({ name }: { name: string }): Promise<Response> => { return { message: `Hello ${name}!` }; }, ); interface Response { message: string; } \nAs you can see, it's all standard TypeScript.\nYou define an API endpoint by wrapping a regular async function in a call to api. Doing this makes Encore identify the hello directory as a service, and that the world function is a public API endpoint. Encore automatically handles authentication, HTTP routing, request validation, error handling, observability, API documentation, and more.\nIf you want to create more services and endpoints, you simply create new folders and define endpoints by wrapping functions in the api function. If you're curious, you can read more about defining services and APIs.\nEncore's Infrastructure SDK provides several declarative ways of using backend primitives like databases, Pub/Sub, and scheduled tasks by simply writing code.\n3. Start your app & Explore Local Development Dashboard\n🥐 Now let's run your app locally:\n$ cd your-app-name # replace with the app name you picked\n$ encore run\nYou should see this:\nThat means your local development environment is up and running! Encore takes care of setting up all the necessary infrastructure for your applications, even including databases and Pub/Sub.\nOpen the Local Development Dashboard\nYou can now start using your Local Development Dashboard.\n🥐 Open http://localhost:9400 in your browser to access it.\nThe Local Development Dashboard is a powerful tool to help you move faster when you're developing new features.\nIt comes with an API explorer, a Service Catalog with automatically generated documentation, and powerful oberservability features like distributed tracing.\nThrough the Local Development Dashboard you also have access to Encore Flow, a visual representation of your microservice architecture that updates in real-time as you develop your application.\nCall your API\n🥐 While you keep the app running, call your API from the API Explorer:\nYou can also open a separate terminal to call your API endpoint:\n$ curl http://localhost:4000/hello/world\n{\"Message\": \"Hello, world!\"}\nIf you see this JSON response, you've successfully made an API call to your very first Encore application. Well done, you're on your way!\nReview a trace of the request\nYou can now take a look at the trace for the request you just made by clicking on it in the right column in the local dashboard.\nWith such a simple API, there's not much to it, just a simple request and response.\nHowever, just imagine how powerful it is to have tracing when you're developing a more complex system with multiple services, Pub/Sub, and databases. (Learn more about Encore's tracing capabilities in the tracing docs.)\n4. Push a code change and deploy\nLet's put our mark on this API and make our first code change.\n🥐 Head back to your code editor and look at the hello.ts file again. If you can't come up a creative change yourself, why not simply change the \"Hello\" message to a more sassy \"Howdy\"?\n🥐 Once you've made your change, save the file.\nWhen you save, the daemon run by the Encore CLI instantly detects the change and automatically recompiles your application and reloads your local development environment.\nThe output where you're running your app will look something like this:\nChanges detected, recompiling... Reloaded successfully. INF registered endpoint endpoint=World path=/hello/:name service=hello INF listening for incoming HTTP requests \n🥐 Test your change by calling your API again.\n$ curl http://localhost:4000/hello/world\n{\"Message\": \"Howdy, world!\"}\nGreat job, you made a change and your app was reloaded automatically.\nNow you're ready to head to the cloud!\nDeploy your app to the cloud\nThe first time you deploy an app, Encore will by default create a staging environment in Encore's free development cloud (Encore Cloud). (Learn about the usage limits.)\nLater, when you are ready to create a production environment, you can connect your AWS or GCP account and Encore will deploy to your own cloud. (Or even both of them, Encore makes it seamless to deploy to multiple cloud environments.)\n🥐 Now push your changes and deploy your application by running:\n$ git add -A .\n$ git commit -m 'Initial commit'\n$ git push encore\nEncore will now build and test your app, provision the needed infrastructure, and deploy your application to the cloud.\nYour app will soon be running in the cloud, isn't this exciting?\n5. Explore the Cloud Dashboard\nAfter triggering the deployment, you will see a URL where you can view its progress in Encore's Cloud Dashboard. It will look something like: https://app.encore.dev/$APP_ID/deploys/...\n🥐 Open the URL to access the Cloud Dashboard and check the progress of your deployment.\nYou can now use the Cloud Dashboard to view production logs and traces, create new environments, connect your cloud account, integrate with GitHub, and much more.\nCall your API in the cloud\nNow that you've created your staging environment, you're ready to call your API running in the cloud. Your API Base URL will be something like: https://staging-$APP_ID.encr.app\n🥐 When the deploy is finished, call your API from the Cloud Dashboard using the API Explorer in the Service Catalog.\nOr you can call it from the terminal (replacing $APP_ID with your own App ID):\n$ curl https://staging-$APP_ID.encr.app/hello/world\n{\"Message\": \"Howdy, world!\"}\nIf you see this, you've successfully made an API call to your very first Encore app running in the cloud.\nCongratulations, you're well on your way to escaping the maze of cloud complexity!\nWhat's next?\n🥐 Check out the REST API tutorial to learn how to create endpoints, use databases, and more.\nIf you want to chat to other pioneering developers already building with Encore, or need help, join the friendly community on Discord."
  },
  {
    "url": "https://encore.dev/docs/tutorials",
    "text": "Tutorials\nStart building your backend application using Encore\nCheck out these tutorials to learn how to build applications with Encore and find inspiration for what to create."
  },
  {
    "url": "https://encore.dev/docs/tutorials/uptime",
    "text": "1. Create your Encore application\nPlease note\nTo make it easier to follow along, we've laid out a trail of croissants to guide your way. Whenever you see a 🥐 it means there's something for you to do.\n🥐 Create a new Encore application, using this tutorial project's starting-point branch. This gives you a ready-to-go frontend to use.\n$ encore app create uptime --example=github.com/encoredev/example-app-uptime/tree/starting-point-ts\nYour newly created application will also be registered on https://app.encore.dev for when you deploy your new app later.\n🥐 Check that your frontend works:\n$ cd uptime\n$ encore run\nThen visit http://localhost:4000/ to see the Next.js frontend. It won't work yet, since we haven't yet built the backend, so let's do just that!\nWhen we're done we'll have a backend with an event-driven architecture, as seen below in the automatically generated diagram where white boxes are services and black boxes are Pub/Sub topics:\n2. Create monitor service\nLet's start by creating the functionality to check if a website is currently up or down. Later we'll store this result in a database so we can detect when the status changes and send alerts.\n🥐 Create an Encore service named monitor containing a file named ping.ts.\n$ mkdir monitor\n$ touch monitor/ping.ts\n🥐 Add an Encore API endpoint named ping that takes a URL as input and returns a response indicating whether the site is up or down.\n// Service monitor checks if a website is up or down. import { api } from \"encore.dev/api\"; export interface PingParams { url: string; } export interface PingResponse { up: boolean; } // Ping pings a specific site and determines whether it's up or down right now. export const ping = api<PingParams, PingResponse>( { expose: true, path: \"/ping/:url\", method: \"GET\" }, async ({ url }) => { // If the url does not start with \"http:\" or \"https:\", default to \"https:\". if (!url.startsWith(\"http:\") && !url.startsWith(\"https:\")) { url = \"https://\" + url; } try { // Make an HTTP request to check if it's up. const resp = await fetch(url, { method: \"GET\" }); // 2xx and 3xx status codes are considered up const up = resp.status >= 200 && resp.status < 300; return { up }; } catch (err) { return { up: false }; } } ); \n🥐 Let's try it! Run encore run in your terminal and you should see the service start up.\nThen open up the Local Development Dashboard running at http://localhost:9400 and try calling the monitor.ping endpoint, passing in google.com as the URL.\nIf you prefer to use the terminal instead run curl http://localhost:4000/ping/google.com in a new terminal instead. Either way you should see the response:\nYou can also try with httpstat.us/400 and some-non-existing-url.com and it should respond with {\"up\": false}. (It's always a good idea to test the negative case as well.)\nAdd a test\n🥐 Let's write an automated test so we don't break this endpoint over time. Create the file monitor/ping.test.ts with the content:\nimport { describe, expect, test } from \"vitest\"; import { ping } from \"./ping\"; describe(\"ping\", () => { test.each([ // Test both with and without \"https://\" { site: \"google.com\", expected: true }, { site: \"https://encore.dev\", expected: true }, // 4xx and 5xx should considered down. { site: \"https://not-a-real-site.xyz\", expected: false }, // Invalid URLs should be considered down. { site: \"invalid://scheme\", expected: false }, ])( `should verify that $site is ${\"$expected\" ? \"up\" : \"down\"}`, async ({ site, expected }) => { const resp = await ping({ url: site }); expect(resp.up).toBe(expected); }, ); }); \n🥐 Run encore test to check that it all works as expected. You should see something like:\n$ encore test\nDEV v1.3.0\n✓ monitor/ping.test.ts (4)\n✓ ping (4)\n✓ should verify that 'google.com' is up\n✓ should verify that 'https://encore.dev' is up\n✓ should verify that 'https://not-a-real-site.xyz' is up\n✓ should verify that 'invalid://scheme' is up\nTest Files 1 passed (1)\nTests 4 passed (4)\nStart at 12:31:03\nDuration 460ms (transform 43ms, setup 0ms, collect 59ms, tests 272ms, environment 0ms, prepare 47ms)\nPASS Waiting for file changes...\n3. Create site service\nNext, we want to keep track of a list of websites to monitor.\nSince most of these APIs will be simple \"CRUD\" (Create/Read/Update/Delete) endpoints, let's build this service using Knex.js, an ORM library that makes building CRUD endpoints really simple.\n🥐 Let's create a new service named site with a SQL database. To do so, create a new directory site in the application root with migrations folder inside that folder:\n$ mkdir site\n$ mkdir site/migrations\n🥐 Add a database migration file inside that folder, named 1_create_tables.up.sql. The file name is important (it must look something like 1_<name>.up.sql).\nAdd the following contents:\nsite/migrations/1_create_tables.up.sql\nCREATE TABLE site ( id SERIAL PRIMARY KEY, url TEXT NOT NULL UNIQUE ); \n🥐 Next, install the Knex.js library and PostgreSQL client:\n$ npm i knex pg\nNow let's create the site service itself with our CRUD endpoints.\n🥐 Create site/site.ts with the contents:\nimport { api } from \"encore.dev/api\"; import { SQLDatabase } from \"encore.dev/storage/sqldb\"; import knex from \"knex\"; // Site describes a monitored site. export interface Site { id: number; // ID is a unique ID for the site. url: string; // URL is the site's URL. } // AddParams are the parameters for adding a site to be monitored. export interface AddParams { // URL is the URL of the site. If it doesn't contain a scheme // (like \"http:\" or \"https:\") it defaults to \"https:\". url: string; } // Add a new site to the list of monitored websites. export const add = api( { expose: true, method: \"POST\", path: \"/site\" }, async (params: AddParams): Promise<Site> => { const site = (await Sites().insert({ url: params.url }, \"*\"))[0]; return site; }, ); // Get a site by id. export const get = api( { expose: true, method: \"GET\", path: \"/site/:id\", auth: false }, async ({ id }: { id: number }): Promise<Site> => { const site = await Sites().where(\"id\", id).first(); return site ?? Promise.reject(new Error(\"site not found\")); }, ); // Delete a site by id. export const del = api( { expose: true, method: \"DELETE\", path: \"/site/:id\" }, async ({ id }: { id: number }): Promise<void> => { await Sites().where(\"id\", id).delete(); }, ); export interface ListResponse { sites: Site[]; // Sites is the list of monitored sites } // Lists the monitored websites. export const list = api( { expose: true, method: \"GET\", path: \"/site\" }, async (): Promise<ListResponse> => { const sites = await Sites().select(); return { sites }; }, ); // Define a database named 'site', using the database migrations // in the \"./migrations\" folder. Encore automatically provisions, // migrates, and connects to the database. const SiteDB = new SQLDatabase(\"site\", { migrations: \"./migrations\", }); const orm = knex({ client: \"pg\", connection: SiteDB.connectionString, }); const Sites = () => orm<Site>(\"site\"); \n🥐 Now make sure you have Docker installed and running, and then restart encore run to cause the site database to be created by Encore. Then let's call the site.add endpoint:\n$ curl -X POST 'http://localhost:4000/site' -d '{\"url\": \"https://encore.dev\"}'\n{\n\"id\": 1,\n\"url\": \"https://encore.dev\"\n}\n4. Record uptime checks\nIn order to notify when a website goes down or comes back up, we need to track the previous state it was in.\n🥐 To do so, let's add a database to the monitor service as well. Create the directory monitor/migrations and the file monitor/migrations/1_create_tables.up.sql:\nmonitor/migrations/1_create_tables.up.sql\nCREATE TABLE checks ( id BIGSERIAL PRIMARY KEY, site_id BIGINT NOT NULL, up BOOLEAN NOT NULL, checked_at TIMESTAMP WITH TIME ZONE NOT NULL ); \nWe'll insert a database row every time we check if a site is up.\n🥐 Add a new endpoint check to the monitor service, that takes in a Site ID, pings the site, and inserts a database row in the checks table.\nFor this service we'll use Encore's SQLDatabase class instead of Knex (in order to showcase both approaches).\nimport { api } from \"encore.dev/api\"; import { SQLDatabase } from \"encore.dev/storage/sqldb\"; import { ping } from \"./ping\"; import { site } from \"~encore/clients\"; // Check checks a single site. export const check = api( { expose: true, method: \"POST\", path: \"/check/:siteID\" }, async (p: { siteID: number }): Promise<{ up: boolean }> => { const s = await site.get({ id: p.siteID }); const { up } = await ping({ url: s.url }); await MonitorDB.exec` INSERT INTO checks (site_id, up, checked_at) VALUES (${s.id}, ${up}, NOW()) `; return { up }; }, ); // Define a database named 'monitor', using the database migrations // in the \"./migrations\" folder. Encore automatically provisions, // migrates, and connects to the database. export const MonitorDB = new SQLDatabase(\"monitor\", { migrations: \"./migrations\", }); \n🥐 Restart encore run to cause the monitor database to be created, and then call the new monitor.check endpoint:\n$ curl -X POST 'http://localhost:4000/check/1'\n🥐 Inspect the database to make sure everything worked:\n$ encore db shell monitor\npsql (14.4, server 14.2)\nType \"help\" for help.\nmonitor=> SELECT * FROM checks;\nid | site_id | up | checked_at\n----+---------+----+-------------------------------\n1 | 1 | t | 2022-10-21 09:58:30.674265+00\nIf that's what you see, everything's working great!\nAdd a cron job to check all sites\nWe now want to regularly check all the tracked sites so we can respond in case any of them go down.\nWe'll create a new checkAll API endpoint in the monitor service that will list all the tracked sites and check all of them.\n🥐 Let's extract some of the functionality we wrote for the check endpoint into a separate function, like so:\nimport {Site} from \"../site/site\"; // Check checks a single site. export const check = api( { expose: true, method: \"POST\", path: \"/check/:siteID\" }, async (p: { siteID: number }): Promise<{ up: boolean }> => { const s = await site.get({ id: p.siteID }); return doCheck(s); }, ); async function doCheck(site: Site): Promise<{ up: boolean }> { const { up } = await ping({ url: site.url }); await MonitorDB.exec` INSERT INTO checks (site_id, up, checked_at) VALUES (${site.id}, ${up}, NOW()) `; return { up }; } \nNow we're ready to create our new checkAll endpoint.\n🥐 Create the new checkAll endpoint inside monitor/check.ts:\n// CheckAll checks all sites. export const checkAll = api( { expose: true, method: \"POST\", path: \"/check-all\" }, async (): Promise<void> => { const sites = await site.list(); await Promise.all(sites.sites.map(doCheck)); }, ); \n🥐 Now that we have a checkAll endpoint, define a cron job to automatically call it every 1 hour (since this is an example, we don't need to go too crazy and check every minute):\nimport { CronJob } from \"encore.dev/cron\"; // Check all tracked sites every 1 hour. const cronJob = new CronJob(\"check-all\", { title: \"Check all sites\", every: \"1h\", endpoint: checkAll, }); \nPlease note\nCron jobs are not triggered when running the application locally but work when deploying the application to a cloud environment.\nThe frontend needs a way to list all sites and display if they are up or down. \n🥐 Add a file in the monitor service and name it status.ts. Add the following code:\nimport { api } from \"encore.dev/api\"; import { MonitorDB } from \"./check\"; interface SiteStatus { id: number; up: boolean; checkedAt: string; } // StatusResponse is the response type from the Status endpoint. interface StatusResponse { // Sites contains the current status of all sites, // keyed by the site ID. sites: SiteStatus[]; } // status checks the current up/down status of all monitored sites. export const status = api( { expose: true, path: \"/status\", method: \"GET\" }, async (): Promise<StatusResponse> => { const rows = await MonitorDB.query` SELECT DISTINCT ON (site_id) site_id, up, checked_at FROM checks ORDER BY site_id, checked_at DESC `; const results: SiteStatus[] = []; for await (const row of rows) { results.push({ id: row.site_id, up: row.up, checkedAt: row.checked_at, }); } return { sites: results }; }, ); \nNow try visiting http://localhost:4000/ in your browser again. This time you should see a working frontend that lists all sites and their current status.\n5. Deploy to Encore's development cloud\nTo try out your uptime monitor for real, let's deploy it to Encore's free development cloud.\nEncore comes with built-in CI/CD, and the deployment process is as simple as a git push. (You can also integrate with GitHub to activate per Pull Request Preview Environments, learn more in the CI/CD docs.)\n🥐 Now, let's deploy your app to Encore's free development cloud by running:\n$ git add -A .\n$ git commit -m 'Initial commit'\n$ git push encore\nEncore will now build and test your app, provision the needed infrastructure, and deploy your application to the cloud.\nAfter triggering the deployment, you will see a URL where you can view its progress in Encore's Cloud Dashboard. It will look something like: https://app.encore.dev/$APP_ID/deploys/...\nFrom there you can also see metrics, traces, link your app to a GitHub repo to get automatic deploys on new commits, and connect your own AWS or GCP account to use for production deployment.\n🥐 When the deploy has finished, you can try out your uptime monitor by going to https://staging-$APP_ID.encr.app.\nYou now have an Uptime Monitor running in the cloud, well done!\n6. Publish Pub/Sub events when a site goes down\nAn uptime monitoring system isn't very useful if it doesn't actually notify you when a site goes down.\nTo do so let's add a Pub/Sub topic on which we'll publish a message every time a site transitions from being up to being down, or vice versa.\n🥐 Define the topic using Encore's Pub/Sub module in monitor/check.ts:\nimport { Subscription, Topic } from \"encore.dev/pubsub\"; // TransitionEvent describes a transition of a monitored site // from up->down or from down->up. export interface TransitionEvent { site: Site; // Site is the monitored site in question. up: boolean; // Up specifies whether the site is now up or down (the new value). } // TransitionTopic is a pubsub topic with transition events for when a monitored site // transitions from up->down or from down->up. export const TransitionTopic = new Topic<TransitionEvent>(\"uptime-transition\", { deliveryGuarantee: \"at-least-once\", }); \nNow let's publish a message on the TransitionTopic if a site's up/down state differs from the previous measurement.\n🥐 Create a getPreviousMeasurement function to report the last up/down state:\n// getPreviousMeasurement reports whether the given site was // up or down in the previous measurement. async function getPreviousMeasurement(siteID: number): Promise<boolean> { const row = await MonitorDB.queryRow` SELECT up FROM checks WHERE site_id = ${siteID} ORDER BY checked_at DESC LIMIT 1 `; return row?.up ?? true; } \n🥐 Now add a function to conditionally publish a message if the up/down state differs by modifying the doCheck function:\nasync function doCheck(site: Site): Promise<{ up: boolean }> { const { up } = await ping({ url: site.url }); // Publish a Pub/Sub message if the site transitions // from up->down or from down->up. const wasUp = await getPreviousMeasurement(site.id); if (up !== wasUp) { await TransitionTopic.publish({ site, up }); } await MonitorDB.exec` INSERT INTO checks (site_id, up, checked_at) VALUES (${site.id}, ${up}, NOW()) `; return { up }; } \nNow the monitoring system will publish messages on the TransitionTopic whenever a monitored site transitions from up->down or from down->up. It doesn't know or care who actually listens to these messages.\nThe truth is right now nobody does. So let's fix that by adding a Pub/Sub subscriber that posts these events to Slack.\n7. Send Slack notifications when a site goes down\n🥐 Start by creating a Slack service containing the following:\nimport { api } from \"encore.dev/api\"; import { secret } from \"encore.dev/config\"; import log from \"encore.dev/log\"; export interface NotifyParams { text: string; // the slack message to send } // Sends a Slack message to a pre-configured channel using a // Slack Incoming Webhook (see https://api.slack.com/messaging/webhooks). export const notify = api<NotifyParams>({}, async ({ text }) => { const url = webhookURL(); if (!url) { log.info(\"no slack webhook url defined, skipping slack notification\"); return; } const resp = await fetch(url, { method: \"POST\", body: JSON.stringify({ text }), }); if (resp.status >= 400) { const body = await resp.text(); throw new Error(`slack notification failed: ${resp.status}: ${body}`); } }); // SlackWebhookURL defines the Slack webhook URL to send uptime notifications to. const webhookURL = secret(\"SlackWebhookURL\"); \n🥐 Now go to a Slack community of your choice where you have the permission to create a new Incoming Webhook.\n🥐 Once you have the Webhook URL, set it as an Encore secret:\n$ encore secret set --type dev,local,pr SlackWebhookURL\nEnter secret value: *****\nSuccessfully updated development secret SlackWebhookURL.\n🥐 Test the slack.notify endpoint by calling it via cURL:\n$ curl 'http://localhost:4000/slack.notify' -d '{\"text\": \"Testing Slack webhook\"}'\nYou should see the Testing Slack webhook message appear in the Slack channel you designated for the webhook.\n🥐 When it works it's time to add a Pub/Sub subscriber to automatically notify Slack when a monitored site goes up or down. Add the following:\nimport { Subscription } from \"encore.dev/pubsub\"; import { TransitionTopic } from \"../monitor/check\"; const _ = new Subscription(TransitionTopic, \"slack-notification\", { handler: async (event) => { const text = `*${event.site.url} is ${event.up ? \"back up.\" : \"down!\"}*`; await notify({ text }); }, }); \n8. Deploy your finished Uptime Monitor\nNow you're ready to deploy your finished Uptime Monitor, complete with a Slack integration.\n🥐 As before, deploying your app to the cloud is as simple as running:\n$ git add -A .\n$ git commit -m 'Add slack integration'\n$ git push encore\nCelebrate with fireworks\nNow that your app is running in the cloud, let's celebrate with some fireworks:\n🥐 In the Cloud Dashboard, open the Command Menu by pressing Cmd + K (Mac) or Ctrl + K (Windows/Linux).\nFrom here you can easily access all Cloud Dashboard features and for example jump straight to specific services in the Service Catalog or view Traces for specific endpoints.\n🥐 Type fireworks in the Command Menu and press enter. Sit back and enjoy the show!\nConclusion\nWe've now built a fully functioning uptime monitoring system.\nIf we may say so ourselves (and we may; it's our documentation after all) it's pretty remarkable how much we've accomplished in such little code:\nWe've built three different services (site, monitor, and slack)\nWe've added two databases (to the site and monitor services) for tracking monitored sites and the monitoring results\nWe've added a cron job for automatically checking the sites every hour\nWe've set up a Pub/Sub topic to decouple the monitoring system from the Slack notifications\nWe've added a Slack integration, using secrets to securely store the webhook URL, listening to a Pub/Sub subscription for up/down transition events\nAll of this in just a bit over 300 lines of code. It's time to lean back and take a sip of your favorite beverage, safe in the knowledge you'll never be caught unaware of a website going down suddenly."
  },
  {
    "url": "https://encore.dev/docs/tutorials/graphql",
    "text": "Learn how to build a GraphQL API using Go and Encore\nEncore has great support for GraphQL with its type-safe approach to building APIs.\nEncore's automatic tracing also makes it easy to find and fix performance issues that often arise in GraphQL APIs (like the N+1 problem).\nA TypeScript tutorial for using GraphQL with Encore is coming soon."
  },
  {
    "url": "https://encore.dev/docs/tutorials/rest-api",
    "text": "This is the end result:\nPlease note\nTo make it easier to follow along, we've laid out a trail of croissants to guide your way. Whenever you see a 🥐 it means there's something for you to do.\n1. Create a service and endpoint\nCreate a new application by running encore app create and select Empty app as the template.\nNow let's create a new url service.\n🥐 In your application's root folder, create a new folder url and create a new file url.ts that looks like this:\nimport { api } from \"encore.dev/api\"; import { randomBytes } from \"node:crypto\"; interface URL { id: string; // short-form URL id url: string; // complete URL, in long form } interface ShortenParams { url: string; // the URL to shorten } // Shortens a URL. export const shorten = api( { method: \"POST\", path: \"/url\", expose: true }, async ({ url }: ShortenParams): Promise<URL> => { const id = randomBytes(6).toString(\"base64url\"); return { id, url }; }, ); \nThis sets up the POST /url endpoint.\n🥐 Let’s see if it works! Start your app by running encore run.\nYou should see this:\nEncore development server running! Your API is running at: http://127.0.0.1:4000 Development Dashboard URL: http://localhost:9400/5g288 3:50PM INF registered API endpoint endpoint=shorten path=/url service=url \n🥐 Next, call your endpoint:\n$ curl http://localhost:4000/url -d '{\"url\": \"https://encore.dev\"}'\nYou should see this:\n{ \"id\": \"5cJpBVRp\", \"url\": \"https://encore.dev\" } \nIt works! There’s just one problem...\nRight now, we’re not actually storing the URL anywhere. That means we can generate shortened IDs but there’s no way to get back to the original URL! We need to store a mapping from the short ID to the complete URL.\n2. Save URLs in a database\nFortunately, Encore makes it really easy to set up a PostgreSQL database to store our data. To do so, we first define a database schema, in the form of a migration file.\n🥐 Create a new folder named migrations inside the url folder. Then, inside the migrations folder, create an initial database migration file named 1_create_tables.up.sql. The file name format is important (it must start with 1_ and end in .up.sql).\n🥐 Add the following contents to the file:\nCREATE TABLE url ( id TEXT PRIMARY KEY, original_url TEXT NOT NULL ); \n🥐 Next, go back to the url/url.ts file and import the SQLDatabase class from encore.dev/storage/sqldb module by modifying the imports to look like this:\nimport { api } from \"encore.dev/api\"; import { SQLDatabase } from \"encore.dev/storage/sqldb\"; import { randomBytes } from \"node:crypto\"; \n🥐 Now, to insert data into our database, let’s create an instance of the SQLDatabase class:\nconst db = new SQLDatabase(\"url\", { migrations: \"./migrations\" }); \n🥐 Lastly, we can update our shorten function to insert into the database:\nexport const shorten = api( { method: \"POST\", path: \"/url\", expose: true }, async ({ url }: ShortenParams): Promise<URL> => { const id = randomBytes(6).toString(\"base64url\"); await db.exec` INSERT INTO url (id, original_url) VALUES (${id}, ${url}) `; return { id, url }; }, ); \nPlease note\nBefore running your application, make sure you have Docker installed and running. It's required to locally run Encore applications with databases.\n🥐 Next, start the application again with encore run and Encore automatically sets up your database.\n(In case your application won't run, check the databases troubleshooting guide.)\n🥐 Now let's call the API again:\n$ curl http://localhost:4000/url -d '{\"url\": \"https://encore.dev\"}'\n🥐 Finally, let's verify that it was saved in the database by running encore db shell url from the app root directory and inputting select * from url;:\n$ encore db shell url\npsql (13.1, server 11.12)\nType \"help\" for help.\nurl=# select * from url;\nid | original_url\n----------+--------------------\nzr6RmZc4 | https://encore.dev\n(1 row)\nThat was easy!\n3. Add endpoint to retrieve URLs\nTo complete our URL shortener API, let’s add the endpoint to retrieve a URL given its short id.\n🥐 Add this endpoint to url/url.ts:\nimport { APIError } from \"encore.dev/api\"; export const get = api( { method: \"GET\", path: \"/url/:id\", expose: true }, async ({ id }: { id: string }): Promise<URL> => { const row = await db.queryRow` SELECT original_url FROM url WHERE id = ${id} `; if (!row) throw APIError.notFound(\"url not found\"); return { id, url: row.original_url }; }, ); \nEncore uses the /url/:id syntax to represent a path with a parameter. The id name corresponds to the parameter name in the function signature. In this case it is of type string, but you can also use other built-in types like number or boolean if you want to restrict the values.\n🥐 Let’s make sure it works by calling it (remember to change the id below to the one you found in the last step):\n$ curl http://localhost:4000/url/zr6RmZc4\nYou should now see this:\n{ \"id\": \"zr6RmZc4\", \"url\": \"https://encore.dev\" } \nAnd there you have it! That's how you build REST APIs and use PostgreSQL databases in Encore.\n4. Add a test\nBefore deployment, it is good practice to have tests to assure that the service works properly. Such tests including database access are easy to write.\n🥐 Let's start by adding the vitest package to your project:\n$ npm i --save-dev vitest\nVitest is a testing framework that works great with Encore but you can use another TypeScript testing framework if you like.\n🥐 Next we need to add a test script to our package.json:\n... \"scripts\": { \"test\": \"vitest\" }, ... \nWe've prepared a test to check that the whole cycle of shortening the URL, storing and then retrieving the original URL works. It looks like this:\nimport { describe, expect, test } from \"vitest\"; import { get, shorten } from \"./url\"; describe(\"shorten\", () => { test(\"getting a shortened url should give back the original\", async () => { const resp = await shorten({ url: \"https://example.com\" }); const url = await get({ id: resp.id }); expect(url.url).toBe(\"https://example.com\"); }); }); \n🥐 Save this in a separate file url/url.test.test.\n🥐 Now run encore test to verify that it's working.\nIf you use the local development dashboard (localhost:9400), you can even see traces for tests.\n5. Deploy to the cloud\nThe final step before you deploy is to commit all changes to the project repo.\n🥐 Commit the new files to the project's git repo and trigger a deploy to Encore's free development cloud by running:\n$ git add -A .\n$ git commit -m 'Initial commit'\n$ git push encore\nEncore will now build and test your app, provision the needed infrastructure, and deploy your application to the cloud.\nAfter triggering the deployment, you will see a URL where you can view its progress in Encore's Cloud Dashboard. It will look something like: https://app.encore.dev/$APP_ID/deploys/...\nFrom there you can also see metrics, traces, and connect your own AWS or GCP account to use for production deployment.\nNow you have a fully fledged backend running in the cloud, well done!\nCelebrate with fireworks\nNow that your app is running in the cloud, let's celebrate with some fireworks:\n🥐 In the Cloud Dashboard, open the Command Menu by pressing Cmd + K (Mac) or Ctrl + K (Windows/Linux).\nFrom here you can easily access all Cloud Dashboard features and for example jump straight to specific services in the Service Catalog or view Traces for specific endpoints.\n🥐 Type fireworks in the Command Menu and press enter. Sit back and enjoy the show!\nWhat's next\nNow that you know how to build a backend with a database, you're ready to let your creativity flow and begin building your next great idea!\n🥐 A great next step is to integrate with GitHub. Once you've linked with GitHub, Encore will automatically start building and running tests against your Pull Requests.\nWe're excited to hear what you're going to build with Encore, join the pioneering developer community on Discord and share your story."
  },
  {
    "url": "https://encore.dev/docs/tutorials/slack-bot",
    "text": "This is the end result:\nPlease note\nTo make it easier to follow along, we've laid out a trail of croissants to guide your way. Whenever you see a 🥐 it means there's something for you to do.\n1. Create your Encore application\n🥐 Create a new Encore application by running encore app create and select Empty app as the template. Take a note of your app id, we'll need it in the next step.\n2. Create a Slack app\n🥐 The first step is to create a new Slack app:\nHead over to Slack's API site and create a new app.\nWhen prompted, choose to create the app from an app manifest.\nChoose a workspace to install the app in.\n🥐 Enter the following manifest (replace $APP_ID in the URL below with your app id from above):\n_metadata: major_version: 1 display_information: name: Encore Bot description: Cowsay for the cloud age. features: slash_commands: - command: /cowsay # Replace $APP_ID below url: https://staging-$APP_ID.encr.app/cowsay description: Say things with a flair! usage_hint: your message here should_escape: false bot_user: display_name: encore-bot always_online: true oauth_config: scopes: bot: - commands - chat:write - chat:write.public settings: org_deploy_enabled: false socket_mode_enabled: false token_rotation_enabled: false \nOnce created, we're ready to move on with implementing our Encore endpoint!\n3. Implement the Slack endpoint\nSince Slack sends custom HTTP headers that we need to pay attention to, we're going to use a raw endpoint in Encore. For more information on this check out Slack's documentation on Enabling interactivity with Slash Commands.\n🥐 In your Encore app, create a new directory named slack and create a file slack/slack.ts with the following contents:\nimport { api } from \"encore.dev/api\"; import type { IncomingMessage } from \"node:http\"; // cowart is the formatting string for printing the cow art. const cowart = (msg: string) => `Moo! ${msg} `; export const cowsay = api.raw( { expose: true, path: \"/cowsay\", method: \"*\" }, async (req, resp) => { const body = await getBody(req); const text = new URLSearchParams(body).get(\"text\"); const msg = cowart(text || \"Moo!\"); resp.setHeader(\"Content-Type\", \"application/json\"); resp.end(JSON.stringify({ response_type: \"in_channel\", text: msg })); }, ); // Extract the body from an incoming request. function getBody(req: IncomingMessage): Promise<string> { return new Promise((resolve) => { const bodyParts: any[] = []; req .on(\"data\", (chunk) => { bodyParts.push(chunk); }) .on(\"end\", () => { resolve(Buffer.concat(bodyParts).toString()); }); }); } \nLet's try it out locally.\n🥐 Start your app with encore run and then call it in another terminal:\n$ curl http://localhost:4000/cowsay -d 'text=Eat your greens!'\n{\"response_type\":\"in_channel\",\"text\":\"Moo! Eat your greens!\"}\nLooks great!\n🥐 Next, let's deploy it to the cloud:\n$ git add -A .\n$ git commit -m 'Initial commit'\n$ git push encore\nOnce deployed, we're ready to try our Slack command!\n🥐 Head over to the workspace you installed the app in and run /cowsay Hello there. You should see something like this:\nAnd just like that we have a fully working Slack integration.\n4. Secure the webhook endpoint\nIn order to get up and running quickly we ignored one important aspect for a production-ready Slack app: verifying that the webhook requests are actually coming from Slack. Let's do that now!\nThe Slack documentation covers this really well on the Verifying requests from Slack page.\nIn short, what we need to do is:\nSave a shared secret that Slack provides us\nUse the secret to verify that the request comes from Slack, using HMAC (Hash-based Message Authentication Code).\nSave the shared secret\nLet's define a secret using Encore's secrets management functionality.\n🥐 Add this to your slack.ts file:\nimport { secret } from \"encore.dev/config\"; const slackSigningSecret = secret(\"SlackSigningSecret\"); \n🥐 Head over to the configuration section for your Slack app (go to Your Apps → select your app → Basic Information).\n🥐 Copy the Signing Secret and then run encore secret set --type prod SlackSigningSecret and paste the secret.\n🥐 For development you will also want to set encore secret set --type dev,local,pr SlackSigningSecret. You can use the same secret value or a placeholder value.\nCompute the HMAC\nTypeScript makes computing HMAC very straightforward, but it's still a fair amount of code.\n🥐 Add a few more imports to your file, so that it reads:\nimport { createHmac, timingSafeEqual } from \"node:crypto\"; import type { IncomingHttpHeaders } from \"http\"; \n🥐 Next, we'll add the verifySignature function:\n// Verifies the signature of an incoming request from Slack. const verifySignature = async function ( body: string, headers: IncomingHttpHeaders, ) { const requestTimestampSec = parseInt( headers[\"x-slack-request-timestamp\"] as string, ); const signature = headers[\"x-slack-signature\"] as string; if (Number.isNaN(requestTimestampSec)) { throw new Error( `Failed to verify authenticity: header x-slack-request-timestamp did not have the expected type (${requestTimestampSec})`, ); } // Calculate time-dependent values const nowMs = Date.now(); const requestTimestampMaxDeltaMin = 5; const fiveMinutesAgoSec = Math.floor(nowMs / 1000) - 60 * requestTimestampMaxDeltaMin; // Enforce verification rules // Rule 1: Check staleness if (requestTimestampSec < fiveMinutesAgoSec) { throw new Error( `Failed to verify authenticity: x-slack-request-timestamp must differ from system time by no more than ${requestTimestampMaxDeltaMin} minutes or request is stale`, ); } // Rule 2: Check signature // Separate parts of signature const [signatureVersion, signatureHash] = signature.split(\"=\"); // Only handle known versions if (signatureVersion !== \"v0\") { throw new Error(`Failed to verify authenticity: unknown signature version`); } // Compute our own signature hash const hmac = createHmac(\"sha256\", slackSigningSecret()); hmac.update(`${signatureVersion}:${requestTimestampSec}:${body}`); const ourSignatureHash = hmac.digest(\"hex\"); if ( !signatureHash || !timingSafeEqual( Buffer.from(signatureHash, \"utf8\"), Buffer.from(ourSignatureHash, \"utf8\"), ) ) { throw new Error(`Failed to verify authenticity: signature mismatch`); } }; \nWe're now ready to verify the signature.\n🥐 Update the cowsay function to look like this:\nexport const cowsay = api.raw( { expose: true, path: \"/cowsay\", method: \"*\" }, async (req, resp) => { const body = await getBody(req); try { await verifySignature(body, req.headers); } catch (err) { const e = err as Error; resp.statusCode = 500; resp.end(e.message); return; } const text = new URLSearchParams(body).get(\"text\"); const msg = cowart(text || \"Moo!\"); resp.setHeader(\"Content-Type\", \"application/json\"); resp.end(JSON.stringify({ response_type: \"in_channel\", text: msg })); }, ); \n5. Put it all together and deploy\nFinally we're ready to put it all together.\n🥐 Update the cowart like so:\nconst cowart = (msg: string) => ` \\`\\`\\` +-${\"-\".repeat(msg.length)}-+ | ${msg} | +-${\"-\".repeat(msg.length)}-+ \\\\ __n__n__ .------\\`-\\\\00/-' / ## ## (oo) / \\\\## __ ./ |//YY \\\\|/ ||| ||| \\`\\`\\` `; \n🥐 Finally, let's commit our changes and deploy it:\n$ git add -A .\n$ git commit -m 'Verify webhook requests and improve art'\n$ git push encore\n🥐 Once deployed, head back to Slack and run /cowsay Hello there.\nIf everything is set up correctly, you should see:\nAnd there we go, a production-ready Slack bot in less than 100 lines of code.\nWell done!\nCelebrate with fireworks\nNow that your app is running in the cloud, let's celebrate with some fireworks:\n🥐 In the Cloud Dashboard, open the Command Menu by pressing Cmd + K (Mac) or Ctrl + K (Windows/Linux).\nFrom here you can easily access all Cloud Dashboard features and for example jump straight to specific services in the Service Catalog or view Traces for specific endpoints.\n🥐 Type fireworks in the Command Menu and press enter. Sit back and enjoy the show!"
  },
  {
    "url": "https://encore.dev/docs/tutorials/booking-system",
    "text": "Building a Booking System\nLearn how to build your own appointment booking system with both user facing and admin functionality\nIn this tutorial we'll build a booking system with a user facing UI (see available slots and book appointments) and an admin dashboard (manage scheduled appointments and set availability). You will learn how to:\nCreate API endpoints using Encore (both public and authenticated).\nWorking with PostgreSQL databases using sqlc and pgx.\nScrub sensitive user data from traces.\nWork with dates and times in Go.\nAuthenticate requests using an auth handler.\nSend emails using a SendGrid integration.\nDemo version of the app\nThe final result will look like this:\nA TypeScript tutorial for the Booking System will be available soon."
  },
  {
    "url": "https://encore.dev/docs/tutorials/meeting-notes",
    "text": "In this tutorial, we will create a backend in less than 100 lines of code. The backend will:\nStore data in a cloud SQL database\nMake API calls to a third-party service\nDeploy to the cloud and be publicly available\nThe example app we will build is a markdown meeting notes app BUT it’s trivial to replace the specifics if you have another idea in mind (again, less than 100 lines of code).\nDemo version of the app\nA TypeScript tutorial for the Meeting Notes app will be available soon."
  },
  {
    "url": "https://encore.dev/docs/go",
    "text": "Modern backend applications rely on a common set of infrastructure primitives for most of the behavior. To improve your development workflow, Encore's Go SDK lets you declare these primitives as type-safe objects in application code. Encore then takes care of running your local environments, provisioning cloud infrastructure and deploying to your cloud on AWS/GCP.\nSee how to use each primitive:\nServices and APIs\nDatabases\nCron Jobs\nPub/Sub & Queues\nCaching\nSecrets\nCheck out the Tutorials section for examples of complete Encore applications.\nBenefits of using Encore for Go\nUsing the Go SDK to declare infrastructure in application code helps unlock these benefits:\nDevelop new features locally as if the infrastructure is already set up: Encore automatically compiles your app and sets up the necessary infrastructure on the fly.\nFaster feedback loops: With type-safe infrastructure you can identify problems as early as in your code editor, instead of learning about issues via the — much slower — deployment cycle.\nNo manual maintenance required: There is no need to manually write IaC configuration, like Terraform, and no need to maintain configuration for multiple environments manually. Encore uses your application code as the source of truth and automatically keeps all environments in sync.\nOne codebase for all environments: Encore automatically provisions your local, preview, and cloud environments (using your own cloud account) on AWS/GCP.\nCloud-agnostic by default: The Infrastructure SDK is an abstraction layer on top of the cloud provider's APIs, so you avoid becoming locked in to a single cloud.\nEvolve infrastructure without code changes: As your requirements evolve, you can change and configure the provisioned infrastructure by using Encore's Cloud Dashboard or your cloud provider's console.\nSimplicity without giving up flexibility\nWhile most requirements are met by a common set of infrastructure primitives, sooner or later you will likely need something highly specific to your problem domain. Encore is designed to ensure you can use any cloud infrastructure, even if it's not built into Encore's Infrastructure SDK. This works seamlessly since Encore provisions infrastructure in your own cloud account, so you can use any of your cloud provider's services as you traditionally would."
  },
  {
    "url": "https://encore.dev/docs/ts",
    "text": "Modern backend applications rely on a common set of infrastructure primitives for most of the behavior. To improve your development workflow, Encore's TypeScript SDK lets you declare these primitives as type-safe objects in application code. Encore then takes care of running your local environments, provisioning cloud infrastructure, and deploying to your cloud on AWS/GCP.\nSee how to use each primitive:\nServices and APIs\nDatabases\nCron Jobs\nPub/Sub & Queues\nSecrets\nCheck out the Tutorials section for examples of complete Encore applications.\nBenefits of using Encore for TypeScript\nUsing the TypeScript SDK to declare infrastructure in application code helps unlock these benefits:\nDevelop new features locally as if the infrastructure is already set up: Encore automatically compiles your app and sets up the necessary infrastructure on the fly.\nFaster feedback loops: With type-safe infrastructure you can identify problems as early as in your code editor, instead of learning about issues via the — much slower — deployment cycle.\nNo manual maintenance required: There is no need to manually write IaC configuration, like Terraform, and no need to maintain configuration for multiple environments manually. Encore uses your application code as the source of truth and automatically keeps all environments in sync.\nOne codebase for all environments: Encore automatically provisions your local, preview, and cloud environments (using your own cloud account) on AWS/GCP.\nCloud-agnostic by default: The Infrastructure SDK is an abstraction layer on top of the cloud provider's APIs, so you avoid becoming locked in to a single cloud.\nEvolve infrastructure without code changes: As your requirements evolve, you can change and configure the provisioned infrastructure by using Encore's Cloud Dashboard or your cloud provider's console.\nSimplicity without giving up flexibility\nWhile most requirements are met by a common set of infrastructure primitives, sooner or later you will likely need something highly specific to your problem domain. Encore is designed to ensure you can use any cloud infrastructure, even if it's not built into Encore's Infrastructure SDK. This works seamlessly since Encore provisions infrastructure in your own cloud account, so you can use any of your cloud provider's services as you traditionally would."
  },
  {
    "url": "https://encore.dev/docs/develop/cli-reference",
    "text": "Running\nRun\nRuns your application.\n$ encore run [--debug] [--watch=true] [flags]\nTest\nTests your application\nTakes all the same flags as go test.\n$ encore test ./... [go test flags]\nCheck\nChecks your application for compile-time errors using Encore's compiler.\n$ encore check\nApp\nCommands to create and link Encore apps\nClone\nClone an Encore app to your computer\n$ encore app clone [app-id] [directory]\nCreate\nCreate a new Encore app\n$ encore app create [name]\nLink\nLink an Encore app with the server\n$ encore app link [app-id]\nAuth\nCommands to authenticate with Encore\nLogin\nLog in to Encore\n$ encore auth login\nLogout\nLogs out the currently logged in user\n$ encore auth logout\nSignup\nCreate a new Encore account\n$ encore auth signup\nWhoami\nShow the current logged in user\n$ encore auth whoami\nDaemon\nEncore CLI daemon commands\nRestart\nIf you experience unexpected behavior, try restarting the daemon using:\n$ encore daemon\nEnv\nOutputs Encore environment information\n$ encore daemon env\nDatabase Management\nDatabase management commands\nConnect to database via shell\nConnects to the database via psql shell\nDefaults to connecting to your local environment. Specify --env to connect to another environment.\n$ encore db shell <database-name> [--env=<name>]\nConnection URI\nOutputs a database connection string for <database-name>. Defaults to connecting to your local environment. Specify --env to connect to another environment.\n$ encore db conn-uri <database-name> [--env=<name>] [flags]\nProxy\nSets up local proxy that forwards any incoming connection to the databases in the specified environment.\n$ encore db proxy [--env=<name>] [flags]\nReset\nResets the databases for the given services. Use --all to reset all databases.\n$ encore db reset [service-names...] [flags]\nCode Generation\nCode generation commands\nGenerate client\nGenerates an API client for your app. For more information about the generated clients, see this page.\nBy default generates the API based on your primary environment. Use '--env=local' to generate it based on your local development version of the app.\nSupported language codes are:\ngo: A Go client using the net/http package\ntypescript: A TypeScript client using the in-browser Fetch API\njavascript: A JavaScript client using the in-browser Fetch API\n$ encore gen client <app-id> [--env=prod] [flags]\nLogs\nStreams logs from your application\n$ encore logs [--env=prod] [--json]\nSecrets Management\nSecret management commands\nSet\nSets a secret value\n$ encore secret set --type <types> <secret-name>\nWhere <types> defines which environment types the secret value applies to. Use a comma-separated list of production, development, preview, and local. Shorthands: prod, dev, pr.\nExamples\nEntering a secret directly in terminal:\n$ encore secret set --type dev MySecret Enter secret value: ... Successfully created secret value for MySecret. \nPiping a secret from a file:\n$ encore secret set --type dev,local MySecret < my-secret.txt Successfully created secret value for MySecret. \nNote that this strips trailing newlines from the secret value.\nVersion\nReports the current version of the encore application\n$ encore version\nUpdate\nChecks for an update of encore and, if one is available, runs the appropriate command to update it.\n$ encore version update\nVPN\nVPN management commands\nStart\nSets up a secure connection to private environments\n$ encore vpn start\nStatus\nDetermines the status of the VPN connection\n$ encore vpn status\nStop\nStops the VPN connection\n$ encore vpn stop"
  },
  {
    "url": "https://encore.dev/docs/develop/client-generation",
    "text": "Encore makes it simple to write scalable distributed backends by allowing you to make function calls that Encore translates into RPC calls. Encore also generates API clients with interfaces that look like the original Go functions, with the same parameters and response signature as the server.\nThe generated clients are single files that use only the standard functionality of the target language, with full type safety. This allow anyone to look at the generated client and understand exactly how it works.\nThe structure of the generated code varies by language, to ensure it's idiomatic and easy to use, but always includes all publicly accessible endpoints, data structures, and documentation strings.\nEncore currently supports generating the following clients:\nGo - Using net/http for the underlying HTTP transport.\nTypeScript - Using the browser fetch API for the underlying HTTP client.\nJavaScript - Using the browser fetch API for the underlying HTTP client.\nOpenAPI - Using the OpenAPI Specification's language-agnostic interface to HTTP APIs. (Experimental)\nIf there's a language you think should be added, please submit a pull request or create a feature request on GitHub, or reach out on Discord.\nTake care\nIf you ship the generated client to end customers, keep in mind that old clients will continue to be used after you make changes. To prevent issues with the generated clients, avoid making breaking changes in APIs that your clients access.\n\nGenerating a Client\nTo generate a client, use the encore gen client command. It generates a type-safe client using the most recent API metadata running in a particular environment for the given Encore application. For example:\n# Generate a TypeScript client for calling the hello-a8bc application based on the primary environment\nencore gen client hello-a8bc --output=./client.ts\n# Generate a Go client for the hello-a8bc application based on the locally running code\nencore gen client hello-a8bc --output=./client.go --env=local\n# Generate an OpenAPI client for the hello-a8bc application based on the primary environment\nencore gen client hello-a8bc --lang=openapi --output=./openapi.json\nEnvironment Selection\nBy default, encore gen client generates the client for the version of the application currently deployed on the primary environment of your application. You can change this using the --env flag and specifying the environment name.\nIf you want to generate the client for the version of your application you have local running, then you can use the special environment name local (you'll need to be running the application first).\nPlease note\nThe generated client can be used with any environment, not just the one it was generated for. However, the APIs, data structures and marshalling logic will be based on whatever is present and running in that environment at the point in time the client is generated.\nService filtering\nBy default encore gen client outputs code for all services with at least one publicly accessible (or authenticated) API. You can narrow down this set of services by specifying the --services (or -s) flag. It takes a comma-separated list of service names.\nFor example, to generate a typescript client for the email and users services, run:\nencore gen client --services=email,users -o client.ts\nOutput Mode\nBy default the client's code will be output to stdout, allowing you to pipe it into your clipboard, or another tool. However, using --output you can specify a file location to write the client to. If output is specified, you do not need to specify the language as Encore will detect the language based on the file extension.\nExample Script\nYou could combine this into a package.json file for your Typescript frontend, to allow you to run npm run gen in that project to update the client to match the code running in your staging environment.\n{ \"scripts\": { // ... \"gen\": \"encore gen client hello-a8bc --output=./client.ts --env=staging\" // ... } } \nUsing the Client\nThe generated client has all the data structures required as parameters or returned as response values as needed by any of the public or authenticated API's of your Encore application. Each service is exposed as object on the client, with each public or authenticated API exposed as a function on those objects.\nFor instance, if you had a service called email with a function Send, on the generated client you would call this using; client.email.Send(...).\nFor more tips and examples of using a generated JavaScript/Typescript client, see the Integrate with a web frontend docs.\nCreating an instance\nWhen constructing a client, you need to pass a BaseURL as the first parameter; this is the URL at which the API can be accessed. The client provides two helpers:\nLocal - This is a constant provided, which will always point at your locally running instance environment.\nEnvironment(\"name\") - This is a function which allows you to specify an environment by name\nHowever, BaseURL is a string, so if the two helpers do not provide enough flexibility you can pass any valid URL to be used as the BaseURL.\nAuthentication\nIf your application has any API's which require authentication, then additional options will generated into the client, which can be used when constructing the client. Just like with API's schemas, the data type required by your application's auth handler will be part of the client library, allowing you to set it in two ways:\nIf your credentials won't change during the lifetime of the client, simply passing the authentication data to the client through the WithAuth (Go) or auth (TypeScript) options.\nHowever, if the authentication credentials can change, you can also pass a function which will be called before each request and can return a new instance of the authentication data structure or return the existing instance.\nHTTP Client Override\nIf required, you can override the underlying HTTP implementation with your own implementation. This is useful if you want to perform logging of the requests being made, or route the traffic over a secured tunnel such as a VPN.\nIn Go this can be configured using the WithHTTPClient option. You are required to provide an implementation of the HTTPDoer interface, which the http.Client implements. For TypeScript clients, this can be configured using the fetcher option and must conform to the same prototype as the browsers inbuilt fetch API.\nStructured Errors\nErrors created or wrapped using Encore's errs package will be returned to the client and deserialized as an APIError, allowing the client to perform adaptive error handling based on the type of error returned. You can perform a type check on errors caused by calling an API to see if it is an APIError, and once cast as an APIError you can access the Code, Message and Details fields. For TypeScript Encore generates a isAPIError type guard which can be used.\nThe Code field is an enum with all the possible values generated in the library, alone with description of when we would expect them to be returned by your API. See the errors documentation for an online reference of this list.\nFor instance, we could build a simple CLI application to use our url shortener, and handle any structured errors in a way which makes sense for that error code.\npackage main import ( \"context\" \"fmt\" \"os\" \"time\" \"shorten_cli/client\" ) func main() { // Create a new client with the default BaseURL client, err := client.New( client.Environment(\"production\"), client.WithAuth(os.Getenv(\"SHORTEN_API_KEY\")), ) if err != nil { panic(err) } // Timeout if the request takes more than 5 seconds ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second) defer cancel() // Call the Shorten function in the URL service resp, err := client.Url.Shorten( ctx, client.UrlShortenParams{ URL: os.Args[1] }, ) if err != nil { // Check the error returned if err, ok := err.(*client.APIError); ok { switch err.Code { case client.ErrUnauthenticated: fmt.Println(\"SHORTEN_API_KEY was invalid, please check your environment\") os.Exit(1) case client.ErrAlreadyExists: fmt.Println(\"The URL you provided was already shortened\") os.Exit(0) } } panic(err) // if here then something has gone wrong in an unexpected way } fmt.Printf(\"https://short.encr.app/%s\", resp.ID) }"
  },
  {
    "url": "https://encore.dev/docs/develop/infra-namespaces",
    "text": "Encore's CLI allows you to create and switch between multiple, independent infrastructure namespaces. Infrastructure namespaces are isolated from each other, and each namespace contains its own independent data.\nThis makes it trivial to switch tasks, confident your old state and data will be waiting for you when you return.\nIf you've ever worked on a new feature that involves making changes to the database schema, only to context switch to reviewing a Pull Request and had to reset your database, you know the feeling.\nWith Encore's infrastructure namespaces, this is a problem of the past. Run encore namespace switch --create pr:123 (or encore ns switch -c pr:123 for short) to create and switch to a new namespace.\nThe next encore run will run in the new namespace, with a completely fresh database. When you're done, run encore namespace switch - to switch back to your previous namespace.\nUsage\nBelow are the commands for working with namespaces. Note that you can use encore ns as a short form for encore namespace.\n# List your namespaces (* indicates the current namespace)\n$ encore namespace list\n# Create a new namespace\n$ encore namespace create my-ns\n# Switch to a namespace\n$ encore namespace switch my-ns\n# Switch to a namespace, creating it if it doesn't exist\n$ encore namespace switch --create my-ns\n# Switch to the previous namespace\n$ encore namespace switch -\n# Delete a namespace (and all associated data)\n$ encore namespace delete my-ns\nMost other Encore commands that interact or use infrastructure take an optional --namespace (-n for short) that overrides the current namespace. If left unspecified, the current namespace is used.\nFor example:\n# Run the app using the \"my-ns\" namespace\n$ encore run --namespace my-ns\n# Open a database shell to the \"my-ns\" namespace\n$ encore db shell DATABASE_NAME --namespace my-ns\n# Reset all databases within the \"my-ns\" namespace\n$ encore db reset --all --namespace my-ns"
  },
  {
    "url": "https://encore.dev/docs/observability/dev-dash",
    "text": "Encore provides an efficient local development workflow that automatically provisions local infrastructure and supports automated testing with dedicated test infrastructure.\nThe local environment also comes with a built-in Local Development Dashboard to simplify development and improve productivity. It has several features to help you design, develop, and debug your application:\nService Catalog and API Explorer for easily making API calls to your local backend\nDistributed Tracing for simple and powerful debugging\nAutomatic API Documentation for knowledge sharing and answering questions\nEncore Flow for visualizing your microservices architecture\nAll these features update in real-time as you make changes to your application.\nTo access the dashboard, start your Encore application with encore run and it opens automatically. You can also follow the link in your terminal:\n$ encore run API Base URL: http://localhost:4000 Dev Dashboard URL: http://localhost:9400/hello-world-cgu2"
  },
  {
    "url": "https://encore.dev/docs/observability/encore-flow",
    "text": "Flow is a visual tool that gives you an always up-to-date view of your entire system, helping you reason about your microservices architecture and identify which services depend on each other and how they work together.\nBirds-eye view\nHaving access to a zoomed out representation of your system can be invaluable in pretty much all parts of the development cycle. Flow helps you:\nTrack down bottlenecks before they grow into big problems.\nGet new team members onboarded much faster.\nPinpoint hot paths in your system, services that might need extra attention.\nServices and PubSub topics are represented as boxes, arrows indicate a dependency. In the example below the login service has dependencies on the user and authentication services. Dashed arrows shows publications or subscriptions to a topic. Here, payment publishes to the payment-made topic and email subscribe to it:\nHighlight dependencies\nHover over a service, or PubSub topic, to instantly reveal the nature and scale of its dependencies.\nHere the login service and its dependencies are highlighted. We can see that login makes queries to the database and requests to two of the endpoints from the user service as well as requests to one endpoint from the authentication service:\nReal-time updates\nFlow is accessible in the Local Development Dashboard and the Cloud Dashboard for cloud environments.\nWhen developing locally, Flow will auto update in real-time to reflect your architecture as you make code changes. This helps you be mindful of important dependencies and makes it clear if you introduce new ones.\nFor cloud environments, Flow auto-updates with each deploy.\nIn the example below a new subscription on the topic payment-made is introduced and then removed in user service:"
  },
  {
    "url": "https://encore.dev/docs/observability/logging",
    "text": "Encore offers built-in support for Structured Logging, which combines a free-form log message with structured and type-safe key-value pairs. This enables straightforward analysis of what your application is doing, in a way that is easy for a computer to parse, analyze, and index. This makes it simple to quickly filter and search through logs.\nEncore’s logging is integrated with the built-in Distributed Tracing functionality, and all logs are automatically included in the active trace. This dramatically simplifies debugging of your application.\nUsage\nFirst, import encore.dev/rlog in your package. Then simply call one of the package methods Info, Error, or Debug. For example:\nrlog.Info(\"log message\", \"user_id\", 12345, \"is_subscriber\", true) rlog.Error(\"something went terribly wrong!\", \"err\", err) \nThe first parameter is the log message. After that follows zero or more key-value pairs for structured logging for context.\nIf you’re logging many log messages with the same key-value pairs each time it can be a bit cumbersome. To help with that, use rlog.With() to group them into a context object, which then copies the key-value pairs into each log event:\nctx := rlog.With(\"user_id\", 12345) ctx.Info(\"user logged in\", \"is_subscriber\", true) // includes user_id=12345 \nFor more information, see the API Documentation.\nLive-streaming logs\nEncore also makes it simple to live-stream logs directly to your terminal, from any environment, by running:"
  },
  {
    "url": "https://encore.dev/docs/observability/metrics",
    "text": "Having easy access to key metrics is a critical part of application observability. Encore solves this by providing automatic dashboards of common application-level metrics for each service.\nEncore also makes it easy to define custom metrics for your application. Once defined, custom metrics are automatically displayed on metrics page in the Cloud Dashboard.\nBy default, Encore also exports metrics data to your cloud provider's built-in monitoring service.\nDefining custom metrics\nDefine custom metrics by importing the encore.dev/metrics package and create a new metric using one of the metrics.NewCounter or metrics.NewGauge functions.\nFor example, to count the number of orders processed:\nimport \"encore.dev/metrics\" var OrdersProcessed = metrics.NewCounter[uint64](\"orders_processed\", metrics.CounterConfig{}) func process(order *Order) { // ... OrdersProcessed.Increment() } \nMetric types\nEncore currently supports two metric types: counters and gauges.\nCounters, like the name suggests, measure the count of something. A counter's value must always increase, never decrease. (Note that the value gets reset to 0 when the application restarts.) Typical use cases include counting the number of requests, the amount of data processed, and so on.\nGauges measure the current value of something. Unlike counters, a gauge's value can fluctuate up and down. Typical use cases include measuring CPU usage, the number of active instances running of a process, and so on.\nFor information about their respective APIs, see the API documentation for Counter and Gauge.\nDefining labels\nEncore's metrics package provides a type-safe way of attaching labels to metrics. To define labels, create a struct type representing the labels and then use metrics.NewCounterGroup or metrics.NewGaugeGroup:\ntype Labels struct { Success bool } var OrdersProcessed = metrics.NewCounterGroup[Labels, uint64](\"orders_processed\", metrics.CounterConfig{}) func process(order *Order) { var success bool // ... populate success with true/false ... OrdersProcessed.With(Labels{Success: success}).Increment() } \nTake care\nEach combination of label values creates a unique time series tracked in memory and stored by the monitoring system. Using numerous labels can lead to a combinatorial explosion, causing high cloud expenses and degraded performance.\nAs a general rule, limit the unique time series to tens or hundreds at most, rather than thousands.\nIntegrations with third party observability services\nTo make it easy to use a third party service for monitoring, we're adding direct integrations between Encore and popular observability services. This means you can send your metrics directly to these third party services instead of your cloud provider's monitoring service.\nGrafana Cloud\nTo send metrics data to Grafana Cloud, you first need to Add a Grafana Cloud Stack to your application.\nOpen your application on app.encore.dev, and click on Settings in the main navigation. Then select Grafana Cloud in the settings menu and click on Add Stack.\nNext, open the environment Overview for the environment you wish to sent metrics from and click on Settings. Then in the Sending metrics data section, select your Grafana Cloud Stack from the drop-down and save.\nThat's it! After your next deploy, Encore will start sending metrics data to your Grafana Cloud Stack.\nDatadog\nTo send metrics data to Datadog, you first need to add a Datadog Account to your application.\nOpen your application on app.encore.dev, and click on Settings in the main navigation. Then select Datadog in the settings menu and click on Add Account.\nNext, open the environment Overview for the environment you wish to sent metrics from and click on Settings. Then in the Sending metrics data section, select your Datadog Account from the drop-down and save.\nThat's it! After your next deploy, Encore will start sending metrics data to your Datadog Account."
  },
  {
    "url": "https://encore.dev/docs/observability/tracing",
    "text": "Distributed systems often have many moving parts, making it difficult to understand what your code is doing and finding the root-cause to bugs. That’s where Tracing comes in. If you haven’t seen it before, it may just about change your life.\nTracing is a revolutionary way to gain insight into what your applications are doing. It works by capturing the series of events as they occur during the execution of your code (a “trace”). This works by propagating a trace id between all individual systems, then correlating and joining the information together to present a unified picture of what happened end-to-end.\nAs opposed to the labor intensive instrumentation you'd normally need to go through to use tracing, Encore automatically captures traces for your entire application – in all environments. Uniquely, this means you can use tracing even for local development to help debugging and speed up iterations.\nYou view traces in the Local Development Dashboard and in the Cloud Dashboard for Production and other environments.\nUnlike other tracing solutions, Encore understands what each trace event is and captures unique insights about each one. This means you get access to more information than ever before:\nStack traces\nStructured logging\nHTTP requests\nNetwork connection information\nAPI calls\nDatabase queries\netc.\nRedacting sensitive data\nEncore's tracing automatically captures request and response payloads to simplify debugging.\nFor cases where this is undesirable, such as for passwords or personally identifiable information (PII), Encore supports redacting fields marked as containing sensitive data.\nSee the documentation on API Schemas for more information."
  },
  {
    "url": "https://encore.dev/docs/deploy/deploying",
    "text": "Encore simplifies the deployment process, making it as straightforward as a git push. Encore's built-in integration with Git and GitHub, automated CI/CD pipeline, and automatic provisioning of Preview Environments and cloud infrastructure, is designed to speed up development and remove manual steps.\nSetting Up Your Encore Application\nCreate your Application: If you haven't already, create an application using the Encore CLI. This automatically creates a new git repository managed by Encore.\n$ encore app create\nIntegrate with GitHub (Optional): If you prefer to use GitHub, you can integrate your app with GitHub. This way, you can push code to GitHub, which triggers Encore's deployment process. This is especially handy for teams as it enables collaborative development, version control, and other GitHub functionality.\nDeploying Your Application\nWith Encore, deploys are triggered simply by pushing changes to the connected Git repository.\nIf you are using Encore's Git, run the following command to deploy your application:\n$ git add -A .\n$ git commit -m 'Commit message'\n$ git push encore\nIf you are using GitHub, a standard git push to your repository will work:\n$ git add -A .\n$ git commit -m 'Commit message'\n$ git push origin\nIn both scenarios, this will trigger Encore's built-in CI/CD pipeline. This includes building your application, running tests, provisioning the necessary infrastructure, and deploying your application.\nConfigure deploy trigger\nWhen using GitHub, you can configure Encore to automatically trigger deploys when you push to a specific branch name.\nTo configure which branch name is used to trigger deploys, open your app in the Cloud Dashboard and go to the Overview page for your intended environment. Click on Settings and then in the section Branch Push configure the Branch name and hit save.\nPreview Environments\nWhen you connect your GitHub account and push changes to a pull request, Encore will automatically create a Preview Environment. This is a fully functional, isolated environment where you can test your application as it would run in production. This environment runs in Encore's free development cloud, giving you an efficient way to validate your changes before they are merged and deployed to the primary environment.\nCustom build settings\nYou can override certain aspects of the CI/CD process in the encore.app file:\nThe Docker base image to use when deploying\nWhether to build with Cgo enabled\nWhether to bundle the source code in the docker image (useful for Sentry stack traces)\nBelow are the available build settings configurable in the encore.app file, with their default values:\n{ \"build\": { // Enables cgo when building the application and running tests // in Encore's CI/CD system. \"cgo_enabled\": false, // Docker-related configuration \"docker\": { // The Docker base image to use when deploying the application. // It must be a publicly accessible image, and defaults to \"scratch\". \"base_image\": \"scratch\", // Whether to bundle the source code in the docker image. // The source code will be copied into /workspace as part // of the build process. This is primarily useful for tools like // Sentry that need access to the source code to generate stack traces. \"bundle_source\": false } } }"
  },
  {
    "url": "https://encore.dev/docs/deploy/environments",
    "text": "Encore makes it simple to create the environments you need to build your application with confidence: local, preview, testing, and production. Each environment is an isolated fully working instance of your backend, automatically provisioned by Encore.\nEnvironments always stay in sync, as they are created based on the needs of your application, using the Encore Application Model. Environments are provisioned using contextually appropriate infrastructure depending on the type of environment.\nCreating environments\nTo create an environment for your app, open your app in the Cloud Dashboard and go to the Environments page, then click on Create env in the top right.\nThere you can pick a name, and decide if you want a production or development environment (see Environment Types below).\nYou can also choose how you would like to trigger deploys for the environment (either by pushing to a Git branch or manually), and if you want to manually approve infrastructure changes.\nFinally, select which cloud provider you want to deploy to (see the Cloud Providers documentation to learn more) and decide which type of process allocation you want: should all services be deployed to one process or separately?\nClick Create and you're done!\nEnvironment Types\nEncore has four types of environments:\nproduction\ndevelopment\npreview\nlocal\nSome environment types differ in how infrastructure is provisioned:\npreview environments are provisioned in Encore Cloud and are optimized to be cost-efficient and fast to provision.\nlocal is provisioned by Encore's CLI using local versions of infrastructure.\nAside from determining infrastructure, environment type is also used for Secrets management.\nLocal environment\nWhen you've installed the Encore CLI, you start your local environment by simply running encore run. This builds and tests your application, and provisions all the necessary infrastructure to run your application locally (see the infra docs to learn exactly how local infrastructure is provisioned).\nBy default, the local environment runs on http://localhost:4000.\nPreview environments\nWhen you connect your application to GitHub, Encore will automatically provision ephemeral Preview Environments for each Pull Request. See the Preview Environments documentation to learn more.\nFrontend Collaboration\nPreview Environments make it really easy to collaborate and test changes with your frontend. Just update your frontend API client to point to the pr:# environment. This is a one-line change since your API client always specifies the environment name, e.g. https://<env>-<my-app>.encr.app/.\nIf your pull request makes changes to the API, you can generate a new API client for the new backend API using encore gen client --env=pr:72 --lang=typescript my-app\nCloud environments\nEncore makes it simple to create multiple cloud environments in different cloud providers by connecting your cloud account(s). Cloud environments can be created as Development, or Production, depending on your use case (see the infra docs to learn exactly what infrastructure is provisioned in each cloud).\nProcess Allocation\nJust because you want to deploy each service separately in some environments, doesn't mean you want to do it in all environments.\nHandily, Encore lets you decide how you want to deploy your services for cloud environments. You don't need to change a single line of code.\nWhen you create an environment, you decide which process allocation you want for that environment.\nPlease note\nDeploying services as separate processes is not yet supported when using AWS Fargate. For multi-process deployments, select AWS EKS or GCP CloudRun / GKE.\nPrimary environment\nEncore application's have a primary environment that is used as the default environment for functionality like viewing API documentation or app insights in the Cloud Dashboard, and as the default for CLI functionality like API client generation. It should generally reflect what you consider to be the main 'production' environment.\nTo configure which environment should be used as the primary environment, open your app in the Cloud Dashboard, go to Settings > General > Primary Environment, then select the environment you want from the dropdown and click Update."
  },
  {
    "url": "https://encore.dev/docs/develop/api-docs",
    "text": "Automatically get a Service Catalog and complete API docs\nAll developers agree API documentation is great to have, but the effort of maintaining it inevitably leads to docs becoming stale and out of date.\nTo solve this, Encore uses the Encore Application Model to automatically generate a Service Catalog along with complete documentation for all APIs. This ensures docs are always up-to-date as your APIs evolve.\nThe API docs are available both in your local dev dash and for your whole team in the Cloud Dashboard."
  },
  {
    "url": "https://encore.dev/docs/deploy/preview-environments",
    "text": "When you connect your application to GitHub, Encore will begin to automatically provision ephemeral Preview Environments for each Pull Request. Preview Environments are fully functional, isolated, environments where you can test your application as it would run in production.\nPreview Environments are named after the pull request, for example PR #72 creates a Preview Environment named pr:72 with the API base url https://pr72-$APP_ID.encr.app.\nYou can also view the environment in the Cloud Dashboard, where the url will be https://app.encore.dev/$APP_ID/envs/pr:72.\nPreview Infrastructure\nPreview Environments run in Encore's free development cloud, removing the need to manually manage and pay for your own sandbox environments. This gives you a cost-efficient way to validate your changes before they are merged and deployed to the primary environment.\nSee the infra docs if you're curious about exactly how Preview Environments are provisioned.\nFrontend Collaboration\nPreview Environments make it really easy to collaborate and test changes with your frontend. Just update your frontend API client to point to the pr:# environment. This is a one-line change since your API client always specifies the environment name, e.g. https://<env>-<my-app>.encr.app/.\nIf your pull request makes changes to the API, you can generate a new API client for the new backend API using encore gen client --env=pr:72 --lang=typescript my-app"
  },
  {
    "url": "https://encore.dev/docs/deploy/infra",
    "text": "Encore automatically provisions all necessary infrastructure, in all environments and across all major cloud providers, without requiring application code changes. You simply connect your cloud account and create an environment.\nThis is powered by Encore's Infrastructure SDK, which lets you declare infrastructure resources (databases, caches, queues, scheduled jobs, etc.) as type-safe objects in application code.\nAt compile time, Encore creates an Application Model with a definition of the infrastructure your application requires. Encore then uses this model to provision the infrastructure in both your cloud account, and development and preview environments in Encore Cloud.\nThe approach removes the need for infrastructure configuration files and avoids creating cloud-specific dependencies in your application.\nHaving an end-to-end integration between application code and infrastructure also enables Encore to keep environments in sync and track cloud infrastructure, giving you an up-to-date view of your infrastructure to avoid unnecessary cloud costs.\nEnvironment types\nBy default, Encore provisions infrastructure using contextually appropriate objectives for each environment type. You retain control over the infrastructure in your cloud account, and can configure it directly both via Encore's Cloud Dashboard and your cloud provider's console. Encore takes care of syncing your changes.\nLocalEncore CloudGCP / AWS\nEnvironment types:\tDevelopment\tPreview, Development\tDevelopment, Production\t\nObjectives:\tProvisioning speed\tProvisioning speed, Cost*\tReliability, Security, Scalability\t\n*Encore Cloud is free to use, subject to Fair Use guidelines and usage limits. Learn more\nDevelopment Infrastructure\nEncore provisions infrastructure resources differently for each type of development environment.\nLocalPreview / Development (Encore Cloud)GCP / AWS\nSQL Databases:\tDocker\tEncore Managed (Kubernetes), Neon\tSee production\t\nPub/Sub:\tIn-memory (NSQ)\tGCP Pub/Sub\tSee production\t\nCaches:\tIn-memory (Redis)\tIn-memory (Redis)\tSee production\t\nCron Jobs:\tDisabled\tEncore Managed\tSee production\t\nLocal Development\nFor local development Encore provisions a combination of Docker and in-memory infrastructure components. SQL Databases are provisioned using Docker. For Pub/Sub and Caching the infrastructure is run in-memory. \nWhen running tests, a separate SQL Database cluster is provisioned that is optimized for high performance (using an in-memory filesystem and fsync disabled) at the expense of reduced reliability.\nTo avoid surprises during development, Cron Jobs are not triggered in local environments. They can always be triggered manually by calling the API directly from the development dashboard.\nThe application code itself is compiled and run natively on your machine (without Docker).\nPreview Environments\nWhen you've connected your application to GitHub, Encore automatically provisions a temporary Preview Environment for each Pull Request.\nPreview Environments are created in Encore Cloud, and are optimized for provisioning speed and cost-effectiveness. The Preview Environment is automatically destroyed when the Pull Request is merged or closed.\nPreview Environments are named after the pull request, so PR #72 will create an environment named pr:72.\nEncore Cloud\nEncore Cloud is a simple, zero-configuration hosting solution provided by Encore. It's perfect for development environments and small-scale use that do not require any specific SLAs. It's also a great way to evaluate Encore without needing to connect your cloud account.\nEncore Cloud is not designed for business-critical use and does not offer reliability guarantees for persistent storage like SQL Databases. Other infrastructure primitives like Pub/Sub and Caching are provisioned with small-scale use in mind.\nLearn more about the usage limitations\nProduction Infrastructure\nEncore provisions production infrastructure resources using best-practice guidelines and services for each respective cloud provider.\nGCPAWS\nNetworking:\tVPC\tVPC\t\nCompute:\tCloud Run, GKE\tFargate ECS, EKS\t\nSQL Databases:\tGCP Cloud SQL, Neon\tAmazon RDS, Neon\t\nPub/Sub:\tGCP Pub/Sub\tAmazon SQS & Amazon SNS\t\nCaches:\tGCP Memorystore (Redis)\tAmazon ElastiCache (Redis)\t\nCron Jobs:\tEncore Managed\tEncore Managed\t\nSecrets:\tSecret Manager\tAWS Secrets Manager\t\nConfigurability\nWith Encore you do not define any cloud service specifics in the application code. This means that after deploying, you can safely use your cloud provider's console to modify the provisioned resources, or use the built-in configuration UI in Encore's Cloud Dashboard. Encore takes care of syncing the changes automatically in both directions.\nIn the future, Encore will offer automated optimization of cloud environments according to your application's real-world behavior.\nProcess allocation\nYou can configure how microservices should be deployed on the compute hardware; either deploying all services in one process or one process per service.\nIt's often recommended to deploy all services in one process in order to reduce costs and minimize response times between services. (But it depends on your use case.) Deploying each service as its own process will improve scalability and decrease blast radius if things go wrong. This is only recommended for production environments.\nGoogle Cloud Platform (GCP)\nEncore provisions a single GCP Project for each environment, containing a single Virtual Private Cloud (VPC), and a whole slew of miscellaneous resources (IAM roles, policies, subnets, security groups, route tables, and so on). Secrets are stored using Secret Manager.\nCompute instances\nWhen using GCP you can decide between Cloud Run (a fully managed infrastructure that scales to zero) or a Google Kubernetes Engine (GKE) cluster. If you prefer you can also import an existing Kubernetes cluster and have Encore deploy to it.\nSQL Databases\nWhen using SQL Databases, Encore provisions a single GCP Cloud SQL cluster, and separate databases within that cluster. The cluster is configured with the latest PostgreSQL version available at the time of provisioning.\nThe machine type is chosen as the smallest available that supports auto-scaling (1 vCPU / 3.75GiB memory). You can freely increase the machine type yourself to handle larger scales.\nAdditionally, Encore sets up:\nAutomatic daily backups (retained for 7 days) with point-in-time recovery\nPrivate networking, ensuring the database is only accessible from the VPC\nMutual TLS encryption for additional security\nHigh availability mode with automatic failover (via disk replication to multiple zones)\nPub/Sub\nWhen using Pub/Sub, Encore provisions GCP Pub/Sub topics and subscriptions. Additionally, Encore automatically creates and configures dead-letter topics.\nCaching\nWhen using Caching, Encore provisions GCP Memorystore for Redis clusters.\nThe machine type is chosen as the smallest available that supports auto-scaling (5GiB memory, with one read replica). You can freely change the machine type yourself to handle larger scales.\nAdditionally, Encore sets up:\nRedis authentication\nTransit encryption with TLS for additional security\nA 10% memory buffer to better memory fragmentation, and active defragmentation\nCron Jobs\nWhen using Cron Jobs, Encore Cloud triggers the execution of cron jobs by calling the corresponding API using a signed request so the application can verify the source of the request as coming from Encore's cron functionality. No infrastructure is provisioned for this to work.\nAmazon Web Services (AWS)\nEncore provisions a dedicated Virtual Private Cloud (VPC) for each environment. It contains an Elastic Container Registry to host Docker images, and a whole slew of miscellaneous resources (IAM roles, policies, subnets, security groups, route tables, and so on). Secrets are stored using Secrets Manager.\nCompute instances\nEncore provisions a Fargate ECS cluster (managed, serverless, pay-as-you-go compute engine) or an Elastic Kubernetes Service (EKS) cluster.\nSQL Databases\nWhen using SQL Databases, Encore provisions a single Amazon RDS cluster, and separate databases within that cluster. The cluster is configured with the latest PostgreSQL version available at the time of provisioning.\nThe instance type is chosen as the smallest available latest-generation type that supports auto-scaling (currently db.m5.large, with 2 vCPU / 8GiB memory). You can freely change the instance type yourself to handle larger scales.\nAdditionally, Encore sets up:\nAutomatic daily backups (retained for 7 days) with point-in-time recovery\nPrivate networking, ensuring the database is only accessible from the VPC\nDedicated subnets for the database instances, with security group rules to secure them\nPub/Sub\nWhen using Pub/Sub, Encore provisions a combination of Amazon SQS and Amazon SNS topics and subscriptions. Additionally, Encore automatically creates and configures dead-letter topics.\nCaching\nWhen using Caching, Encore provisions Amazon ElastiCache for Redis clusters.\nThe machine type is chosen as the smallest available that supports auto-scaling (currently cache.m6g.large, with one read replica). You can freely change the machine type yourself to handle larger scales.\nAdditionally, Encore sets up:\nRedis ACL authentication\nA replication group, with multi-AZ replication and automatic failover for high availability\nTransit encryption with TLS for additional security\nA 10% memory buffer to better memory fragmentation, and active defragmentation\nCron Jobs\nWhen using Cron Jobs, Encore Cloud triggers the execution of cron jobs by calling the corresponding API using a signed request so the application can verify the source of the request as coming from Encore's cron functionality. No infrastructure is provisioned for this to work."
  },
  {
    "url": "https://encore.dev/docs/deploy/kubernetes/kubectl",
    "text": "Encore automatically provisions and manages Kubernetes clusters for you, but sometimes it's useful to manually inspect clusters using the kubectl cli. To do this, you need to configure kubectl to connect and authenticate through encore. You can do this by running the following command in your app directory:\nencore kubernetes configure -e <environment>\nWhere <environment> is the name of the environment you want to configure kubectl for.\nThis will configure kubectl to use encore to authenticate the cluster and proxy your traffic to the correct cluster. You can now use kubectl as you normally would, for example:\nkubectl get pods"
  },
  {
    "url": "https://encore.dev/docs/deploy/kubernetes",
    "text": "When you build your app using Encore's Infrastructure SDK, you can deploy the same code to many different types of cloud infrastructure. Encore will automatically handle provisioning different infrastructure for each environment — depending on your goals. Configuring what type of compute platform you want is done through the Cloud Dashboard rather than in the application code.\nIf you already have a Kubernetes cluster, you may want to deploy your Encore application into this pre-existing cluster. See the docs for how to do this.\nDeploying to a new Kubernetes cluster\n1. Connect your cloud account: Ensure your cloud account (such as Google Cloud Platform or AWS) is connected to Encore. (See docs)\n2. Create environment: Open your app in the Cloud Dashboard and go to Environments, then click on Create Environment. \nNext, select your cloud (AWS or GCP) and then specify Kubernetes as the compute platform. Encore supports deploying to GKE on GCP, and EKS Fargate on AWS.\nYou can also configure if you want to allocate all services in one process or run one process per service.\n3. Push your code: To deploy, commit and push your code to the branch you configured as the deployment trigger. You can also trigger a manual deploy from the Cloud Dashboard by going to the Environment Overview page and clicking on Deploy.\n4. Automatic deployment by Encore: Once you've triggered the deploy, Encore will automatically provision and deploy the necessary infrastructure on Kubernetes, per your environment configuration in the Cloud Dashboard. You can monitor the status of your deploy and view your environment's details through the Encore Cloud Dashboard.\n5. Accessing your cluster with kubectl: You can access your cluster using the kubectl CLI tool. See the docs for how to do this."
  },
  {
    "url": "https://encore.dev/docs/primitives/secrets",
    "text": "Wouldn't it be nice to store secret values like API keys, database passwords, and private keys directly in the source code? Of course, we can’t do that – it's horrifyingly insecure! (Unfortunately, it's also very common.)\nEncore's built-in secrets manager makes it simple to store secrets in a secure way and lets you use them in your program like regular variables.\nUsing secrets in your application\nTo use a secret in your application, first define it directly in your code by creating an unexported struct named secrets, where all fields are of type string. For example:\nvar secrets struct { SSHPrivateKey string // ed25519 private key for SSH server GitHubAPIToken string // personal access token for deployments // ... } \nWhen you've defined secrets in your program, the Encore compiler will check that they are set before running or deploying your application. If a secret is not set, you will get a compilation error notifying you that a secret value is missing.\nOnce you've provided values for all secrets, you can just use them in your application like a regular variable. For example:\nfunc callGitHub(ctx context.Context) { req, _ := http.NewRequestWithContext(ctx, \"GET\", \"https:///api.github.com/user\", nil) req.Header.Add(\"Authorization\", \"token \" + secrets.GitHubAPIToken) resp, err := http.DefaultClient.Do(req) // ... handle err and resp } \nPlease note\nSecret keys are globally unique for your whole application. If multiple services use the same secret name they both receive the same secret value at runtime.\nStoring secret values\nUsing the Cloud Dashboard\nThe simplest way to set up secrets is with the Secrets Manager in the Encore Cloud Dashboard. Open your app in app.encore.dev, go to Settings in the main navigation, and then click on Secrets in the settings menu.\nFrom here you can create secrets, save secret values, and configure different values for different environments.\nUsing the CLI\nIf you prefer, you can also set up secrets from the CLI using:\nencore secret set --type <types> <secret-name>\n<types> defines which environment types the secret value applies to. Use a comma-separated list of production, development, preview, and local. Shorthands: prod, dev, pr.\nFor example encore secret set --type prod SSHPrivateKey sets the secret value for production environments,\nand encore secret set --type dev,preview,local GitHubAPIToken sets the secret value for development, preview, and local environments.\nIn some cases, it can be useful to define a secret for a specific environment instead of an environment type. You can do so with encore secret set --env <env-name> <secret-name>. Secret values for specific environments take precedence over values for environment types.\nEnvironment settings\nEach secret can only have one secret value for each environment type. For example: If you have a secret value that's shared between development, preview and local, and you want to override the value for local, you must first edit the existing secret and remove local using the Secrets Manager in the Cloud Dashboard. You can then add a new secret value for local. The end result should look something like the picture below.\nHow it works: Where secrets are stored\nWhen you store a secret Encore stores it encrypted using Google Cloud Platform's Key Management Service (KMS).\nProduction / Your own cloud: When you deploy to production using your own cloud account on GCP or AWS, Encore provisions a secrets manager in your account (using either KMS or AWS Secrets Manager) and replicates your secrets to it. The secrets are then injected into the container using secret environment variables.\nLocal: For local secrets Encore automatically replicates them to developers' machines when running encore run.\nDevelopment / Encore Cloud: Environments on Encore's development cloud (running on GCP under the hood) work the same as self-hosted GCP environments, using GCP Secrets Manager.\nOverriding local secrets\nWhen setting secrets via the encore secret set command, they are automatically synced to all developers working on the same application, courtesy of the Encore Platform.\nIn some cases, however, you want to override a secret only for your local machine. This can be done by creating a file named .secrets.local.cue in the root of your Encore application, next to the encore.app file.\nThe file contains key-value pairs of secret names to secret values. For example:\nGitHubAPIToken: \"my-local-override-token\" SSHPrivateKey: \"custom-ssh-private-key\""
  },
  {
    "url": "https://encore.dev/docs/develop/auth-keys",
    "text": "Pre-authentication keys (“auth keys” for short) let you authenticate the Encore CLI without needing to sign in via a web browser. This is most useful when setting up CI/CD pipelines.\nTypes of auth keys\nReusable Keys for authenticating more than one machine.\nEphemeral Keys - Machines authenticated by this key will be automatically logged out after one hour.\nTake care\nBe very careful with reusable keys! These can be very dangerous if stolen. They're best kept in a key vault product (eg. 1Password, LastPass) specifically designed for the purpose.\nAuthentication\nAuth keys authenticate a machine as the Encore app for which the key was generated. If Ada generates an auth key, and uses it to set up her CI/CD pipeline, then that machine is authenticated as Ada's Encore app.\nGenerating a key\nStep 1: Generate an auth key\nAs an Encore user, visit the auth key page by going to Your apps > (Select your app) > App Settings > Auth Keys.\nA key can be both reusable and ephemeral at the same time (you can decide the combination based on your particular use case).\nTake care\nDon't forget to store your key! Once generated, you will need to copy and store your key in a vault product (eg. 1Password, LastPass). We do not display the full contents of a key in our dashboard for security reasons.\nThis page also gives you the ability to revoke existing keys.\nStep 2: Authenticate with the auth key\nUsing the Encore CLI, you can authenticate with your newly generated key:\n$ encore auth login --auth-key=ena_nEQIkfeM43t7oxpleMsIULbhbtLAbYnnLf1D\nRevoking a key\nYou can revoke a key simply by pressing the Delete button next to it. This will prevent any machines currently using it to authenticate to the Encore platform (regardless of the key type)."
  },
  {
    "url": "https://encore.dev/docs/other/vs-terraform",
    "text": "There are many tools designed to overcome the challenges of cloud infrastructure complexity. Terraform and Pulumi are Infrastructure as Code tools that help you provision infrastructure by writing infrastructure configuration files. Encore uses a fundamentally different approach that lets you declare infrastructure as type-safe objects in your application.\nLet's take a look at how Encore compares to IaC tools like Terraform and Pulumi:\nEncoreTerraformPulumi\nApproach?\tInfrastructure from Code\tInfrastructure as Code\tInfrastructure as Code\t\nSupports major cloud providers like AWS/GCP?\t✅︎ Yes\t✅︎ Yes\t✅︎ Yes\t\nSupports Kubernetes and custom infra configuration?\t✅︎ Yes\t✅︎ Yes\t✅︎ Yes\t\nAvoid learning a DSL?\t✅︎ Yes\t❌ No\t✅︎ Yes\t\nInfrastructure is Type-Safe?\t✅︎ Yes\t❌ No\t❌ No\t\nBuilt-in local dev environment?\t✅︎ Yes\t❌ No\t❌ No\t\nBuilt-in Preview Environments per Pull Request?\t✅︎ Yes\t❌ No\t❌ No\t\nBuilt-in Distributed Tracing?\t✅︎ Yes\t❌ No\t❌ No\t\nAvoid manually writing infra config files?\t✅︎ Yes\t❌ No\t❌ No\t\nAvoid manual maintenance of separate codebase for infra config?\t✅︎ Yes\t❌ No\t❌ No\t\nAvoid manual effort to keep environments in sync?\t✅︎ Yes\t❌ No\t❌ No\t\nEncore removes manual effort and maintenance required with IaC\nA common challenge with Infrastructure as Code (IaC) is that it takes a lot of manual effort to write. What's worse is, you need to repeat the effort for each new environment, or take a short cut by duplicating your prod environment and creating costly over-provisioned test or staging environments.\nWhen you use IaC you also end up with a separate codebase to maintain and keep in sync with your application's actual requirements. The complexity and scope of this problem grows as you introduce more infrastructure and more environments. That means as your system grows, with IaC, you will need to spend more and more time to maintain your infrastructure configuration.\nEncore's infrastructure from code approach means there are no configuration files to maintain, nor any refactoring to do when changing the underlying infrastructure. Your application code is the source of truth for the semantic infrastructure requirements.\nIn practise, you use Encore's Infrastructure SDK to declare infrastructure as type-safe objects in your application code, and Encore automatically provisions the necessary infrastructure in all environments. Including in your own cloud, with support for major cloud providers like AWS/GCP. (This also means your application is cloud-agnostic by default and you avoid cloud lock-in.)\nEncore's local development workflow lets application developers focus\nWhen using IaC to provision cloud environments, you're not at all solving for local development.\nThis means, with Terraform, developers need to manually set up and maintain their local environment to mimic what's running in the cloud, in order to facilitate local development and testing.\nThis can be a major distraction for application developers, because it forces them to spend time learning how to setup and maintain various local versions of cloud infrastructure, e.g. by using Docker Compose and NSQ. This work is a continuous effort as the system evolves, and becomes more and more complex as the footprint grows.\nAll this effort takes time away from product development and slows down onboarding time for new developers.\nWhen using Encore, your local and cloud environments are both defined by the same code base: your application code. This means developers only need to use encore run to start their local dev envioronments. Encore's Open Source CLI takes care of setting up local version of all infrastructure and provides a local development dashboard with built-in observability tools.\nThis greately speeds up development iterations as developers can start using new infrastructure immediately, which makes building new services and event-driven systems extremely efficient.\nEncore ensures your cloud environments are secure by automating IAM\nWhen using IaC tools like Terraform, you must always assign explicit permissions using IAM idenities and IAM policies. This can be very time consuming when developing a large-scale distributed systems, and when you get it wrong it can lead to glaring security holes or unexpected system behavior.\nWhen using Encore, IAM identities and policies are automatically defined according to best practices for least privilege security. This is possible because Encore parses your source code and builds a graph of the logical architecture, it then uses this to define the infrastructure needs. This means Encore knows exactly which services needs access to which infrastructure for your application to function as expected.\nEncore provides an end-to-end purpose-built workflow for cloud backend developement\nEncore does a lot more than just automate infrastructure provisioning and configuration. It's designed as a purpose-built tool for cloud backend development and comes with out-of-the-box tooling for both development and DevOps.\nEncore's built-in developer tools\nCross-service type-safety with IDE auto-complete\nDistributed Tracing\nTest Tracing\nAutomatic API Documentation\nAutomatic Architecture Diagrams\nAPI Client Generation\nSecrets Management\nService/API mocking\nEncore's built-in DevOps tools\nAutomatic Infrastructure provisioning on AWS/GCP\nInfrastructure Tracking & Approvals workflow\nCloud Configuration 2-way sync between Encore and AWS/GCP\nAutomatic least privilege IAM\nPreview Environments per Pull Request\nCost Analytics Dashboard\nEncore Terraform provider for extending Encore with infrastructure that is not currently part of Encore's Infrastructure SDK"
  },
  {
    "url": "https://encore.dev/docs/how-to/migrate-away",
    "text": "We realize most people read this page before even trying Encore, so we start with a perspective on how you might reason about adopting Encore. Read on to see what tools are available for migrating away.\nPicking technologies for your project is an important decision. It's tricky because you don't know what the requirements are going to look like in the future. This uncertainty makes many teams opt for maximum flexibility, often without acknowledging this has a major negative impact on productivity.\nWhen designing Encore, we've leaned on standardization to provide a well-integrated and incredibly productive development workflow. The design is based on the core team's experience building highly scalable distributed systems at Spotify and Google, complemented with loads of invaluable input from the developer community. \nIn practise this means Encore is opinionated in certain areas, enabling static analysis used to create Encore's application model. This is core to how Encore can provide its powerful features, like automatically instrumenting distributed tracing, and provisioning and managing cloud infrastructure.\nBut I'm a snowflake!\nMany software projects end up having some novel requirements, highly specific to the problem they're addressing. To accommodate for this Encore is designed to let you go outside of the mold when you need to, by letting you drop down in abstraction level.\nWe believe that adopting Encore is a low-risk decision for several reasons:\nThere's no upfront work to get the benefits\nEncore apps are normal programs where less than 5% of the code is Encore-specific\nAll infrastructure, and data, lives in your own account on AWS/GCP\nIt's simple to integrate with \"unsupported\" cloud services and other systems\nKey parts are Open Source, including the parser, compiler, and runtime\nWhat to expect when migrating away\nIf you want to migrate away, we want to ensure this is as smooth as possible! Here are some of the ways Encore is designed to keep your app portable, with minimized lock-in, and the tools provided to aid in migrating away.\nCode changes\nBuilding with Encore doesn't require writing your application in an Encore-specific way. Encore applications are normal programs where less than 5% of the code is specific to Encore.\nThis means that the changes required to migrate away will be almost exactly the same work you would have needed to do if you hadn't used Encore in the first place, e.g. writing infrastructure boilerplate. There's no added migration cost.\nIn practise, the code specific to Encore is limited to the use of Encore's Infrastructure SDK. So if you wish to stop using Encore, you need to rework these interfaces to function in a traditional way. This normally means adding boilerplate that isn't necessary when using Encore.\nEjecting your app as a Docker image\nIf you've decided to migrate away from Encore, Encore has built-in support for ejecting your application as a way of removing the connection to Encore. Ejecting your app produces a standalone Docker image that can be deployed anywhere you'd like. See encore eject docker --help for more information.\nConfiguring your ejected docker image\nTo run your app as an ejected image it needs to be configured. This configuration is normally handled by Encore, but needs to be manually managed when ejecting. Two environment variables need to be set: ENCORE_APP_SECRETS and ENCORE_RUNTIME_CONFIG.\nENCORE_APP_SECRETS provides the values of all of your application secrets. The value should be a comma-separated list of key-value pairs, where the key is the secret name and the value is the secret value in base64 encoded form (using Go's RawURLEncoding scheme). For example, if you had two secrets Foo and Bar with the values Hello and World respectively, the value of ENCORE_APP_SECRETS should be Foo=SGVsbG8,Bar=V29ybGQ.\nENCORE_RUNTIME_CONFIG provides the runtime configuration Encore applications need. As the precise configuration changes over time, please refer to the current runtime config definition. The app, environment, and deployment related information powers the encore.Meta API and can be set to arbitrary values. The SQL database and SQL server information is used to configure how Encore connects to SQL databases, and should be configured according to your infrastructure setup. AuthKeys and TraceEndpoint must both be left unspecified as they determine how the application communicates with Encore, and leaving them empty disables that functionality.\nTell us what you need\nWe're engineers ourselves and we understand the importance of not being constrained by a single technology.\nWe're working every single day on making it even easier to start, and stop, using Encore. If you have specific concerns, questions, or requirements, we'd love to hear from you!\nPlease reach out on Discord or send an email with your thoughts."
  },
  {
    "url": "https://encore.dev/docs/how-to/break-up-monolith",
    "text": "It's common to want to break out specific functionality into separate services. Perhaps you want to independently scale a specific service, or simply want to structure your codebase in smaller pieces.\nEncore makes it simple to evolve your system architecture over time, and enables you to deploy your application in multiple different ways without making code changes.\nHow to break out a service from a monolith\nAs a (slightly silly) example, let's imagine we have a monolith hello with two API endpoints H1 and H2. It looks like this:\npackage hello import ( \"context\" ) //encore:api public path=/hello/:name func H1(ctx context.Context, name string) (*Response, error) { msg := \"Hello, \" + name + \"!\" return &Response{Message: msg}, nil } //encore:api public path=/yo/:name func H2(ctx context.Context, name string) (*Response, error) { msg := \"Yo, \" + name + \"!\" return &Response{Message: msg}, nil } type Response struct { Message string } \nNow we're going to break out H2 into its own separate service. Happily, all we need to do is create a new package, let's call it yo, and move the H2 endpoint into it.\nLike so:\npackage yo import ( \"context\" ) //encore:api public path=/yo/:name func H2(ctx context.Context, name string) (*Response, error) { msg := \"Yo, \" + name + \"!\" return &Response{Message: msg}, nil } type Response struct { Message string } \nOn disk we now have:\n/my-app ├── encore.app // ... and other top-level project files │ ├── hello // hello service (a Go package) │ └── hello.go // hello service code │ └── yo // yo service (a Go package) └── yo.go // yo service code \nEncore now understands these are separate services, and when you run your app you'll see that the Service Catalog has been automatically updated accordingly.\nAs well as the Flow architecture diagram.\nMicroservices process allocation\nJust because you want to deploy each service separately in some environments, doesn't mean you want to do it in all environments.\nHandily, Encore lets you decide how you want to deploy your services for each environment. You don't need to change a single line of code.\nWhen you create an environment, you can simply decide which process allocation you want for that environment.\nSharing databases between services (or not)\nDeciding whether to share a database between multiple services depends on your specific situation. Encore supports both options. Learn more in the database documentation."
  },
  {
    "url": "https://encore.dev/docs/develop/testing/mocking",
    "text": "Encore comes with built-in support for mocking out APIs and services, which makes it easier to test your application in isolation.\nMocking Endpoints\nLet's say you have an endpoint that calls an external API in our products service:\n//encore:api private func GetPrice(ctx context.Context, p *PriceParams) (*PriceResponse, error) { // Call external API to get the price } \nWhen testing this function, you don't want to call the real external API since that would be slow and cause your tests to fail if the API is down. Instead, you want to mock out the API call and return a fake response.\nIn Encore, you can do this by adding a mock implementation of the endpoint using the et.MockEndpoint function inside your test:\npackage shoppingcart import ( \"context\" \"testing\" \"encore.dev/et\" // Encore's test support package \"your_app/products\" ) func Test_Something(t *testing.T) { t.Parallel() // Run this test in parallel with other tests without the mock implementation interfering // Create a mock implementation of pricing API which will only impact this test and any sub-tests et.MockEndpoint(products.GetPrice, func(ctx context.Context, p *products.PriceParams) (*products.PriceResponse, error) { return &products.PriceResponse{Price: 100}, nil }) // ... the rest of your test code here ... } \nWhen any code within the test, or any sub-test calls the GetPrice API, the mock implementation will be called instead. The mock will not impact any other tests running in parallel. The function you pass to et.MockEndpoint must have the same signature as the real endpoint.\nIf you want to mock out the API for all tests in the package, you can add the mock implementation to the TestMain function:\npackage shoppingcart import ( \"context\" \"os\" \"testing\" \"encore.dev/et\" \"your_app/products\" ) func TestMain(m *testing.M) { // Create a mock implementation of pricing API which will impact all tests within this package et.MockEndpoint(products.GetPrice, func(ctx context.Context, p *products.PriceParams) (*products.PriceResponse, error) { return &products.PriceResponse{Price: 100}, nil }) // Now run the tests os.Exit(m.Run()) } \nMocks can be changed at any time, including removing them by setting the mock implementation to nil.\nMocking services\nAs well as mocking individual APIs, you can also mock entire services. This can be useful if you want to inject a different set of dependencies into your service for testing, or a service that your code depends on. This can be done using the et.MockService function:\npackage shoppingcart import ( \"context\" \"testing\" \"encore.dev/et\" // Encore's test support package \"your_app/products\" ) func Test_Something(t *testing.T) { t.Parallel() // Run this test in parallel with other tests without the mock implementation interfering // Create a instance of the products service which will only impact this test and any sub-tests et.MockService(\"products\", &products.Service{ SomeField: \"a testing value\", }) // ... the rest of your test code here ... } \nWhen any code within the test, or any sub-test calls the products service, the mock implementation will be called instead. Unlike et.MockEndpoint, the mock implementation does not need to have the same signature, and can be any object. The only requirement is that any of the services APIs that are called during the test must be implemented by as a receiver method on the mock object. (This also includes APIs that are defined as package level functions in the service, and are not necessarily defined as receiver methods on that services struct).\nTo help with compile time safety on service mocking, for every service Encore will automatically generate an Interface interface which contains all the APIs defined in the service. This interface can be passed as a generic argument to et.MockService to ensure that the mock object implements all the APIs defined in the service:\ntype myMockObject struct{} func (m *myMockObject) GetPrice(ctx context.Context, p *products.PriceParams) (*products.PriceResponse, error) { return &products.PriceResponse{Price: 100}, nil } func Test_Something(t *testing.T) { t.Parallel() // Run this test in parallel with other tests without the mock implementation interfering // This will cause a compile time error if myMockObject does not implement all the APIs defined in the products service et.MockService[products.Interface](\"products\", &myMockObject{}) } \nAutomatic generation of mock objects\nThanks to the generated Interface interface, it's possible to automatically generate mock objects for your services using either Mockery or GoMock."
  },
  {
    "url": "https://encore.dev/docs/develop/testing",
    "text": "Go comes with excellent built-in support for automated tests. Encore builds on top of this foundation, and lets you write tests in exactly the same way. We won't cover the basics of how to write tests here, see the official Go docs for that. Let's instead focus on the difference between testing in Encore compared to a standard Go application.\nThe main difference is that since Encore requires an extra compilation step, you must run your tests using encore test instead of go test. This is a wrapper that compiles the Encore app and then runs go test. It supports all the same flags that the go test command does.\nFor example, use encore test ./... to run tests in all sub-directories, or just encore test for the current directory.\nTest tracing\nEncore comes with built-in test tracing for local development.\nYou only need to open Encore's local development dashboard at localhost:9400 to see traces for all your tests. This makes it very simple to understand the root cause for why a test is failing.\nIntegration testing\nSince Encore removes almost all boilerplate, most of the code you write is business logic that involves databases and calling APIs between services. Such behavior is most easily tested with integration tests.\nWhen running tests, Encore automatically sets up the databases you need in a separate database cluster. They are additionally configured to skip fsync and to use an in-memory filesystem since durability is not a concern for automated tests.\nThis drastically reduces the speed overhead of writing integration tests.\nIn general, Encore applications tend to focus more on integration tests compared to traditional applications that are heavier on unit tests. This is nothing to worry about and is the recommended best practice.\nService Structs\nIn tests, service structs are initialised on demand when the first API call is made to that service and then that instance of the service struct for all future tests. This means your tests can run faster as they don't have to each initialise all the service struct's each time a new test starts.\nHowever, in some situations you might be storing state in the service struct that would interfere with other tests. When you have a test you want to have it's own instance of the service struct, you can use the et.EnableServiceInstanceIsolation() function within the test to enable this for just that test, while the rest of your tests will continue to use the shared instance.\nTest-only infrastructure\nEncore allows tests to define infrastructure resources specifically for testing. This can be useful for testing library code that interacts with infrastructure.\nFor example, the x.encore.dev/pubsub/outbox package defines a test-only database that is used to do integration testing of the outbox functionality.\nTesting from your IDE\nGoLand / IntelliJ\nEncore has an officially supported plugin available in the JetBrains marketplace.\nIt lets you run unit tests directly from within your IDE with support for debug mode and breakpoints.\nVisual Studio Code (VS Code)\nThere's no official VS Code plugin available yet, but we are happy to include your contribution if you build one. Reach out on Discord if you need help to get started.\nFor advice on debugging when using VS Code, see the Debugging docs."
  },
  {
    "url": "https://encore.dev/docs/ts/primitives/databases",
    "text": "Encore treats SQL databases as logical resources and natively supports PostgreSQL databases.\nCreating a database\nTo create a database, import encore.dev/storage/sqldb and call new SQLDatabase, assigning the result to a top-level variable.\nFor example:\ntodo/todo.ts\ntodo/migrations/1_create_table.up.sql\nimport { SQLDatabase } from \"encore.dev/storage/sqldb\"; // Create the todo database and assign it to the \"db\" variable const db = new SQLDatabase(\"todo\", { migrations: \"./migrations\", }); // Then, query the database using db.query, db.exec, etc. \nAs seen above, the new SQLDatabase() call takes two parameters: the name of the database, and a configuration object. The configuration object specifies the directory containing the database migration files, which is how you define the database schema.\nSee the Defining the database schema section below for more details.\nWith this code in place Encore will automatically create the database when starting encore run (locally) or on the next deployment (in the cloud). Encore automatically injects the appropriate configuration to authenticate and connect to the database, so once the application starts up the database is ready to be used.\nDefining the database schema\nDatabase schemas are defined by creating migration files in a directory named migrations within an Encore service package. Each migration file is named <number>_<name>.up.sql, where <number> is a sequence number for ordering the migrations and <name> is a descriptive name of what the migration does.\nOn disk it might look like this:\n/my-app ├── encore.app // ... and other top-level project files │ └── todo // todo service ├── migrations // database migrations (directory) │ ├── 1_create_table.up.sql // database migration file │ └── 2_add_field.up.sql // database migration file ├── todo.ts // todo service code └── todo.test.ts // tests for todo service \nEach migration runs in order and expresses the change in the database schema from the previous migration.\nThe file name format is important. Migration files must start with a number followed by _, and increasing for each migration. Each file name must also end with .up.sql.\nThe simplest naming convention is to start from 1 and counting up:\n1_first_migration.up.sql\n2_second.up.sql\n3_migration_name_goes_here.up.sql\n... and so on.\nIt's also possible to prefix the migration files with leading zeroes to have them ordered nicer in the editor (like 0001_migration.up.sql).\nThe first migration usually defines the initial table structure. For example, a todo service might start out by creating todo/migrations/1_create_table.up.sql with the following contents:\nCREATE TABLE todo_item ( id BIGSERIAL PRIMARY KEY, title TEXT NOT NULL, done BOOLEAN NOT NULL DEFAULT false ); \nProvisioning databases\nEncore automatically provisions databases to match what your application requires. When you define a database, Encore will provision the database at your next deployment.\nEncore provisions databases in an appropriate way depending on the environment. When running locally, Encore creates a database cluster using Docker. In the cloud, it depends on the environment type:\nIn production environments, the database is provisioned through the Managed SQL Database service offered by the chosen cloud provider.\nIn development environments, the database is provisioned as a Kubernetes deployment with a persistent disk attached.\nSee exactly what is provisioned for each cloud provider, and each environment type, in the infrastructure documentation.\nUsing databases\nOnce you have created the database using const db = new SQLDatabase(...) you can start querying and inserting data into the database by calling methods on the db variable.\nQuerying data\nTo query data, use the db.query or db.queryRow methods. db.query returns an asynchronous iterator, yielding rows one by one as they are streamed from the database. queryRow returns a single row, or null if the query yields no rows.\nBoth APIs operate using JavaScript template strings, allowing easy use of placeholder parameters while preventing the possibility of SQL Injection vulnerabilities.\nTypical usage looks like this:\nconst allTodos = await db.query`SELECT * FROM todo_item`; for await (const todo of allTodos) { // Process each todo } \nOr to query a single todo item by id:\nasync function getTodoTitle(id: number): string | undefined { const row = await db.query`SELECT title FROM todo_item WHERE id = ${id}`; return row?.title; } \nInserting data\nTo insert data, or to make database queryies that don't return any rows, use db.exec.\nFor example:\nawait db.exec` INSERT INTO todo_item (title, done) VALUES (${title}, false) `; \nConnecting to databases\nIt's often useful to be able to connect to the database from outside the backend application. For example for scripts, ad-hoc querying, or dumping data for analysis.\nUsing the Encore CLI\nEncore's CLI comes with built-in support for connecting to databases:\nencore db shell <database-name> [--env=<name>] opens a psql shell to the database named <database-name> in the given environment. Leaving out --env defaults to the local development environment.\nencore db conn-uri <database-name> [--env=<name>] outputs a connection string for the database named <database-name>. When specifying a cloud environment, the connection string is temporary. Leaving out --env defaults to the local development environment.\nencore db proxy [--env=<name>] sets up a local proxy that forwards any incoming connection to the databases in the specified environment. Leaving out --env defaults to the local development environment.\nSee encore help db for more information on database management commands.\nUsing database user credentials\nFor cloud environments you can view database user credentials (created by Encore when provisioning databases) via the Cloud Dashboard:\nOpen your app in the Cloud Dashboard, navigate to the Infrastructure page for the appropriate environment, and locate the USERS section within the relevant Database Cluster.\nHandling migration errors\nWhen Encore applies database migrations, there's always a possibility the migrations don't apply cleanly.\nThis can happen for many reasons:\nThere's a problem with the SQL syntax in the migration\nYou tried to add a UNIQUE constraint but the values in the table aren't actually unique\nThe existing database schema didn't look like you thought it did, so the database object you tried to change doesn't actually exist\n... and so on\nIf that happens, Encore rolls back the migration. If it happens during a cloud deployment, the deployment is aborted. Once you fix the problem, re-run encore run (locally) or push the updated code (in the cloud) to try again.\nEncore tracks which migrations have been applied in the schema_migrations table:\ndatabase=# \\d schema_migrations Table \"public.schema_migrations\" Column | Type | Collation | Nullable | Default ---------+---------+-----------+----------+--------- version | bigint | | not null | dirty | boolean | | not null | Indexes: \"schema_migrations_pkey\" PRIMARY KEY, btree (version) \nThe version column tracks which migration was last applied. If you wish to skip a migration or re-run a migration, change the value in this column. For example, to re-run the last migration, run UPDATE schema_migrations SET version = version - 1;. Note that Encore does not use the dirty flag by default.\nPostgreSQL Extensions\nEncore uses the encoredotdev/postgres docker image for local development, CI/CD, and for databases hosted on Encore Cloud.\nThis docker image ships with many popular PostgreSQL extensions pre-installed. In particular, pgvector and PostGIS are available.\nSee the full list of available extensions.\nTroubleshooting\nApplication won't run\nWhen you run your application locally with encore run, Encore will parse and compile your application, and provision the necessary infrastructure including databases. If this fails with a database error, there are a few common causes.\nError: sqldb: unknown database \nThis error is often caused by a problem with the initial migration file, such as incorrect naming or location.\nVerify that you've created the migration file correctly, then try encore run again.\nError: could not connect to the database \nWhen you can't connect to the database in your local environment, there's likely an issue with Docker:\nMake sure that you have Docker installed and running, then try encore run again.\nIf this fails, restart the Encore daemon by running encore daemon, then try encore run again.\nError: Creating PostgreSQL database cluster Failed \nThis means Encore was not able to create the database. Often this is due to a problem with Docker.\nCheck if you have permission to access Docker by running docker images.\nSet the correct permissions with sudo usermod -aG docker $USER (Learn more in the Docker documentation)\nThen log out and log back in so that your group membership is refreshed.\nError: unable to add CA to cert pool \nThis error is commonly caused by the presence of the file $HOME/.postgresql/root.crt on the filesystem. When this file is present the PostgreSQL client library will assume the database server has that root certificate, which will cause the above error.\nRemove or rename the file, then try encore run again."
  },
  {
    "url": "https://encore.dev/docs/ts/primitives/cron-jobs",
    "text": "When you need to run periodic and recurring tasks, Encore's Infrastructure SDK provides a declarative way of using Cron Jobs.\nWhen a Cron Job is defined, Encore will call the API of your choice on the schedule you have defined. This means there is no need to maintain any infrastructure, as Encore handles the scheduling, monitoring and execution of Cron Jobs.\nDefining a Cron Job\nTo define a Cron Job, import encore.dev/cron and call new CronJob, assigning the result to a top-level variable.\nFor example:\nimport { CronJob } from \"encore.dev/cron\"; import { api } from \"encore.dev/api\"; // Send a welcome email to everyone who signed up in the last two hours. const _ = new CronJob(\"welcome-email\", { title: \"Send welcome emails\", every: \"2h\", endpoint: sendWelcomeEmail, }) // Emails everyone who signed up recently. // It's idempotent: it only sends a welcome email to each person once. export const sendWelcomeEmail = api({}, async () => { // Send welcome emails... }); \nThe \"welcome-email\" argument to new CronJob is a unique ID you give to each Cron Job. If you later refactor the code and move the Cron Job definition to another package, Encore uses this ID to keep track that it's the same Cron Job and not a different one.\nWhen this code gets deployed Encore will automatically register the Cron Job in Encore Cloud and begin calling the sendWelcomeEmail API every two hours.\nEncore's Cloud Dashboard provides a convenient user interface for monitoring and debugging Cron Job executions across all your environments via the Cron Jobs menu item:\nA few important things to know:\nCron Jobs do not run when developing locally or in Preview Environments; but you can always call the API manually to test the behavior.\nCron Jobs execution in Encore Cloud is capped at once every hour for users on the Free Tier; deploy to your own cloud or upgrade to the Pro plan to use more frequent executions.\nCron Jobs support both public and private APIs.\nThe API endpoints used in Cron Jobs should always be idempotent. It's possible they're called multiple times in some network conditions.\nThe API endpoints used in Cron Jobs must not take any request parameters.\nCron schedules\nAbove we used the every field, which executes the Cron Job on a periodic basis. It runs around the clock each day, starting at midnight (UTC).\nIn order to ensure a consistent delay between each run, the interval used must divide 24 hours evenly. For example, 10m and 6h are both allowed (since 24 hours is evenly divisible by both), whereas 7h is not (since 24 is not evenly divisible by 7). The Encore compiler will catch this and give you a helpful error at compile-time if you try to use an invalid interval.\nCron expressions\nFor more advanced use cases, such as running a Cron Job on a specific day of the month, or a specific week day, or similar, the every field is not expressive enough.\nFor these use cases, Encore provides full support for Cron expressions by using the schedule field instead of the every field.\nFor example:\n// Run the monthly accounting sync job at 4am (UTC) on the 15th day of each month. const _ = new CronJob(\"accounting-sync\", { title: \"Cron Job Example\", schedule: \"0 4 15 * *\", endpoint: accountingSync, })"
  },
  {
    "url": "https://encore.dev/docs/ts/primitives/services-and-apis",
    "text": "Encore makes it simple to build applications with one or many services, without needing to manually handle the typical complexity of developing microservices.\nDefining a service\nWith Encore you define a service by creating a folder and inside that folder defining one or more APIs within a regular TypeScript file. Encore recognizes this as a service, and uses the folder name as the service name. When deploying, Encore will automatically provision the required infrastructure for each service.\nOn disk it might look like this:\n/my-app ├── encore.app // ... and other top-level project files ├── package.json │ ├── hello // hello service (a folder) │ ├── hello.ts // hello service code │ └── hello_test.ts // tests for hello service │ └── world // world service (a folder) └── world.ts // world service code \nThis means building a microservices architecture is as simple as creating multiple directories within your application.\nDefining APIs\nEncore allows you to easily define type-safe, idiomatic TypeScript API endpoints.\nIt's easy to accept both the URL path parameters, as well as JSON request body data, HTTP headers, and query strings.\nIt's all done in a way that is fully declarative, enabling Encore to automatically parse and validate the incoming request and ensure it matches the schema, with zero boilerplate.\nTo define an API, use the api function from the encore.dev/api module to wrap a regular TypeScript async function that receives the request data as input and returns response data. This tells Encore that the function is an API endpoint. Encore will then automatically generate the necessary boilerplate at compile-time.\nIn the example below, we define the API endpoint ping which accepts POST requests and is exposed as hello.ping (because our service name is hello).\n// inside the hello.ts file import { api } from \"encore.dev/api\"; export const ping = api( { method: \"POST\" }, async (p: PingParams): Promise<PingResponse> => { return { message: `Hello ${p.name}!` }; }, ); \nRequest and response schemas\nIn the example above we defined an API that uses request and response schemas. The request data is of type PingParams and the response data of type PingResponse. That means we need to define them like so:\n// inside the hello.ts file import { api } from \"encore.dev/api\"; // PingParams is the request data for the Ping endpoint. interface PingParams { name: string; } // PingResponse is the response data for the Ping endpoint. interface PingResponse { message: string; } // hello is an API endpoint that responds with a simple response. // This is exposed as \"hello.ping\". export const hello = api( { method: \"POST\", path: \"/hello\" }, async (p: PingParams): Promise<PingResponse> => { return { message: `Hello ${p.name}!` }; }, ); \nRequest and response schemas are both optional in case you don't need them. That means there are four different ways of defining an API:\napi({ ... }, async (params: Params): Promise<Response> => {}); – when you need both.\napi({ ... }, async (): Promise<Response> => {}); – when you only return a response.\napi({ ... }, async (params: Params): Promise<void> => {}); – when you only respond with success/fail.\napi({ ... }, async (): Promise<void> => {}); – when you need neither request nor response data.\nThe api function is a generic function.\nYou can also pass the type arguments for the request and response objects to the api function which looks like this: api<Params, Response>(async (params) => {});\nThis approach is simple but very powerful. It lets Encore use static analysis to understand the request and response schemas of all your APIs, which enables Encore to automatically generate API documentation, type-safe API clients, and much more.\nExposing API endpoints to the outside world\nWhen you define an API, by default it is not exposed to the outside world, and it can only be called by other APIs within the same Encore application.\nTo expose an API to the internet, add the expose: true field to the APIOptions object passed in as the first argument to api.\n{ expose: false } – defines a private API that is never accessible to the outside world. It can only be called from other services in your app and via cron jobs. This is default value if the expose field isn't set.\n{ expose: true } – defines a public API that anybody on the internet can call (this is the default value if no access field is set).\nRequiring authentication data\nAdditionally, you can specify that an API can only be called with valid authentication, by specifying the option auth: true. With this option, Encore will first call the authentication handler you've defined to validate the authentication of incoming requests.\nSetting auth: true can also be useful for internal APIs that aren't exposed to the internet. In that case, it means that the internal caller must have valid authentication data associated with its request.\nFinally, even if an API endpoint does not specify auth: true, it will still receive any authentication data that was provided.\nFor more information on defining APIs that require authentication, see the authentication guide.\nREST APIs\nEncore has support for RESTful APIs and lets you easily define resource-oriented API URLs, parse parameters out of them, and more.\nTo create a REST API, start by defining an endpoint and specify the method and path fields in the APIOptions object.\nTo specify a placeholder variable, use :name and add a function parameter with the same name to the function signature. Encore parses the incoming request URL and makes sure it matches the type of the parameter.\nFor example, if you want to have a getBlogPost endpoint that takes a numeric id as a parameter:\n// getBlogPost retrieves a blog post by id. export const getBlogPost = api( { method: \"GET\", path: \"/blog/:id\" }, async ({ id }: { id: number }): Promise<BlogPost> => { // Use id to query database... }, ); \nYou can also combine path parameters with body payloads. For example, if you want to have an updateBlogPost endpoint:\ninterface Params { id: number; post: BlogPost; } // updateBlogPost updates an existing blog post by id. export const updateBlogPost = api( { method: \"PUT\", path: \"/blog/:id\" }, async ({ id, post }: Params): Promise<BlogPost> => { // Use id to query database... }, ); \nQuery parameters\nTo define that a field should be parsed from the query string of the incoming request, wrap its type with Query<...>. For example:\nimport { Query } from \"encore.dev/api\"; interface SearchParams { filter: Query<string>; // will be parsed from \"?filter=....\" in the request url } interface SearchResponse { matches: BlogPost[]; // blog posts matching the search filter. } // Search for blog posts matching the filter. export const search = api<SearchParams, SearchResponse>( { path: \"/blog/search\" }, async ({ filter }) => { // Use filter to query database... }, ); \nRaw endpoints\nIn case you need to operate at a lower abstraction level, Encore supports defining raw endpoints that let you access the underlying HTTP request. This is often useful for things like accepting webhooks.\nTo define a raw endpoint, use the api.raw function. It works similarly to api, but does not accept a request and response schema. Instead, it works like the Node.js http module and Express.js, where the function receives two parameters: a request object and a response writer.\nIt looks like this:\nimport { api } from \"encore.dev/api\"; export const myRawEndpoint = api.raw( { expose: true, path: \"/raw\", method: \"GET\" }, async (req, resp) => { resp.writeHead(200, { \"Content-Type\": \"text/plain\" }); resp.end(\"Hello, raw world!\"); }, ); \nIt can be called like so:\n$ curl http://localhost:4000/raw\nHello, raw world!\nCalling APIs\nCalling an API endpoint looks like a regular function call with Encore. To call an endpoint you first need to import the service from encore.app/clients and then call the API endpoint like a regular function. When compiling your application, Encore uses static analysis to parse all APIs and make then available through the encore.app/clients module for internal calls.\nIn the example below, we import the service hello and call the ping endpoint using a function call to hello.ping.\nimport { hello } from \"~encore/clients\"; // import 'hello' service export const myOtherAPI = api({}, async (): Promise<void> => { const resp = await hello.ping({ name: \"World\" }); console.log(resp.message); // \"Hello World!\" }); \nThis means your development workflow is as simple as building a monolith, even if you use multiple services. You get all the benefits of function calls, like compile-time checking of all the parameters and auto-completion in your editor, while still allowing the division of code into logical components, services, and systems.\n{/ TODO: Add info about the current request meta data when available. /}"
  },
  {
    "url": "https://encore.dev/docs/how-to/github",
    "text": "Encore applications are easy to integrate with GitHub for source code hosting.\nTo link your application to GitHub, open your application on app.encore.dev, and click on Settings in the main navigation. Then select GitHub in the settings menu.\nNext, connect your account to GitHub by clicking the Connect Account to GitHub button. This will open GitHub where you can grant access either to all repositories or only the specific one(s) you want to link with Encore.\nWhen you come back to Encore, click the Link App to GitHub button:\nIn the popup, select the repository you would like to link your app with:\nClick Link and you're done! Encore will now automatically start building and running tests against your Pull Requests, and provision Preview Environments for each Pull Request.\nPlacing your Encore app in a monorepo sub-folder\nIf you already have a monorepo and want to place your Encore application in a sub-folder, you need to tell Encore which folder the encore.app file is in.\nDo this by opening your app in the Cloud Dashboard and go to Settings > General. Then in the Root Directory section, you specify the directory within your Git repository in which your encore.app file is located.\nConfigure deploy trigger\nWhen using GitHub, you can configure Encore to automatically trigger deploys when you push to a specific branch name. To configure which branch name is used to trigger deploys, open your app in the Cloud Dashboard and go to the Overview page for your intended environment. Click on Settings and then in the section Branch Push configure the Branch name and hit save.\nPreview Environments for each Pull Request\nOnce you've linked your app with GitHub, Encore will automatically start building and running tests against your Pull Requests.\nEncore will also provision a dedicated Preview Environment for each pull request. This environment works just like a regular development environment, and lets you test your changes before merging.\nLearn more in the Preview Environments documentation."
  },
  {
    "url": "https://encore.dev/docs/ts/primitives/pubsub",
    "text": "Publishers & Subscribers (Pub/Sub) let you build systems that communicate by broadcasting events asynchronously. This is a great way to decouple services for better reliability and responsiveness.\nEncore's Infrastructure SDK lets you use Pub/Sub in a cloud-agnostic declarative fashion. At deployment, Encore automatically provisions the required infrastructure.\nCreating a Topic\nThe core of Pub/Sub is the Topic, a named channel on which you publish events. Topics must be declared as package level variables, and cannot be created inside functions. Regardless of where you create a topic, it can be published to from any service, and subscribed to from any service.\nWhen creating a topic, it must be given an event type, a unique name, and a configuration to define its behaviour.\nFor example, to create a topic with events about user signups:\nimport { Topic } \"encore.dev/pubsub\" export interface SignupEvent { userID: string; } export const signups = new Topic<SignupEvent>(\"signups\", { deliveryGuarantee: \"at-least-once\", }); \nPublishing events\nTo publish an Event, call publish on the topic passing in the event object (which is the type specified in the new Topic<Type> constructor).\nFor example:\nconst messageID = await signups.publish({userID: id}); // If we get here the event has been successfully published, // and all registered subscribers will receive the event. // The messageID variable contains the unique id of the message, // which is also provided to the subscribers when processing the event. \nBy defining the signups topic variable as an exported variable you can also publish to the topic from other services in the same way.\nSubscribing to Events\nTo Subscribe to events, you create a Subscription as a top-level variable, by calling the new Subscription constructor.\nEach subscription needs:\nthe topic to subscribe to\na name which is unique for the topic\na configuration object with at least a handler function to process the events\na configuration object\nFor example, to create a subscription to the signups topic from earlier:\nimport { Subscription } from \"encore.dev/pubsub\"; const _ = new Subscription(signups, \"send-welcome-email\", { handler: async (event) => { // Send a welcome email using the event. }, }); \nSubscriptions can be defined in the same service as the topic is declared, or in any other service of your application. Each subscription to a single topic receives the events independently of any other subscriptions to the same topic. This means that if one subscription is running very slowly, it will grow a backlog of unprocessed events. However, any other subscriptions will still be processing events in real-time as they are published.\nError Handling\nIf a subscription function returns an error, the event being processed will be retried, based on the retry policy configured on that subscription.\nAfter the max number of retries is reached,the event will be placed into a dead-letter queue (DLQ) for that subscriber. This allows the subscription to continue processing events until the bug which caused the event to fail can be fixed. Once fixed, the messages on the dead-letter queue can be manually released to be processed again by the subscriber.\nCustomizing message delivery\nAt-least-once delivery\nThe above examples configure the topic to ensure that, for each subscription, events will be delivered at least once.\nThis means that if the topic believes the event was not processed, it will attempt to deliver the message again. Therefore, all subscription handlers should be idempotent. This helps ensure that if the handler is called two or more times, from the outside there's no difference compared to calling it once.\nThis can be achieved using a database to track if you have already performed the action that the event is meant to trigger, or ensuring that the action being performed is also idempotent in nature.\nExactly-once delivery\nTopics can also be configured to deliver events exactly once by setting the deliveryGuarantee field to \"exactly-once\". This enables stronger guarantees on the infrastructure level to minimize the likelihood of message re-delivery.\nHowever, there are still some rare circumstances when a message might be redelivered. For example, if a networking issue causes the acknowledgement of successful processing the message to be lost before the cloud provider receives it (the Two Generals' Problem). As such, if correctness is critical under all circumstances, it's still advisable to design your subscription handlers to be idempotent.\nBy enabling exactly-once delivery on a topic the cloud provider enforces certain throughput limitations:\nAWS: 300 messages per second for the topic (see AWS SQS Quotas).\nGCP: At least 3,000 messages per second across all topics in the region (can be higher on the region see GCP PubSub Quotas).\nTake care\nExactly-once delivery does not perform message deduplication on the publishing side. If publish is called twice with the same message, the message will be delivered twice.\nMessage Attributes\nBy default, each field in the event type is encoded as JSON and sent as part of the Pub/Sub message payload.\nPub/Sub topics also support sending data as \"attributes\", which are key-value pairs that enable other behavior like subscriptions that filter messages or ensuring message ordering.\nTo define that a field should be sent as an attribute, define it with the Attribute type.\nFor example, to add an attribute named source:\nimport { Topic, Attribute } from \"encore.dev/pubsub\"; export interface SignupEvent { userID: string; source: Attribute<string>; } export const signups = new Topic<SignupEvent>(\"signups\", { deliveryGuarantee: \"at-least-once\", }); \nOrdered Topics\nTopics are unordered by default, meaning that messages can be delivered in any order. This allows for better throughput on the topic as messages can be processed in parallel. However, in some cases, messages must be delivered in the order they were published for a given entity.\nTo create an ordered topic, configure the topic's orderingAttribute to match the name of a top-level Attribute field in the event type. This field ensures that messages delivered to the same subscriber are delivered in the order of publishing for that specific field value. Messages with a different value on the ordering attribute are delivered in an unspecified order.\nTo maintain topic order, messages with the same ordering key aren't delivered until the earliest message is processed or dead-lettered, potentially causing delays due to head-of-line blocking. Mitigate processing issues by ensuring robust logging and alerts, and appropriate subscription retry policies.\nPlease note\nThe orderingAttribute currently has no effect in local environments.\nThroughput limitations\nEach cloud provider enforces certain throughput limitations for ordered topics:\nAWS: 300 messages per second for the topic (see AWS SQS Quotas)\nGCP: 1 MBps for each ordering key (See GCP Pub/Sub Resource Limits)\nOrdered topic example\nimport { Topic, Attribute } from \"encore.dev/pubsub\"; export interface CartEvent { shoppingCartID: Attribute<number>; event: string; } export const cartEvents = new Topic<CartEvent>(\"cart-events\", { deliveryGuarantee: \"at-least-once\", orderingAttribute: \"shoppingCartID\", }) async function example() { // These are delivered in order as they all have the same shopping cart ID await cartEvents.publish({shoppingCartID: 1, event: \"item_added\"}); await cartEvents.publish({shoppingCartID: 1, event: \"checkout_started\"}); await cartEvents.publish({shoppingCartID: 1, event: \"checkout_completed\"}); // This may be delivered at any point as it has a different shopping cart ID. await cartEvents.publish({shoppingCartID: 2, event: \"item_added\"}); }"
  },
  {
    "url": "https://encore.dev/docs/primitives/services-and-apis",
    "text": "Encore makes it simple to build applications with one or many services, without needing to manually handle the typical complexity of developing microservices.\nDefining a service\nWith Encore you define a service by defining one or more APIs within a regular Go package. Encore recognizes this as a service, and uses the package name as the service name. When deploying, Encore will automatically provision the required infrastructure for each service.\nOn disk it might look like this:\n/my-app ├── encore.app // ... and other top-level project files │ ├── hello // hello service (a Go package) │ ├── hello.go // hello service code │ └── hello_test.go // tests for hello service │ └── world // world service (a Go package) └── world.go // world service code \nThis means building a microservices architecture is as simple as creating multiple Go packages within your application. See the app structure documentation for more details.\nService Initialization\nUnder the hood Encore automatically generates a main function that initializes all your infrastructure resources when the application starts up. This means you don't write a main function for your Encore application.\nIf you want to customize the initialization behavior of your service, you can define a service struct and define custom initialization logic with that. See the service struct docs for more info.\nDefining APIs\nTo define an API, add the //encore:api annotation any regular Go function. This tells Encore that the function is an API endpoint. Encore will then automatically generate the necessary boilerplate at compile-time.\nIn the example below, we define the API endpoint Ping, in the hello service, which gets exposed as hello.Ping.\npackage hello // service name //encore:api public func Ping(ctx context.Context, params *PingParams) (*PingResponse, error) { msg := fmt.Sprintf(\"Hello, %s!\", params.Name) return &PingResponse{Message: msg}, nil } \nRequest and response schemas\nIn the example above we defined an API that uses request and response schemas. The request data is of type PingParams and the response data of type PingResponse. That means we need to define them like so:\npackage hello // service name // PingParams is the request data for the Ping endpoint. type PingParams struct { Name string } // PingResponse is the response data for the Ping endpoint. type PingResponse struct { Message string } // Ping is an API endpoint that responds with a simple response. // This is exposed as \"hello.Ping\". //encore:api public func Ping(ctx context.Context, params *PingParams) (*PingResponse, error) { msg := fmt.Sprintf(\"Hello, %s!\", params.Name) return &PingResponse{Message: msg}, nil } \nRequest and response schemas are both optional in case you don't need them. That means there are four different ways of defining an API:\nfunc Foo(ctx context.Context, p *Params) (*Response, error) – when you need both.\nfunc Foo(ctx context.Context) (*Response, error) – when you only return a response.\nfunc Foo(ctx context.Context, p *Params) error – when you only respond with success/fail.\nfunc Foo(ctx context.Context) error – when you need neither request nor response data.\nAs you can see, two parts are always present: the ctx context.Context parameter and the error return value.\nThe ctx parameter is used for cancellation. It lets you detect when the caller is no longer interested in the result, and lets you abort the request processing and save resources that nobody needs. Learn more about contexts on the Go blog.\nThe error return type is always required because APIs can always fail from the caller's perspective. Therefore even though our simple Ping API endpoint above never fails in its implementation, from the perspective of the caller perhaps the service is crashing or the network is down and the service cannot be reached.\nThis approach is simple but very powerful. It lets Encore use static analysis to understand the request and response schemas of all your APIs, which enables Encore to automatically generate API documentation, type-safe API clients, and much more.\nAccess controls\nWhen you define an API, you have three options for how it can be accessed:\n//encore:api public – defines a public API that anybody on the internet can call.\n//encore:api private – defines a private API that is never accessible to the outside world. It can only be called from other services in your app and via cron jobs.\n//encore:api auth – defines a public API that anybody can call, but requires valid authentication.\nYou can optionally send in auth data to public and private APIs, in which case the auth handler will be used. When used for private APIs, they are still not accessible from the outside world.\nFor more on defining APIs that require authentication, see the authentication guide.\nREST APIs\nEncore has support for RESTful APIs and lets you easily define resource-oriented API URLs, parse parameters out of them, and more.\nTo create a REST API, start by defining an endpoint and specify the method and path fields in the //encore:api comment. (Learn more in the API schemas guide.)\nTo specify a placeholder variable, use :name and add a function parameter with the same name to the function signature. Encore parses the incoming request URL and makes sure it matches the type of the parameter.\nFor example, if you want to have a GetBlogPost endpoint that takes a numeric id as a parameter:\n// GetBlogPost retrieves a blog post by id. //encore:api public method=GET path=/blog/:id func GetBlogPost(ctx context.Context, id int) (*BlogPost, error) { // Use id to query database... } \nYou can also combine path parameters with body payloads. For example, if you want to have an UpdateBlogPost endpoint:\n// UpdateBlogPost updates an existing blog post by id. //encore:api public method=PUT path=/blog/:id func UpdateBlogPost(ctx context.Context, id int, post *BlogPost) error { // Use `post` to update the blog post with the given id. } \nTake care\nYou cannot define paths that conflict with each other, including paths where the static part can be mistaken for a parameter, e.g both /blog and /blog/:id would conflict with /:username.\nAs a rule of thumb, try to place path parameters at the end of the path and prefix them with the service name, e.g:\nGET /blog/posts GET /blog/posts/:id GET /user/profile/:username GET /user/me \nQuery parameters\nWhen fetching data with GET endpoints, it's common to receive additional parameters for optional behavior, like filtering a list or changing the sort order.\nWhen you use a struct type as the last argument in the function signature, Encore automatically parses these fields from the HTTP query string (for the GET, HEAD, and DELETE methods).\nFor example, if you want to have a ListBlogPosts endpoint:\ntype ListParams struct { Limit uint // number of blog posts to return Offset uint // number of blog posts to skip, for pagination } type ListResponse struct { Posts []*BlogPost } //encore:api public method=GET path=/blog func ListBlogPosts(ctx context.Context, opts *ListParams) (*ListResponse, error) { // Use limit and offset to query database... } \nThis could then be queried as /blog?limit=10&offset=20.\nQuery parameters are more limited than structured JSON data, and can only consist of basic types (string, bool, integer and floating point numbers), Encore's UUID types, and slices of those types.\nRaw endpoints\nIn case you need to operate at a lower abstraction level, Encore supports defining raw endpoints that let you access the underlying HTTP request. This is often useful for things like accepting webhooks.\nTo define a raw endpoint, change the //encore:api annotation and function signature like so:\npackage service import \"net/http\" // Webhook receives incoming webhooks from Some Service That Sends Webhooks. //encore:api public raw func Webhook(w http.ResponseWriter, req *http.Request) { // ... operate on the raw HTTP request ... } \nLike any other Encore API endpoint, once deployed this will be exposed at the URL: \nhttps://<env>-<app-id>.encr.app/service.Webhook. Just like regular endpoints, raw endpoints support the use of :id and *wildcard segments.\nExperienced Go developers will have already noted this is just a regular Go HTTP handler. (See the net/http documentation for how Go HTTP handlers work.)\nLearn more about receiving webhooks and using WebSockets in the receiving regular HTTP requests guide.\nCalling APIs\nCalling an API endpoint looks like a regular function call with Encore. Import the service package as a regular Go package using import \"encore.app/package-name\" and then call the API endpoint like a regular function. Encore will then automatically generate the necessary boilerplate at compile-time.\nIn the example below, we import the service package hello and call the Ping endpoint using a function call to hello.Ping.\nimport \"encore.app/hello\" // import service //encore:api public func MyOtherAPI(ctx context.Context) error { resp, err := hello.Ping(ctx, &hello.PingParams{Name: \"World\"}) if err == nil { log.Println(resp.Message) // \"Hello, World!\" } return err } \nThis means your development workflow is as simple as building a monolith, even if you use multiple services. You get all the benefits of function calls, like compile-time checking of all the parameters and auto-completion in your editor, while still allowing the division of code into logical components, services, and systems.\nThen when building your application, Encore uses static analysis to parse all API calls and compiles them to proper API calls.\nCurrent Request\nBy using Encore's current request API you can get meta-information about the current request. Including the type of request, the time the request started, the service and endpoint called and the path which was called on the service.\nFor more information, see the metadata documentation."
  },
  {
    "url": "https://encore.dev/docs/tutorials/incident-management-tool",
    "text": "In this tutorial, we're going to walk through together how to build our very own Incident Management Tool like Incident.io or PagerDuty. We can then have our own on call schedule that can be rotated between many users, and have incidents come and be assigned according to the schedule!\nIn about 30 minutes, your application will be able to support:\nCreating users, as well as schedules for when users will be on call\nCreating incidents, and reminders for unacknowledged incidents on Slack every 10 minutes\nAuto-assign incidents which are unassigned (when the next user is on call)\nSounds good? Let's dig in! \nOr if you'd rather watch a video of this tutorial, you can do that below.\nView full project on GitHub\nPlease note\nTo make it easier to follow along, we've laid out a trail of croissants to guide your way. Whenever you see a 🥐 it means there's something for you to do.\n1. Create your Encore application\n🥐 Create a new Encore application by running encore app create, select Empty app as the template and name it oncall-tutorial.\n2. Integrate with Slack\n🥐 Follow this guide to create your own Incoming Webhook for your Slack workspace. Incoming webhooks cannot read messages, and can only post to a specific channel of your choice.\n🥐 Once you have your Webhook URL which starts with https://hooks.slack.com/services/... then copy and paste that and run the following commands to save these as secrets. We recommend having a different webhook/channel for development and production.\n$ encore secret set --type dev,local,pr SlackWebhookURL\n$ encore secret set --type prod SlackWebhookURL\n🥐 Next, let's create our slack service that contains the logic for calling the Webhook URL in order to post notifications to our Slack. To do this we need to implement our code in slack/slack.go:\n// Service slack calls a webhook to post notifications to Slack. package slack import ( \"bytes\" \"context\" \"encoding/json\" \"encore.dev/beta/errs\" \"io\" \"net/http\" ) type NotifyParams struct { Text string `json:\"text\"` } //encore:api private func Notify(ctx context.Context, p *NotifyParams) error { eb := errs.B() reqBody, err := json.Marshal(p) if err != nil { return err } req, err := http.NewRequestWithContext(ctx, \"POST\", secrets.SlackWebhookURL, bytes.NewReader(reqBody)) if err != nil { return err } resp, err := http.DefaultClient.Do(req) if err != nil { return err } defer resp.Body.Close() if resp.StatusCode >= 400 { body, _ := io.ReadAll(resp.Body) return eb.Code(errs.Unavailable).Msgf(\"notify slack: %s: %s\", resp.Status, body).Err() } return nil } var secrets struct { SlackWebhookURL string } \nPlease note\nThe slack service can be reused across any of your Encore apps. All you need is the slack/slack.go code and the SlackWebhookURL secret to be defined. Then you can call the following method signature anywhere in your app:\nslack.Notify(context, &slack.NotifyParams{ Text: \"Send a Slack notification\" }) \n3. Create a service to manage users\nWith an Incident Management Tool (or usually any tool, for that matter) we need a service for users. This will allow us to figure out who we should assign incoming incidents to!\nTo get started, we need to create a users service with the following resources:\n#TypeDescription / Filename\n#1\tSQL Migration\tOur PostgreSQL schema for scheduling data \nusers/migrations/1_create_users.up.sql\t\n#2\tHTTP Endpoint \nPOST /users\tCreate a new User \nusers/users.go\t\n#3\tHTTP Endpoint \nGET /users/:id\tGet an existing User \nusers/users.go\t\nWith #1, let's design our database schema for a User in our system. For now let's store a first and last name as well as a Slack handle in case we need to notify them about any incidents which may have been assigned to them or acknowledged by them.\n🥐 Let's create our migration file in users/migrations/1_create_users.up.sql:\nCREATE TABLE users ( id BIGSERIAL PRIMARY KEY, first_name VARCHAR(255) NOT NULL, last_name VARCHAR(255) NOT NULL, slack_handle VARCHAR(255) NOT NULL ); \n🥐 Then, we need to write our code to implement the HTTP endpoints listed in #2 (for creating a user) and #3 (for listing a user) belonging in users/users.go. Let's split them out into three sections: our structs (i.e. data models) and methods.\n// Service users manages users and assigns incidents. package users import ( \"context\" \"encore.dev/storage/sqldb\" ) // This is a Go struct representing our PostgreSQL schema for `users` type User struct { Id int32 FirstName string LastName string SlackHandle string } // Define a database named 'users', using the database migrations // in the \"./migrations\" folder. Encore automatically provisions, // migrates, and connects to the database. var db = sqldb.NewDatabase(\"users\", sqldb.DatabaseConfig{ Migrations: \"./migrations\", }) //encore:api public method=POST path=/users func Create(ctx context.Context, params CreateParams) (*User, error) { user := User{} err := db.QueryRow(ctx, ` INSERT INTO users (first_name, last_name, slack_handle) VALUES ($1, $2, $3) RETURNING id, first_name, last_name, slack_handle `, params.FirstName, params.LastName, params.SlackHandle).Scan(&user.Id, &user.FirstName, &user.LastName, &user.SlackHandle) if err != nil { return nil, err } return &user, nil } // This is what JSON params our POST /users endpoint will accept type CreateParams struct { FirstName string LastName string SlackHandle string } //encore:api public method=GET path=/users/:id func Get(ctx context.Context, id int32) (*User, error) { user := User{} err := db.QueryRow(ctx, ` SELECT id, first_name, last_name, slack_handle FROM users WHERE id = $1 `, id).Scan(&user.Id, &user.FirstName, &user.LastName, &user.SlackHandle) if err != nil { return nil, err } return &user, nil } \n🥐 Next, type encore run in your Terminal and in a separate window run the command under cURL Request (feel free to edit the values!) to create our first user:\ncurl -d '{ \"FirstName\":\"Katy\", \"LastName\":\"Smith\", \"SlackHandle\":\"katy\" }' http://localhost:4000/users # Example JSON response # { # \"Id\":1, # \"FirstName\":\"Katy\", # \"LastName\":\"Smith\", # \"SlackHandle\":\"katy\" # } \nFantastic, we now have a user system in our app! Next we need a list of start and end times of each scheduled rotation so we know who to assign incoming incidents to (as well as notify them on Slack!)\n4. Add scheduling\nA good incident management tool should be able to spread the workload of diagnosing and fixing incidents across multiple users in a team. Being able to know who the correct person to assign an incident to is very important; our incidents might not get resolved quickly otherwise!\nIn order to achieve this, let's create a new service called schedules:\n#TypeDescription / Filename\n#1\tSQL Migration\tOur PostgreSQL schema for user data \nschedules/migrations/1_create_schedules.up.sql\t\n#2\tHTTP Endpoint \nGET /schedules\tGet list of schedules between time range \nschedules/schedules.go\t\n#3\tHTTP Endpoint \nPOST /users/:id/schedules\tCreate a new Schedule \nschedules/schedules.go\t\n#4\tHTTP Endpoint \nGET /scheduled/:timestamp\tGet Schedule at specific time \nschedules/schedules.go\t\nFor the SQL migration in #1, we need to create both a table and an index. For every rotation let's need a new entry containing the user who it is for as well as the start and end times of the scheduled rotation.\n🥐 Let's create our migration file in schedules/migrations/1_create_schedules.up.sql:\nCREATE TABLE schedules ( id BIGSERIAL PRIMARY KEY, user_id INTEGER NOT NULL, start_time TIMESTAMP NOT NULL, end_time TIMESTAMP NOT NULL ); CREATE INDEX schedules_range_index ON schedules (start_time, end_time); \nPlease note\nTable indexes are used to optimize lookups without having to search every row in the table. In this case, looking up rows against both start_time and end_time will be faster with the index as the dataset grows. Learn more about PostgreSQL indexes here.\n🥐 Next, let's implement the HTTP endpoints for #2 (listing schedules), #3 (creating a schedule) and #4 (getting the schedule/user at a specific time) in schedules/schedules.go:\n// Service schedules implements schedules to answer who should be assigned to an incident. package schedules import ( \"context\" \"errors\" \"time\" \"encore.app/users\" \"encore.dev/beta/errs\" \"encore.dev/storage/sqldb\" ) // Define a database named 'schedules', using the database migrations // in the \"./migrations\" folder. Encore automatically provisions, // migrates, and connects to the database. var db = sqldb.NewDatabase(\"schedules\", sqldb.DatabaseConfig{ Migrations: \"./migrations\", }) // This struct holds multiple Schedule structs type Schedules struct { Items []Schedule } // This is a Go struct representing our PostgreSQL schema for `schedules` type Schedule struct { Id int32 User users.User Time TimeRange } // As we use time ranges in our schedule, we created a generic TimeRange struct type TimeRange struct { Start time.Time End time.Time } //encore:api public method=POST path=/users/:userId/schedules func Create(ctx context.Context, userId int32, timeRange TimeRange) (*Schedule, error) { eb := errs.B().Meta(\"userId\", userId, \"timeRange\", timeRange) // check for existing overlapping schedules if schedule, err := ScheduledAt(ctx, timeRange.Start.String()); schedule != nil && err == nil { return nil, eb.Code(errs.InvalidArgument).Cause(err).Msg(\"schedule already exists within this start timestamp\").Err() } if schedule, err := ScheduledAt(ctx, timeRange.End.String()); schedule != nil && err == nil { return nil, eb.Code(errs.InvalidArgument).Cause(err).Msg(\"schedule already exists within this end timestamp\").Err() } // check user exists user, err := users.Get(ctx, userId) if err != nil { return nil, eb.Code(errs.Unavailable).Cause(err).Msg(\"failed to get user\").Err() } schedule := Schedule{User: *user, Time: TimeRange{}} err = db.QueryRow( ctx, `INSERT INTO schedules (user_id, start_time, end_time) VALUES ($1, $2, $3) RETURNING id, start_time, end_time`, userId, timeRange.Start, timeRange.End, ).Scan(&schedule.Id, &schedule.Time.Start, &schedule.Time.End) if err != nil { return nil, eb.Code(errs.Unavailable).Cause(err).Msg(\"failed to insert schedule\").Err() } return &schedule, nil } //encore:api public method=GET path=/scheduled func ScheduledNow(ctx context.Context) (*Schedule, error) { return scheduled(ctx, time.Now()) } //encore:api public method=GET path=/scheduled/:timestamp func ScheduledAt(ctx context.Context, timestamp string) (*Schedule, error) { eb := errs.B().Meta(\"timestamp\", timestamp) parsedtime, err := time.Parse(time.RFC3339, timestamp) if err != nil { return nil, eb.Code(errs.InvalidArgument).Msg(\"timestamp is not in a valid format\").Err() } return scheduled(ctx, parsedtime) } func scheduled(ctx context.Context, timestamp time.Time) (*Schedule, error) { eb := errs.B().Meta(\"timestamp\", timestamp) schedule, err := RowToSchedule(ctx, db.QueryRow(ctx, ` SELECT id, user_id, start_time, end_time FROM schedules WHERE start_time <= $1 AND end_time >= $1 `, timestamp.UTC())) if errors.Is(err, db.ErrNoRows) { return nil, eb.Code(errs.NotFound).Msg(\"no schedule found\").Err() } if err != nil { return nil, err } return schedule, nil } //encore:api public method=GET path=/schedules func ListByTimeRange(ctx context.Context, timeRange TimeRange) (*Schedules, error) { rows, err := db.Query(ctx, ` SELECT id, user_id, start_time, end_time FROM schedules WHERE start_time >= $1 AND end_time <= $2 ORDER BY start_time ASC `, timeRange.Start, timeRange.End) if err != nil { return nil, err } defer rows.Close() var schedules []Schedule for rows.Next() { schedule, err := RowToSchedule(ctx, rows) if err != nil { return nil, err } schedules = append(schedules, *schedule) } return &Schedules{Items: schedules}, nil } //encore:api public method=DELETE path=/schedules func DeleteByTimeRange(ctx context.Context, timeRange TimeRange) (*Schedules, error) { schedules, err := ListByTimeRange(ctx, timeRange) if err != nil { return nil, err } _, err = db.Exec(ctx, `DELETE FROM schedules WHERE start_time >= $1 AND end_time <= $2`, timeRange.Start, timeRange.End) if err != nil { return nil, err } return schedules, err } // Helper function to convert a Row object to to Schedule func RowToSchedule(ctx context.Context, row interface { Scan(dest ...interface{}) error }) (*Schedule, error) { var schedule = &Schedule{Time: TimeRange{}} var userId int32 err := row.Scan(&schedule.Id, &userId, &schedule.Time.Start, &schedule.Time.End) if err != nil { return nil, err } user, err := users.Get(ctx, userId) if err != nil { return nil, err } schedule.User = *user return schedule, nil } \n🥐 Next, type encore run in your Terminal and in a separate window run the command under cURL Request (also feel free to edit the values!) to create our first schedule against the user we created earlier:\ncurl -d '{ \"Start\":\"2023-11-28T10:00:00Z\", \"End\":\"2023-11-30T10:00:00Z\" }' \"http://localhost:4000/users/1/schedules\" # Example JSON response # { # \"Id\":1, # \"User\":{ # \"Id\":1, # \"FirstName\":\"Katy\", # \"LastName\":\"Smith\", # \"SlackHandle\":\"katy\" # }, # \"Time\":{ # \"Start\":\"2023-11-28T10:00:00Z\", # \"End\":\"2023-11-30T10:00:00Z\" # } # } \n5. Create a service to manage incidents\nSo we have users, and we know who is available to be notified (or if nobody should be notified) at any given time with the introduction of the schedules service. The only thing we're missing is the ability to report, assign and acknowledge incidents!\nThe flow we're going to implement is: an incoming incident will arrive, let's either unassign or auto-assign it based on the schedules service, and incidents have to be acknowledged. If they are not acknowledged, they will continue to be notified on Slack every 10 minutes until it has.\nTo start with, we need to create a new incidents service with the following resources:\n#TypeDescription / Filename\n#1\tSQL Migration\tOur PostgreSQL schema for storing incidents \nincidents/migrations/1_create_incidents.up.sql\t\n#2\tHTTP Endpoint \nGET /incidents\tGet list of all unacknowledged incidents \nincidents/incidents.go\t\n#3\tHTTP Endpoint \nPUT /incidents/:id/acknowledge\tAcknowledge an incident \nincidents/incidents.go\t\n#4\tHTTP Endpoint \nGET /scheduled/:timestamp\tGet \nincidents/incidents.go\t\nFor the SQL migration in #1, we need to create the table for our incidents. We need to have a one-to-many relationship between an user and an incident. That is, an incident can only be assigned to a single user but a single user can be assigned to many incidents.\n🥐 Let's create our migration file in incidents/migrations/1_create_incidents.up.sql:\nCREATE TABLE incidents ( id BIGSERIAL PRIMARY KEY, assigned_user_id INTEGER, body TEXT NOT NULL, created_at TIMESTAMP NOT NULL DEFAULT NOW(), acknowledged_at TIMESTAMP ); \n🥐 Next, our code belonging in incidents/incidents.go for being able to support incidents is below:\n// Service incidents reports, assigns and acknowledges incidents. package incidents import ( \"context\" \"encore.app/schedules\" \"encore.app/slack\" \"encore.app/users\" \"encore.dev/beta/errs\" \"encore.dev/storage/sqldb\" \"fmt\" \"time\" ) // Define a database named 'incidents', using the database migrations // in the \"./migrations\" folder. Encore automatically provisions, // migrates, and connects to the database. var db = sqldb.NewDatabase(\"incidents\", sqldb.DatabaseConfig{ Migrations: \"./migrations\", }) // This struct holds multiple Incidents structs type Incidents struct { Items []Incident } // This is a Go struct representing our PostgreSQL schema for `incidents` type Incident struct { Id int32 Body string CreatedAt time.Time Acknowledged bool AcknowledgedAt *time.Time Assignee *users.User } //encore:api public method=GET path=/incidents func List(ctx context.Context) (*Incidents, error) { rows, err := db.Query(ctx, ` SELECT id, assigned_user_id, body, created_at, acknowledged_at FROM incidents WHERE acknowledged_at IS NULL `) if err != nil { return nil, err } return RowsToIncidents(ctx, rows) } //encore:api public method=PUT path=/incidents/:id/acknowledge func Acknowledge(ctx context.Context, id int32) (*Incident, error) { eb := errs.B().Meta(\"incidentId\", id) rows, err := db.Query(ctx, ` UPDATE incidents SET acknowledged_at = NOW() WHERE acknowledged_at IS NULL AND id = $1 RETURNING id, assigned_user_id, body, created_at, acknowledged_at `, id) if err != nil { return nil, err } incidents, err := RowsToIncidents(ctx, rows) if err != nil { return nil, err } if incidents.Items == nil { return nil, eb.Code(errs.NotFound).Msg(\"no incident found\").Err() } incident := &incidents.Items[0] _ = slack.Notify(ctx, &slack.NotifyParams{ Text: fmt.Sprintf(\"Incident #%d assigned to %s %s <@%s> has been acknowledged:\\n%s\", incident.Id, incident.Assignee.FirstName, incident.Assignee.LastName, incident.Assignee.SlackHandle, incident.Body), }) return incident, err } //encore:api public method=POST path=/incidents func Create(ctx context.Context, params *CreateParams) (*Incident, error) { // check who is on-call schedule, err := schedules.ScheduledNow(ctx) incident := Incident{} if schedule != nil { incident.Assignee = &schedule.User } var row *db.Row if schedule != nil { // Someone is on-call row = db.QueryRow(ctx, ` INSERT INTO incidents (assigned_user_id, body) VALUES ($1, $2) RETURNING id, body, created_at `, &schedule.User.Id, params.Body) } else { // Nobody is on-call row = db.QueryRow(ctx, ` INSERT INTO incidents (body) VALUES ($1) RETURNING id, body, created_at `, params.Body) } if err = row.Scan(&incident.Id, &incident.Body, &incident.CreatedAt); err != nil { return nil, err } var text string if incident.Assignee != nil { text = fmt.Sprintf(\"Incident #%d created and assigned to %s %s <@%s>\\n%s\", incident.Id, incident.Assignee.FirstName, incident.Assignee.LastName, incident.Assignee.SlackHandle, incident.Body) } else { text = fmt.Sprintf(\"Incident #%d created and unassigned\\n%s\", incident.Id, incident.Body) } _ = slack.Notify(ctx, &slack.NotifyParams{Text: text}) return &incident, nil } type CreateParams struct { Body string } // Helper to take a db.Rows instance and convert it into a list of Incidents func RowsToIncidents(ctx context.Context, rows *db.Rows) (*Incidents, error) { eb := errs.B() defer rows.Close() var incidents []Incident for rows.Next() { var incident = Incident{} var assignedUserId *int32 if err := rows.Scan(&incident.Id, &assignedUserId, &incident.Body, &incident.CreatedAt, &incident.AcknowledgedAt); err != nil { return nil, eb.Code(errs.Unknown).Msgf(\"could not scan: %v\", err).Err() } if assignedUserId != nil { user, err := users.Get(ctx, *assignedUserId) if err != nil { return nil, eb.Code(errs.NotFound).Msgf(\"could not retrieve user for incident %v\", assignedUserId).Err() } incident.Assignee = user } incident.Acknowledged = incident.AcknowledgedAt != nil incidents = append(incidents, incident) } return &Incidents{Items: incidents}, nil } \nFantastic! We have an almost working application. The main two things we're missing are:\nFor unacknowledged incidents, we need to post a reminder on Slack every 10 minutes until they have been acknolwedged.\nWhenever a user is currently on call, we should assign all previously unassigned incidents to them.\n🥐 To achieve this, we'll need to create two Cron Jobs which thankfully Encore makes incredibly simple. So let's go ahead and create the first one for reminding us every 10 minutes of incidents we haven't acknowledged. Go ahead and add the code below to our incidents/incidents.go file:\n// Track unacknowledged incidents var _ = cron.NewJob(\"unacknowledged-incidents-reminder\", cron.JobConfig{ Title: \"Notify on Slack about incidents which are not acknowledged\", Every: 10 * cron.Minute, Endpoint: RemindUnacknowledgedIncidents, }) //encore:api private func RemindUnacknowledgedIncidents(ctx context.Context) error { incidents, err := List(ctx) // we never query for acknowledged incidents if err != nil { return err } if incidents == nil { return nil } var items = []string{\"These incidents have not been acknowledged yet. Please acknowledge them otherwise you will be reminded every 10 minutes:\"} for _, incident := range incidents.Items { var assignee string if incident.Assignee != nil { assignee = fmt.Sprintf(\"%s %s (<@%s>)\", incident.Assignee.FirstName, incident.Assignee.LastName, incident.Assignee.SlackHandle) } else { assignee = \"Unassigned\" } items = append(items, fmt.Sprintf(\"[%s] [#%d] %s\", assignee, incident.Id, incident.Body)) } if len(incidents.Items) > 0 { _ = slack.Notify(ctx, &slack.NotifyParams{Text: strings.Join(items, \"\\n\")}) } return nil } \nAnd for our second cronjob, when someone goes on call we need to automatically assign the previously unassigned incidents to them. We don't have a HTTP endpoint for assigning incidents so we need to implement a PUT /incidents/:id/assign endpoint.\n🥐 So let's also add that endpoint as well as the cronjob code to our incidents/incidents.go file:\n//encore:api public method=PUT path=/incidents/:id/assign func Assign(ctx context.Context, id int32, params *AssignParams) (*Incident, error) { eb := errs.B().Meta(\"params\", params) rows, err := db.Query(ctx, ` UPDATE incidents SET assigned_user_id = $1 WHERE acknowledged_at IS NULL AND id = $2 RETURNING id, assigned_user_id, body, created_at, acknowledged_at `, params.UserId, id) if err != nil { return nil, err } incidents, err := RowsToIncidents(ctx, rows) if err != nil { return nil, err } if incidents.Items == nil { return nil, eb.Code(errs.NotFound).Msg(\"no incident found\").Err() } incident := &incidents.Items[0] _ = slack.Notify(ctx, &slack.NotifyParams{ Text: fmt.Sprintf(\"Incident #%d is re-assigned to %s %s <@%s>\\n%s\", incident.Id, incident.Assignee.FirstName, incident.Assignee.LastName, incident.Assignee.SlackHandle, incident.Body), }) return incident, err } type AssignParams struct { UserId int32 } var _ = cron.NewJob(\"assign-unassigned-incidents\", cron.JobConfig{ Title: \"Assign unassigned incidents to user on-call\", Every: 1 * cron.Minute, Endpoint: AssignUnassignedIncidents, }) //encore:api private func AssignUnassignedIncidents(ctx context.Context) error { // if this fails, we don't have anyone on call so let's skip this schedule, err := schedules.ScheduledNow(ctx) if err != nil { return err } incidents, err := List(ctx) // we never query for acknowledged incidents if err != nil { return err } for _, incident := range incidents.Items { if incident.Assignee != nil { continue // this incident has already been assigned } _, err := Assign(ctx, incident.Id, &AssignParams{UserId: schedule.User.Id}) if err == nil { rlog.Info(\"OK assigned unassigned incident\", \"incident\", incident, \"user\", schedule.User) } else { rlog.Error(\"FAIL to assign unassigned incident\", \"incident\", incident, \"user\", schedule.User, \"err\", err) return err } } return nil } \n🥐 Next, call encore run in your Terminal and in a separate window run the command under cURL Request (also feel free to edit the values!) to trigger our first incident. Most likely we won't have an assigned user unless you have scheduled a time that overlaps with right now in the last cURL request for creating a schedule:\ncurl -d '{ \"Body\":\"An unexpected error happened on example-website.com on line 38. It needs addressing now!\" }' http://localhost:4000/incidents # Example JSON response # { # \"Id\":1, # \"Body\":\"An unexpected error happened on example-website.com on line 38. It needs addressing now!\", # \"CreatedAt\":\"2022-09-28T15:09:00Z\", # \"Acknowledged\":false, # \"AcknowledgedAt\":null, # \"Assignee\":null # } \n6. Try your app and deploy\nCongratulations! Our application looks ready for others to try - we have our users, schedules incidents and slack services along with 3 database tables and 2 cronjobs. Even better that all of the deployment and maintenance is taken care by Encore!\n🥐 To try out your application, type encore run in your Terminal and run the following cURL commands:\n# Step 1: Create a User and copy the User ID to your clipboard curl -d '{ \"FirstName\":\"Katy\", \"LastName\":\"Smith\", \"SlackHandle\":\"katy\" }' http://localhost:4000/users # Step 2: Create a schedule for the user we just created curl -d '{ \"Start\":\"2022-09-28T10:00:00Z\", \"End\":\"2022-09-29T10:00:00Z\" }' \"http://localhost:4000/users/1/schedules\" # Step 3: Trigger an incident curl -d '{ \"Body\":\"An unexpected error happened on example-website.com on line 38. It needs addressing now!\" }' http://localhost:4000/incidents # Step 4: Acknowledge the Incident curl -X PUT \"http://localhost:4000/incidents/1/acknowledge\" \nAnd if you don't acknowledge incoming incidents on Step 4, you will be reminded on Slack every 10 minutes:\nDeploy to the cloud\n🥐 Push your changes and deploy your application to Encore's free development cloud by running:\n$ git add -A .\n$ git commit -m 'Initial commit'\n$ git push encore\nEncore will now build and test your app, provision the needed infrastructure, and deploy your application to the cloud.\nAfter triggering the deployment, you will see a URL where you can view its progress in Encore's Cloud Dashboard. It will look something like: https://app.encore.dev/$APP_ID/deploys/...\nFrom there you can also see metrics, traces, link your app to a GitHub repo to get automatic deploys on new commits, and connect your own AWS or GCP account to use for production deployment.\nCelebrate with fireworks\nNow that your app is running in the cloud, let's celebrate with some fireworks:\n🥐 In the Cloud Dashboard, open the Command Menu by pressing Cmd + K (Mac) or Ctrl + K (Windows/Linux).\nFrom here you can easily access all Cloud Dashboard features and for example jump straight to specific services in the Service Catalog or view Traces for specific endpoints.\n🥐 Type fireworks in the Command Menu and press enter. Sit back and enjoy the show!\nArchitecture Diagram\nTake a look at the Encore Flow diagram that was automatically generated for our new application too!\nGitHub Repository\n🥐 Check out the example-app-oncall repository on GitHub for this example which includes additional features and tests: https://github.com/encoredev/example-app-oncall\nAlternatively, you can clone our example application by running this in your Terminal:\n$ encore app create --example https://github.com/encoredev/example-app-oncall\nFeedback\n🥐 We'd love to hear your thoughts about this tutorial and learn about what you're building next. Let us know by tweeting your experience, blog about it, or talk to us about it on Slack."
  },
  {
    "url": "https://encore.dev/docs/develop/databases",
    "text": "Encore treats SQL databases as logical resources and natively supports PostgreSQL databases.\nCreating a database\nTo create a database, import encore.dev/storage/sqldb and call sqldb.NewDatabase, assigning the result to a package-level variable. Databases must be created from within an Encore service.\nFor example:\ntodo/db.go\ntodo/migrations/1_create_table.up.sql\npackage todo // Create the todo database and assign it to the \"tododb\" variable var tododb = sqldb.NewDatabase(\"todo\", sqldb.DatabaseConfig{ Migrations: \"./migrations\", }) // Then, query the database using db.QueryRow, db.Exec, etc. \nAs seen above, the sqldb.DatabaseConfig specifies the directory containing the database migration files, which is how you define the database schema. See the Defining the database schema section below for more details.\nWith this code in place Encore will automatically create the database when starting encore run (locally) or on the next deployment (in the cloud). Encore automatically injects the appropriate configuration to authenticate and connect to the database, so once the application starts up the database is ready to be used.\nDefining the database schema\nDatabase schemas are defined by creating migration files in a directory named migrations within an Encore service package. Each migration file is named <number>_<name>.up.sql, where <number> is a sequence number for ordering the migrations and <name> is a descriptive name of what the migration does.\nOn disk it might look like this:\n/my-app ├── encore.app // ... and other top-level project files │ └── todo // todo service (a Go package) ├── migrations // todo service db migrations (directory) │ ├── 1_create_table.up.sql // todo service db migration │ └── 2_add_field.up.sql // todo service db migration ├── todo.go // todo service code └── todo_test.go // tests for todo service \nEach migration runs in order and expresses the change in the database schema from the previous migration.\nThe file name format is important. Migration files must be sequentially named, starting with 1_ and counting up for each migration. Each file name must also end with .up.sql.\nThe first migration usually defines the initial table structure. For example, a todo service might start out by creating todo/migrations/1_create_table.up.sql with the following contents:\nCREATE TABLE todo_item ( id BIGSERIAL PRIMARY KEY, title TEXT NOT NULL, done BOOLEAN NOT NULL DEFAULT false ); \nProvisioning databases\nEncore automatically provisions databases to match what your application requires. When you define a database, Encore will provision the database at your next deployment.\nEncore provisions databases in an appropriate way depending on the environment. When running locally, Encore creates a database cluster using Docker. In the cloud, it depends on the environment type:\nIn production environments, the database is provisioned through the Managed SQL Database service offered by the chosen cloud provider.\nIn development environments, the database is provisioned as a Kubernetes deployment with a persistent disk attached.\nSee exactly what is provisioned for each cloud provider, and each environment type, in the infrastructure documentation.\nInserting data into databases\nOnce you have created the database using var mydb = sqldb.NewDatabase(...) you can start inserting data into the database by calling methods on the mydb variable.\nThe interface is similar to that of the Go standard library's database/sql package. Learn more in the package docs.\nOne way of inserting data is with a helper function that uses the package function sqldb.Exec. For example, to insert a single todo item using the example schema above, we can use the following helper function insert:\ntodo/insert.go\ntodo/db.go\ntodo/migrations/1_create_table.up.sql\n// insert inserts a todo item into the database. func insert(ctx context.Context, id, title string, done bool) error { _, err := tododb.Exec(ctx, ` INSERT INTO todo_item (id, title, done) VALUES ($1, $2, $3) `, id, title, done) return err } \nQuerying databases\nTo query a database in your application, you similarly need to import encore.dev/storage/sqldb in your service package or sub-package.\nFor example, to read a single todo item in the example schema above, we can use sqldb.QueryRow:\nvar item struct { ID int64 Title string Done bool } err := tododb.QueryRow(ctx, ` SELECT id, title, done FROM todo_item LIMIT 1 `).Scan(&item.ID, &item.Title, &item.Done) \nIf QueryRow does not find a matching row, it reports an error that can be checked against by importing the standard library errors package and calling errors.Is(err, sqldb.ErrNoRows).\nLearn more in the package docs.\nConnecting to databases\nIt's often useful to be able to connect to the database from outside the backend application. For example for scripts, ad-hoc querying, or dumping data for analysis.\nUsing the Encore CLI\nEncore's CLI comes with built-in support for connecting to databases:\nencore db shell <database-name> [--env=<name>] opens a psql shell to the database named <database-name> in the given environment. Leaving out --env defaults to the local development environment.\nencore db conn-uri <database-name> [--env=<name>] outputs a connection string for the database named <database-name>. When specifying a cloud environment, the connection string is temporary. Leaving out --env defaults to the local development environment.\nencore db proxy [--env=<name>] sets up a local proxy that forwards any incoming connection to the databases in the specified environment. Leaving out --env defaults to the local development environment.\nSee encore help db for more information on database management commands.\nUsing database user credentials\nFor cloud environments you can view database user credentials (created by Encore when provisioning databases) via the Cloud Dashboard:\nOpen your app in the Cloud Dashboard, navigate to the Infrastructure page for the appropriate environment, and locate the USERS section within the relevant Database Cluster.\nHandling migration errors\nWhen Encore applies database migrations, there's always a possibility the migrations don't apply cleanly.\nThis can happen for many reasons:\nThere's a problem with the SQL syntax in the migration\nYou tried to add a UNIQUE constraint but the values in the table aren't actually unique\nThe existing database schema didn't look like you thought it did, so the database object you tried to change doesn't actually exist\n... and so on\nIf that happens, Encore rolls back the migration. If it happens during a cloud deployment, the deployment is aborted. Once you fix the problem, re-run encore run (locally) or push the updated code (in the cloud) to try again.\nEncore tracks which migrations have been applied in the schema_migrations table:\ndatabase=# \\d schema_migrations Table \"public.schema_migrations\" Column | Type | Collation | Nullable | Default ---------+---------+-----------+----------+--------- version | bigint | | not null | dirty | boolean | | not null | Indexes: \"schema_migrations_pkey\" PRIMARY KEY, btree (version) \nThe version column tracks which migration was last applied. If you wish to skip a migration or re-run a migration, change the value in this column. For example, to re-run the last migration, run UPDATE schema_migrations SET version = version - 1;. Note that Encore does not use the dirty flag by default.\nPostgreSQL Extensions\nEncore uses the encoredotdev/postgres docker image for local development, CI/CD, and for databases hosted on Encore Cloud.\nThis docker image ships with many popular PostgreSQL extensions pre-installed. In particular, pgvector and PostGIS are available.\nSee the full list of available extensions.\nTroubleshooting\nApplication won't run\nWhen you run your application locally with encore run, Encore will parse and compile your application, and provision the necessary infrastructure including databases. If this fails with a database error, there are a few common causes.\nError: sqldb: unknown database \nThis error is often caused by a problem with the initial migration file, such as incorrect naming or location.\nVerify that you've created the migration file correctly, then try encore run again.\nError: could not connect to the database \nWhen you can't connect to the database in your local environment, there's likely an issue with Docker:\nMake sure that you have Docker installed and running, then try encore run again.\nIf this fails, restart the Encore daemon by running encore daemon, then try encore run again.\nError: Creating PostgreSQL database cluster Failed \nThis means Encore was not able to create the database. Often this is due to a problem with Docker.\nCheck if you have permission to access Docker by running docker images.\nSet the correct permissions with sudo usermod -aG docker $USER (Learn more in the Docker documentation)\nThen log out and log back in so that your group membership is refreshed.\nError: unable to add CA to cert pool \nThis error is commonly caused by the presence of the file $HOME/.postgresql/root.crt on the filesystem. When this file is present the PostgreSQL client library will assume the database server has that root certificate, which will cause the above error.\nRemove or rename the file, then try encore run again."
  },
  {
    "url": "https://encore.dev/docs/primitives/databases",
    "text": "Encore treats SQL databases as logical resources and natively supports PostgreSQL databases.\nCreating a database\nTo create a database, import encore.dev/storage/sqldb and call sqldb.NewDatabase, assigning the result to a package-level variable. Databases must be created from within an Encore service.\nFor example:\ntodo/db.go\ntodo/migrations/1_create_table.up.sql\npackage todo // Create the todo database and assign it to the \"tododb\" variable var tododb = sqldb.NewDatabase(\"todo\", sqldb.DatabaseConfig{ Migrations: \"./migrations\", }) // Then, query the database using db.QueryRow, db.Exec, etc. \nAs seen above, the sqldb.DatabaseConfig specifies the directory containing the database migration files, which is how you define the database schema. See the Defining the database schema section below for more details.\nWith this code in place Encore will automatically create the database when starting encore run (locally) or on the next deployment (in the cloud). Encore automatically injects the appropriate configuration to authenticate and connect to the database, so once the application starts up the database is ready to be used.\nDefining the database schema\nDatabase schemas are defined by creating migration files in a directory named migrations within an Encore service package. Each migration file is named <number>_<name>.up.sql, where <number> is a sequence number for ordering the migrations and <name> is a descriptive name of what the migration does.\nOn disk it might look like this:\n/my-app ├── encore.app // ... and other top-level project files │ └── todo // todo service (a Go package) ├── migrations // todo service db migrations (directory) │ ├── 1_create_table.up.sql // todo service db migration │ └── 2_add_field.up.sql // todo service db migration ├── todo.go // todo service code └── todo_test.go // tests for todo service \nEach migration runs in order and expresses the change in the database schema from the previous migration.\nThe file name format is important. Migration files must be sequentially named, starting with 1_ and counting up for each migration. Each file name must also end with .up.sql.\nThe first migration usually defines the initial table structure. For example, a todo service might start out by creating todo/migrations/1_create_table.up.sql with the following contents:\nCREATE TABLE todo_item ( id BIGSERIAL PRIMARY KEY, title TEXT NOT NULL, done BOOLEAN NOT NULL DEFAULT false ); \nProvisioning databases\nEncore automatically provisions databases to match what your application requires. When you define a database, Encore will provision the database at your next deployment.\nEncore provisions databases in an appropriate way depending on the environment. When running locally, Encore creates a database cluster using Docker. In the cloud, it depends on the environment type:\nIn production environments, the database is provisioned through the Managed SQL Database service offered by the chosen cloud provider.\nIn development environments, the database is provisioned as a Kubernetes deployment with a persistent disk attached.\nSee exactly what is provisioned for each cloud provider, and each environment type, in the infrastructure documentation.\nInserting data into databases\nOnce you have created the database using var mydb = sqldb.NewDatabase(...) you can start inserting data into the database by calling methods on the mydb variable.\nThe interface is similar to that of the Go standard library's database/sql package. Learn more in the package docs.\nOne way of inserting data is with a helper function that uses the package function sqldb.Exec. For example, to insert a single todo item using the example schema above, we can use the following helper function insert:\ntodo/insert.go\ntodo/db.go\ntodo/migrations/1_create_table.up.sql\n// insert inserts a todo item into the database. func insert(ctx context.Context, id, title string, done bool) error { _, err := tododb.Exec(ctx, ` INSERT INTO todo_item (id, title, done) VALUES ($1, $2, $3) `, id, title, done) return err } \nQuerying databases\nTo query a database in your application, you similarly need to import encore.dev/storage/sqldb in your service package or sub-package.\nFor example, to read a single todo item in the example schema above, we can use sqldb.QueryRow:\nvar item struct { ID int64 Title string Done bool } err := tododb.QueryRow(ctx, ` SELECT id, title, done FROM todo_item LIMIT 1 `).Scan(&item.ID, &item.Title, &item.Done) \nIf QueryRow does not find a matching row, it reports an error that can be checked against by importing the standard library errors package and calling errors.Is(err, sqldb.ErrNoRows).\nLearn more in the package docs.\nConnecting to databases\nIt's often useful to be able to connect to the database from outside the backend application. For example for scripts, ad-hoc querying, or dumping data for analysis.\nUsing the Encore CLI\nEncore's CLI comes with built-in support for connecting to databases:\nencore db shell <database-name> [--env=<name>] opens a psql shell to the database named <database-name> in the given environment. Leaving out --env defaults to the local development environment.\nencore db conn-uri <database-name> [--env=<name>] outputs a connection string for the database named <database-name>. When specifying a cloud environment, the connection string is temporary. Leaving out --env defaults to the local development environment.\nencore db proxy [--env=<name>] sets up a local proxy that forwards any incoming connection to the databases in the specified environment. Leaving out --env defaults to the local development environment.\nSee encore help db for more information on database management commands.\nUsing database user credentials\nFor cloud environments you can view database user credentials (created by Encore when provisioning databases) via the Cloud Dashboard:\nOpen your app in the Cloud Dashboard, navigate to the Infrastructure page for the appropriate environment, and locate the USERS section within the relevant Database Cluster.\nHandling migration errors\nWhen Encore applies database migrations, there's always a possibility the migrations don't apply cleanly.\nThis can happen for many reasons:\nThere's a problem with the SQL syntax in the migration\nYou tried to add a UNIQUE constraint but the values in the table aren't actually unique\nThe existing database schema didn't look like you thought it did, so the database object you tried to change doesn't actually exist\n... and so on\nIf that happens, Encore rolls back the migration. If it happens during a cloud deployment, the deployment is aborted. Once you fix the problem, re-run encore run (locally) or push the updated code (in the cloud) to try again.\nEncore tracks which migrations have been applied in the schema_migrations table:\ndatabase=# \\d schema_migrations Table \"public.schema_migrations\" Column | Type | Collation | Nullable | Default ---------+---------+-----------+----------+--------- version | bigint | | not null | dirty | boolean | | not null | Indexes: \"schema_migrations_pkey\" PRIMARY KEY, btree (version) \nThe version column tracks which migration was last applied. If you wish to skip a migration or re-run a migration, change the value in this column. For example, to re-run the last migration, run UPDATE schema_migrations SET version = version - 1;. Note that Encore does not use the dirty flag by default.\nPostgreSQL Extensions\nEncore uses the encoredotdev/postgres docker image for local development, CI/CD, and for databases hosted on Encore Cloud.\nThis docker image ships with many popular PostgreSQL extensions pre-installed. In particular, pgvector and PostGIS are available.\nSee the full list of available extensions.\nTroubleshooting\nApplication won't run\nWhen you run your application locally with encore run, Encore will parse and compile your application, and provision the necessary infrastructure including databases. If this fails with a database error, there are a few common causes.\nError: sqldb: unknown database \nThis error is often caused by a problem with the initial migration file, such as incorrect naming or location.\nVerify that you've created the migration file correctly, then try encore run again.\nError: could not connect to the database \nWhen you can't connect to the database in your local environment, there's likely an issue with Docker:\nMake sure that you have Docker installed and running, then try encore run again.\nIf this fails, restart the Encore daemon by running encore daemon, then try encore run again.\nError: Creating PostgreSQL database cluster Failed \nThis means Encore was not able to create the database. Often this is due to a problem with Docker.\nCheck if you have permission to access Docker by running docker images.\nSet the correct permissions with sudo usermod -aG docker $USER (Learn more in the Docker documentation)\nThen log out and log back in so that your group membership is refreshed.\nError: unable to add CA to cert pool \nThis error is commonly caused by the presence of the file $HOME/.postgresql/root.crt on the filesystem. When this file is present the PostgreSQL client library will assume the database server has that root certificate, which will cause the above error.\nRemove or rename the file, then try encore run again."
  },
  {
    "url": "https://encore.dev/docs/primitives/cron-jobs",
    "text": "When you need to run periodic and recurring tasks, Encore's Infrastructure SDK provides a declarative way of using Cron Jobs.\nWhen a Cron Job is defined, Encore will call the API of your choice on the schedule you have defined. This means there is no need to maintain any infrastructure, as Encore handles the scheduling, monitoring and execution of Cron Jobs.\nDefining a Cron Job\nTo define a Cron Job, all you need to do is to import the encore.dev/cron package, and call the cron.NewJob() function and store it as a package-level variable:\nimport \"encore.dev/cron\" // Send a welcome email to everyone who signed up in the last two hours. var _ = cron.NewJob(\"welcome-email\", cron.JobConfig{ Title: \"Send welcome emails\", Every: 2 * cron.Hour, Endpoint: SendWelcomeEmail, }) // SendWelcomeEmail emails everyone who signed up recently. // It's idempotent: it only sends a welcome email to each person once. //encore:api private func SendWelcomeEmail(ctx context.Context) error { // ... return nil } \nThe \"welcome-email\" argument to cron.NewJob is a unique ID you give to each Cron Job. If you later refactor the code and move the Cron Job definition to another package, we use this ID to keep track that it's the same Cron Job and not a different one.\nWhen this code gets deployed Encore will automatically register the Cron Job in Encore Cloud and begin calling the SendWelcomeEmail API every hour.\nEncore's Cloud Dashboard provides a convenient user interface for monitoring and debugging Cron Job executions across all your environments via the Cron Jobs menu item:\nA few important things to know:\nCron Jobs do not run when developing locally or in Preview Environments; but you can always call the API manually to test the behavior.\nCron Jobs execution in Encore Cloud is capped at once every hour for users on the Free Tier; deploy to your own cloud or upgrade to the Pro plan to use more frequent executions.\nCron Jobs support both public and private APIs.\nThe API endpoints used in Cron Jobs should always be idempotent. It's possible they're called multiple times in some network conditions.\nThe API endpoints used in Cron Jobs must not take any request parameters. That is, their signatures must be func(context.Context) error or func(context.Context) (*T, error).\nCron schedules\nAbove we used the Every field, which executes the Cron Job on a periodic basis. It runs around the clock each day, starting at midnight (UTC).\nIn order to ensure a consistent delay between each run, the interval used must divide 24 hours evenly. For example, 10 * cron.Minute and 6 * cron.Hour are both allowed (since 24 hours is evenly divisible by both), whereas 7 * cron.Hour is not (since 24 is not evenly divisible by 7). The Encore compiler will catch this and give you a helpful error at compile-time if you try to use an invalid interval.\nCron expressions\nFor more advanced use cases, such as running a Cron Job on a specific day of the month, or a specific week day, or similar, the Every field is not expressive enough.\nFor these use cases, Encore provides full support for Cron expressions by using the Schedule field instead of the Every field.\nCron expressions allow you to define precise schedules for your tasks, including specific days of the week, specific hours of the day, and more. Note that all times are expressed in UTC.\nFor example:\n// Run the monthly accounting sync job at 4am (UTC) on the 15th day of each month. var _ = cron.NewJob(\"accounting-sync\", cron.JobConfig{ Title: \"Cron Job Example\", Schedule: \"0 4 15 * *\", Endpoint: AccountingSync, })"
  },
  {
    "url": "https://encore.dev/docs/primitives/pubsub",
    "text": "Publishers & Subscribers (Pub/Sub) let you build systems that communicate by broadcasting events asynchronously. This is a great way to decouple services for better reliability and responsiveness.\nEncore's Infrastructure SDK lets you use Pub/Sub in a cloud-agnostic declarative fashion. At deployment, Encore automatically provisions the required infrastructure.\nCreating a Topic\nThe core of Pub/Sub is the Topic, a named channel on which you publish events. Topics must be declared as package level variables, and cannot be created inside functions. Regardless of where you create a topic, it can be published to from any service, and subscribed to from any service.\nWhen creating a topic, it must be given an event type, a unique name, and a configuration to define its behaviour. See the complete specification in the package documentation.\nFor example, to create a topic with events about user signups:\npackage user import \"encore.dev/pubsub\" type SignupEvent struct{ UserID int } var Signups = pubsub.NewTopic[*SignupEvent](\"signups\", pubsub.TopicConfig{ DeliveryGuarantee: pubsub.AtLeastOnce, }) \nAt-least-once delivery\nThe above example configures the topic to ensure that, for each subscription, events will be delivered at least once.\nThis means that if the topic believes the event was not processed, it will attempt to deliver the message again. Therefore, all subscription handlers should be idempotent. This helps ensure that if the handler is called two or more times, from the outside there's no difference compared to calling it once.\nThis can be achieved using a database to track if you have already performed the action that the event is meant to trigger, or ensuring that the action being performed is also idempotent in nature.\nExactly-once delivery\nTopics can also be configured to deliver events exactly once by setting the DeliveryGuarantee field to pubsub.ExactlyOnce. This enables stronger guarantees on the infrastructure level to minimize the likelihood of message re-delivery.\nHowever, there are still some rare circumstances when a message might be redelivered. For example, if a networking issue causes the acknowledgement of successful processing the message to be lost before the cloud provider receives it (the Two Generals' Problem). As such, if correctness is critical under all circumstances, it's still advisable to design your subscription handlers to be idempotent.\nBy enabling exactly-once delivery on a topic the cloud provider enforces certain throughput limitations:\nAWS: 300 messages per second for the topic (see AWS SQS Quotas).\nGCP: At least 3,000 messages per second across all topics in the region (can be higher on the region see GCP PubSub Quotas).\nTake care\nExactly-once delivery does not perform message deduplication on the publishing side. If Publish is called twice with the same message, the message will be delivered twice.\nOrdered Topics\nTopics are unordered by default, meaning that messages can be delivered in any order. This allows for better throughput on the topic as messages can be processed in parallel. However, in some cases, messages must be delivered in the order they were published for a given entity.\nTo create an ordered topic, configure the topic's OrderingAttribute to match the pubsub-attr tag on one of the top-level fields of the event type. This field ensures that messages delivered to the same subscriber are delivered in the order of publishing for that specific field value. Messages with a different value on the ordering attribute are delivered in an unspecified order.\nTo maintain topic order, messages with the same ordering key aren't delivered until the earliest message is processed or dead-lettered, potentially causing delays due to head-of-line blocking. Mitigate processing issues by ensuring robust logging and alerts, and appropriate subscription retry policies.\nPlease note\nThe OrderingAttribute currently has no effect in local environments.\nThroughput limitations\nEach cloud provider enforces certain throughput limitations for ordered topics:\nAWS: 300 messages per second for the topic (see AWS SQS Quotas)\nGCP: 1 MBps for each ordering key (See GCP Pub/Sub Resource Limits)\nOrdered topic example\npackage example import ( \"context\" \"encore.dev/pubsub\" ) type CartEvent struct { ShoppingCartID int `pubsub-attr:\"cart_id\"` Event string } var CartEvents = pubsub.NewTopic[*CartEvent](\"cart-events\", pubsub.TopicConfig{ DeliveryGuarantee: pubsub.AtLeastOnce, OrderingAttribute: \"cart_id\", }) func Example(ctx context.Context) error { // These are delivered in order as they all have the same shopping cart ID CartEvents.Publish(ctx, &CartEvent{ShoppingCartID: 1, Event: \"item_added\"}) CartEvents.Publish(ctx, &CartEvent{ShoppingCartID: 1, Event: \"checkout_started\"}) CartEvents.Publish(ctx, &CartEvent{ShoppingCartID: 1, Event: \"checkout_completed\"}) // This event may be delivered at any point as it has a different shopping cart ID CartEvents.Publish(ctx, &CartEvent{ShoppingCartID: 2, Event: \"item_added\"}) } \nPublishing events\nTo publish an Event, call Publish on the topic passing in the event object (which is the type specified in the pubsub.NewTopic[Type] constructor).\nFor example:\nmessageID, err := Signups.Publish(ctx, &SignupEvent{UserID: id}) if err != nil { return err } // If we get here the event has been successfully published, // and all registered subscribers will receive the event. // The messageID variable contains the unique id of the message, // which is also provided to the subscribers when processing the event. \nBy defining the Signups topic variable as an exported variable you can also publish to the topic from other services in the same way.\nUsing topic references\nEncore uses static analysis to determine which services are publishing messages to what topics. That information is used to provision infrastructure correctly, render architecture diagrams, and configure IAM permissions.\nThis means that *pubsub.Topic variables can't be passed around however you'd like, as it makes static analysis impossible in many cases. To work around these restrictions Encore allows you to get a reference to a topic that can be passed around any way you want.\nIt looks like this (using the Signups topic above):\nsignupRef := pubsub.TopicRef[pubsub.Publisher[*SignupEvent]](Signups) // signupRef is of type pubsub.Publisher[*SignupEvent], which allows publishing. \nThe difference between a TopicRef and a Topic is that topic references need to pre-declare what permissions are needed. Encore then assumes that all the permissions you declare are used.\nFor example, if you declare a TopicRef with the pubsub.Publisher permission (as seen above) Encore assumes that the service will publish messages to the topic and provisions the infrastructure to support that.\nNote that a TopicRef must be declared within a service, but the reference itself can be freely passed around to library code, be dependency injected into service structs, and so on.\nSubscribing to Events\nTo Subscribe to events, you create a Subscription as a package level variable by calling the pubsub.NewSubscription function.\nEach subscription needs:\nthe topic to subscribe to\na name which is unique for the topic\na configuration object with at least a Handler function to process the events\na configuration object\nHere's an example of how you create a subscription to a topic:\npackage email import ( \"encore.dev/pubsub\" \"user\" ) var _ = pubsub.NewSubscription( user.Signups, \"send-welcome-email\", pubsub.SubscriptionConfig[*SignupEvent]{ Handler: SendWelcomeEmail, }, ) func SendWelcomeEmail(ctx context.Context, event *SignupEvent) error { // send email... return nil } \nSubscriptions can be in the same service as the topic is declared, or in any other service of your application. Each subscription to a single topic receives the events independently of any other subscriptions to the same topic. This means that if one subscription is running very slowly, it will grow a backlog of unprocessed events. However, any other subscriptions will still be processing events in real-time as they are published.\nThe ctx passed to the handler function is cancelled when the AckDeadline for the subscription is reached. This is the time when the message is considered to have timed out and can be redelivered to another subscriber. The timeout defaults to 30 seconds if you don't explicitly configure AckDeadline.\nMethod-based handlers\nWhen using service structs for dependency injection it's common to want to define the subscription handler as a method on the service struct, to be able to access the injected dependencies. The pubsub package provides the pubsub.MethodHandler function for this purpose:\n//encore:service type Service struct { /* ... */ } func (s *Service) SendWelcomeEmail(ctx context.Context, event *SignupEvent) error { // ... } var _ = pubsub.NewSubscription( user.Signups, \"send-welcome-email\", pubsub.SubscriptionConfig[*SignupEvent]{ Handler: pubsub.MethodHandler((*Service).SendWelcomeEmail), }, ) \nNote that pubsub.MethodHandler only allows referencing methods on the service struct type, not any other type.\nSubscription configuration\nWhen creating a subscription you can configure behavior such as message retention and retry policy, using the SubscriptionConfig type. See the package documentation for the complete configuration options.\nPlease note\nThe SubscriptionConfig struct fields must be defined as compile-time constants, and cannot be defined in terms of function calls. This is necessary for Encore to understand the exact requirements of the subscription, in order to provision the correct infrastructure upon deployment.\nError Handling\nIf a subscription function returns an error, the event being processed will be retried, based on the retry policy configured on that subscription. After the MaxRetries is hit, the event will be placed into a dead-letter queue (DLQ) for that subscriber. This allows the subscription to continue processing events until the bug which caused the event to fail can be fixed. Once fixed, the messages on the dead-letter queue can be manually released to be processed again by the subscriber.\nTesting Pub/Sub\nEncore uses a special testing implementation of Pub/Sub topics. When running tests, topics are aware of which test is running. This gives you the following guarantees:\nYour subscriptions will not be triggered by events published. This allows you to test the behaviour of publishers independently of side effects caused by subscribers.\nMessage ID's generated on publish are deterministic (based on the order of publishing), thus your assertions can make use of that fact.\nEach test is isolated from other tests, meaning that events published in one test will not impact other tests (even if you use parallel testing).\nEncore provides a helper function, et.Topic, to access the testing topic. You can use this object to extract the events that have been published to it during a test.\nHere's an example implementation:\npackage user import ( \"testing\" \"encore.dev/et\" \"github.com/stretchr/testify/assert\" ) func Test_Register(t *testing.T) { t.Parallel() ... Call Register() and assert changes to the database ... // Get all published messages on the Signups topic from this test. msgs := et.Topic(Signups).PublishedMessages() assert.Len(t, msgs, 1) } \nThe benefits of Pub/Sub\nPub/Sub is a powerful building block in a backend application. It can be used to improve app reliability by reducing the blast radius of faulty components and bottlenecks. It can also be used to increase the speed of response to the user, and even helps reduce cognitive overhead for developers by inverting the dependencies between services.\nFor those not familiar with Pub/Sub, lets take a look at an example API in a user registration service. The behavior we want to implement is that upon registration, we send a welcome email to the user and create a record of the signup in our analytics system. Now let's see how we could implement this only using APIs, compared to how a Pub/Sub implementation might look.\nAn API only approach\nUsing API calls between services, we might design a system which looks like this when the user registers:\nThe user service starts a database transaction and records the user in its database.\nThe user service makes a call to the email service to send a welcome email.\nThe email service then calls an email provider to actually send the email.\nUpon success, the email service replies to the user service that the request was processed.\nThe user service then calls the analytics service to record the signup.\nThe analytics service the writes to the data warehouse to record the information.\nThe analytics service then replies to the user service that the request was processed.\nThe user service commits the database transaction.\nThe user service then can reply to the user to say the registration was successful.\nNotice how we have to wait for everything to complete before we can reply to the user to tell then we've registered them. This means that if our email provider takes 3 seconds to send the email, we've now taken 3 seconds to respond to the user, when in reality once the user was written to the database, we could have responded to the user instantly at that point to confirm the registration.\nAnother downside to this approach is if our data warehouse is currently broken and reporting errors, our system will also report errors whenever anybody tries to signup! Given analytics is purely internal and doesn't impact users, why should the analytics system being down impact user signup?\nA Pub/Sub approach\nA more ideal solution would be if we could decouple the behaviour of emailing the user and recording our analytics, such that the user service only has to record the user in its own database and let the user know they are registered - without worrying about the downstream impacts. Thankfully, this is exactly what Pub/Sub topics allow us to do.\nIn this example, when a user registers we:\nThe user service starts a database transaction and records the user in its database.\nPublish a signup event to the signups topic.\nCommit the transaction and reply to the user to say the registration was successful.\nAt this point the user is free to continue interacting with the application and we've isolated the registration behaviour from the rest of the application.\nIn parallel, the email and analytics services will receive the signup event from the signups topic and will then perform their respective tasks. If either service returns an error, the event will automatically be backed off and retried until the service is able to process the event successfully, or reaches the maximum number of attempts and is placed into the deadletter queue (DLQ).\nNotice how in this version, the processing time of the two other services did not impact the end user and in fact the user service is not even aware of the email and analytics services. This means that new systems which need to know about new users signing up can be added to the application, without the need to change the user service or impacting its performance."
  },
  {
    "url": "https://encore.dev/docs/primitives/code-snippets",
    "text": "When you're familiar with how Encore works, you can simplify your development workflow by copy-pasting these examples. If you're looking for details on how Encore works, please refer to the relevant docs section.\nAPIs\nDefining APIs\npackage hello // service name //encore:api public func Ping(ctx context.Context, params *PingParams) (*PingResponse, error) { msg := fmt.Sprintf(\"Hello, %s!\", params.Name) return &PingResponse{Message: msg}, nil } \nDefining Request and Response schemas\n// PingParams is the request data for the Ping endpoint. type PingParams struct { Name string } // PingResponse is the response data for the Ping endpoint. type PingResponse struct { Message string } \nCalling APIs\nimport \"encore.app/hello\" // import service //encore:api public func MyOtherAPI(ctx context.Context) error { resp, err := hello.Ping(ctx, &hello.PingParams{Name: \"World\"}) if err == nil { log.Println(resp.Message) // \"Hello, World!\" } return err } \nHint: Import the service package and call the API endpoint using a regular function call.\nReceive Webhooks\nimport \"net/http\" // Webhook receives incoming webhooks from Some Service That Sends Webhooks. //encore:api public raw func Webhook(w http.ResponseWriter, req *http.Request) { // ... operate on the raw HTTP request ... } \nHint: Like any other API endpoint, this will be exposed at:\nhttps://<env>-<app-id>.encr.app/service.Webhook\nDatabases\nCreating a SQL database\nTo create a database, import encore.dev/storage/sqldb and call sqldb.NewDatabase, assigning the result to a package-level variable. sqldb.DatabaseConfig specifies the directory containing the database migration files, which is how you define the database schema.\ntodo/db.go\ntodo/migrations/1_create_table.up.sql\npackage todo // Create the todo database and assign it to the \"tododb\" variable var tododb = sqldb.NewDatabase(\"todo\", sqldb.DatabaseConfig{ Migrations: \"./migrations\", }) // Then, query the database using db.QueryRow, db.Exec, etc. \nInserting data into a database\nOne way of inserting data is with a helper function that uses the package function sqldb.Exec:\nimport \"encore.dev/storage/sqldb\" // insert inserts a todo item into the database. func insert(ctx context.Context, id, title string, done bool) error { _, err := tododb.Exec(ctx, ` INSERT INTO todo_item (id, title, done) VALUES ($1, $2, $3) `, id, title, done) return err } \nQuerying a database\nTo read a single todo item in the example schema above, we can use sqldb.QueryRow:\nimport \"encore.dev/storage/sqldb\" var item struct { ID int64 Title string Done bool } err := tododb.QueryRow(ctx, ` SELECT id, title, done FROM todo_item LIMIT 1 `).Scan(&item.ID, &item.Title, &item.Done) \nHint: If sqldb.QueryRow does not find a matching row, it reports an error that can be checked against by importing the standard library errors package and calling errors.Is(err, sqldb.ErrNoRows).\nDefining a Cron Job\nimport \"encore.dev/cron\" var _ = cron.NewJob(\"welcome-email\", cron.JobConfig{ Title: \"Send welcome emails\", Every: 2 * cron.Hour, Endpoint: SendWelcomeEmail, }) //encore:api private func SendWelcomeEmail(ctx context.Context) error { // ... return nil } \nHint: Cron Jobs do not run in your local development environment.\nPubSub\nCreating a PubSub topic\nimport \"encore.dev/pubsub\" type SignupEvent struct { UserID int } var Signups = pubsub.NewTopic[*SignupEvent](\"signups\", pubsub.TopicConfig { DeliveryGuarantee: pubsub.AtLeastOnce, }) \nHint: Topics are declared as package level variables and cannot be created inside functions. Regardless of where you create a topic, it can be published and subscribed to from any service.\nPublishing an Event (Pub)\nif _, err := Signups.Publish(ctx, &SignupEvent{UserID: id}); err != nil { return err } if err := tx.Commit(); err != nil { return err } \nHint: If you want to publish to the topic from another service, import the topic package variable (Signups in this example) and call publish on it from there.\nSubscribing to Events (Sub)\nCreate a Subscription as a package level variable by calling pubsub.NewSubscription.\nvar _ = pubsub.NewSubscription( user.Signups, \"send-welcome-email\", pubsub.SubscriptionConfig[*SignupEvent] { Handler: SendWelcomeEmail, }, ) func SendWelcomeEmail(ctx context.Context, event *SignupEvent) error { ... send email ... return nil } \nDefining a Cache cluster\nimport \"encore.dev/storage/cache\" var MyCacheCluster = cache.NewCluster(\"my-cache-cluster\", cache.ClusterConfig{ // EvictionPolicy tells Redis how to evict keys when the cache reaches // its memory limit. For typical cache use cases, cache.AllKeysLRU is a good default. EvictionPolicy: cache.AllKeysLRU, }) \nSecrets\nDefining Secrets\nvar secrets struct { GitHubAPIToken string // personal access token for deployments SomeOtherSecret string // some other secret } \nHint: The variable must be an unexported struct named secrets, and all the fields must be of type string.\nSetting secret values\n$ encore secret set --type <types...> <secret-name>\nHint: <types> defines which environment types the secret value applies to. Use a comma-separated list of production, development, preview, and local. For each Secret, there can only be one secret value for each environment type.\nUsing secrets\nfunc callGitHub(ctx context.Context) { req, _ := http.NewRequestWithContext(ctx, \"GET\", \"https:///api.github.com/user\", nil) req.Header.Add(\"Authorization\", \"token \" + secrets.GitHubAPIToken) resp, err := http.DefaultClient.Do(req) // ... handle err and resp } \nHint: Secret keys are globally unique for your whole application; if multiple services use the same secret name they both receive the same secret value at runtime."
  },
  {
    "url": "https://encore.dev/docs/primitives/caching",
    "text": "A cache is a high-speed storage layer, commonly used in distributed systems to improve user experiences by reducing latency, improving system performance, and avoiding expensive computation.\nFor scalable systems you typically want to deploy the cache as a separate infrastructure resource, allowing you to run multiple instances of your application concurrently.\nEncore's built-in Caching API lets you use high-performance caches (using Redis) in a cloud-agnostic declarative fashion. At deployment, Encore will automatically provision the required infrastructure.\nCache clusters\nTo use caching in Encore, you must first define a cache cluster. Each cache cluster defined in your application will be provisioned as a separate Redis instance by Encore.\nThis gives you fine-grained control over which service(s) should use the same cache cluster and which should have a separate one.\nIt looks like this:\nimport \"encore.dev/storage/cache\" var MyCacheCluster = cache.NewCluster(\"my-cache-cluster\", cache.ClusterConfig{ // EvictionPolicy tells Redis how to evict keys when the cache reaches // its memory limit. For typical cache use cases, cache.AllKeysLRU is a good default. EvictionPolicy: cache.AllKeysLRU, }) \nPlease note\nWhen starting out it's recommended to use a single cache cluster that's shared between your different services.\nKeyspaces\nWhen using a cache, each cached item is stored at a particular key, which is typically an arbitrary string. If you use a cache cluster to cache different sets of data, it's important that distinct data set have non-overlapping keys.\nEach value stored in the cache also has a specific type, and certain cache operations can only be performed on certain types. For example, a common cache operation is to increment an integer value that is stored in the cache. If you try to apply this operation on a value that is not an integer, an error is returned.\nEncore provides a simple, type-safe solution to these problems through Keyspaces.\nIn order to begin storing data in your cache, you must first define a Keyspace.\nEach keyspace has a Key type and a Value type. The Key type is much like a map key, in that it tells Encore where in the cache the item is stored. The Key type is combined with the Key Pattern to produce a string that is the Redis cache key.\nThe Value type is the type of the values stored in that keyspace. For many keyspaces this is specified in the name of the constructor. For example, NewIntKeyspace stores int64 values.\nFor example, if you want to rate limit the number of requests per user ID it looks like this:\nimport ( \"encore.dev/beta/auth\" \"encore.dev/beta/errs\" \"encore.dev/middleware\" ) // RequestsPerUser tracks the number of requests per user. // The cache items expire after 10 seconds without activity. var RequestsPerUser = cache.NewIntKeyspace[auth.UID](cluster, cache.KeyspaceConfig{ KeyPattern: \"requests/:key\", DefaultExpiry: cache.ExpireIn(10 * time.Second), }) // RateLimitMiddleware is a global middleware that limits the number of authenticated requests // to 10 requests per 10 seconds. //encore:middleware target=all func RateLimitMiddleware(req middleware.Request, next middleware.Next) middleware.Response { if userID, ok := auth.UserID(); ok { val, err := RequestsPerUser.Increment(req.Context(), userID, 1) // NOTE: this \"fails open\", meaning if we can't communicate with the cache // we default to allowing the requests. // // Consider whether that's the correct behavior for your application, // or if you want to return an error to the user in that case. if err == nil && val > 10 { return middleware.Response{ Err: &errs.Error{Code: errs.ResourceExhausted, Message: \"rate limit exceeded\"}, } } } return next(req) } \nAs you can see, the RequestsPerUser defines a KeyPattern which is set to \"requests/:key\". Here :key refers to the value of the Key type, which is the auth.UID value passed in.\nIf you want the cache key to contain multiple values, you can define a struct type and pass that as the key. Then change the KeyPattern to specify the struct fields.\nFor example:\ntype MyKey struct { UserID auth.UID ResourcePath string // the resource being accessed } // ResourceRequestsPerUser tracks the number of requests per user and resource. // The cache items expire after 10 seconds without activity. var ResourceRequestsPerUser = cache.NewIntKeyspace[MyKey](cluster, cache.KeyspaceConfig{ KeyPattern: \"requests/:UserID/:ResourcePath\", DefaultExpiry: cache.ExpireIn(10 * time.Second), }) // ... then: key := MyKey{UserID: \"some-user-id\", ResourcePath: \"/foo\"} ResourceRequestsPerUser.Increment(ctx, key, 1) \nPlease note\nEncore ensures that all the struct fields are present in the KeyPattern, and that the placeholder values are all valid field names.\nThat way the connection between the struct fields and the KeyPattern become compile-time type-safe as well.\nAlso note that Encore ensures there are no conflicting KeyPattern definitions across each cache cluster. Each keyspace must define its own, non-conflicting KeyPattern. This way, you can feel safe that there won't be any accidental overwrites of cache values, even with multiple services sharing the same cache cluster.\nKeyspace operations\nEncore comes with a full suite of keyspace types, each with a wide variety of cache operations.\nBasic keyspace types include strings, integers, floats, and struct types. These keyspaces all share the same set of methods (along with a few keyspace-specific ones).\nThere are also more advanced keyspaces for storing sets of basic types and ordered lists of basic types. These keyspaces offer a different, specialized set of methods specific to set and list operations.\nFor a list of the supported operations, see the package documentation.\nTesting\nWhen running tests, Encore spins up an in-memory cache separately for each test.\nThis way you don't have to think about clearing the cache between tests, or worrying about whether one test affects another. Each test is automatically fully isolated.\nLocal development\nFor local development, Encore maintains a local, in-memory implementation of Redis. This implementation is designed to store a small amount of keys (currently 100).\nWhen the number of keys exceeds this value, keys are randomly purged to get below the limit. This is designed in order to simulate the ephemeral, transient nature of caches while also limiting memory use. The precise behavior for local development may change over time and should not be relied on."
  },
  {
    "url": "https://encore.dev/docs/develop/auth",
    "text": "Almost every application needs to know who's calling it, whether the user represents a person in a consumer-facing app or an organization in a B2B app. Encore supports both use cases in a simple yet powerful way.\nAs described in the docs for defining APIs, Encore offers three access levels for APIs:\n//encore:api public – defines a public API that anybody on the internet can call.\n//encore:api private – defines a private API that is never accessible to the outside world. It can only be called from other services in your app and via cron jobs.\n//encore:api auth – defines a public API that anybody can call, but that requires valid authentication.\nWhen an API is defined with access level auth, outside calls to that API must specify an authorization header, in the form Authorization: Bearer <token>. The token is passed to a designated auth handler function and the API call is allowed to go through only if the auth handler determines the token is valid.\nFor more advanced use cases you can also customize the authentication information you want. See the section on accepting structured auth information below.\nPlease note\nYou can optionally send in auth data to public and private APIs, in which case the auth handler will be used. When used for private APIs, they are still not accessible from the outside world.\nThe auth handler\nEncore applications can designate a special function to handle authentication, by defining a function and annotating it with //encore:authhandler. This annotation tells Encore to run the function whenever an incoming API call contains authentication data.\nThe auth handler is responsible for validating the incoming authentication data and returning an auth.UID (a string type representing a user id). The auth.UID can be whatever you wish, but in practice it usually maps directly to the primary key stored in a user table (either defined in the Encore service or in an external service like Firebase or Auth0).\nWith custom user data\nOftentimes it's convenient for the rest of your application to easily be able to look up information about the authenticated user making the request. If that's the case, define the auth handler like so:\nimport \"encore.dev/beta/auth\" // Data can be named whatever you prefer (but must be exported). type Data struct { Username string // ... } // AuthHandler can be named whatever you prefer (but must be exported). //encore:authhandler func AuthHandler(ctx context.Context, token string) (auth.UID, *Data, error) { // Validate the token and look up the user id and user data, // for example by calling Firebase Auth. } \nWithout custom user data\nWhen you don't require custom user data and it's sufficient to use auth.UID, simply skip it in the return type:\nimport \"encore.dev/beta/auth\" // AuthHandler can be named whatever you prefer (but must be exported). //encore:authhandler func AuthHandler(ctx context.Context, token string) (auth.UID, error) { // Validate the token and look up the user id, // for example by calling Firebase Auth. } \nAccepting structured auth information\nIn the examples above the function accepts a Bearer token as a string argument. In that case Encore parses the Authorization HTTP header and passes the token to the auth handler.\nIn cases where you have different or more complex authorization requirements, you can instead specify a data structure that specifies one or more fields to be parsed from the HTTP request. For example:\ntype MyAuthParams struct { // SessionCookie is set to the value of the \"session\" cookie. // If the cookie is not set it's nil. SessionCookie *http.Cookie `cookie:\"session\"` // ClientID is the unique id of the client, sourced from the URL query string. ClientID string `query:\"client_id\"` // Authorization is the raw value of the \"Authorization\" header // without any parsing. Authorization string `header:\"Authorization\"` } //encore:authhandler func AuthHandler(ctx context.Context, p *MyAuthParams) (auth.UID, error) { // ... } \nThis example tells Encore that the application accepts authentication information via the session cookie, the client_id query string parameter, and the Authorization header. These fields are automatically filled in when the auth handler is called (if present in the request).\nYou can of course combine auth params like this with custom user data (see the section above).\nPlease note\nCookies are generally only used by browsers and are automatically added to requests made by browsers. As a result Encore does not include cookie fields in generated clients' authentication payloads or in the Local Development Dashboard.\nHandling auth errors\nWhen a token doesn't match your auth rules (for example if it's expired, the token has been revoked, or the token is invalid), you should return a non-nil error from the auth handler.\nEncore passes the error message on to the user when you use Encore's built-in error package, so we recommend using that with the error code Unauthenticated to communicate what happened. For example:\nimport \"encore.dev/beta/errs\" //encore:authhandler func AuthHandler(ctx context.Context, token string) (auth.UID, error) { return \"\", &errs.Error{ Code: errs.Unauthenticated, Message: \"invalid token\", } } \nTake care\nNote that for security reasons you may not want to reveal too much information about why a request did not pass your auth checks. There are many subtle security considerations when dealing with authentication and we don't have time to go into all of them here.\nWhenever possible we recommend using a third-party auth provider.\nSee the guides for using Firebase Authentication or Auth0 for examples of how to do that.\nUsing auth data\nOnce the user has been identified by the auth handler, the API handler is called as usual. If it wishes to inspect the authenticated user, it can use the encore.dev/beta/auth package:\nauth.Data() returns the custom user data returned by the auth handler (if any)\nauth.UserID() returns (auth.UID, bool) to get the authenticated user id (if any)\nFor an incoming request from the outside to an API that uses the auth access level, these are guaranteed to be set since the API won't be called if the auth handler doesn't succeed.\nEncore automatically propagates the auth data when you make API calls to other Encore API endpoints.\nPlease note\nIf an endpoint calls another endpoint during its processing, and the original does not have an authenticated user, the request will fail. This behavior preserves the guarantees that auth endpoints always have an authenticated user.\nOptional authentication\nWhile Encore always calls the auth handler for API endpoints marked as auth, you can also call public API endpoints with authentication data.\nThis can be useful for APIs that support both a \"logged in\" and \"logged out\" experience. For example, a site like Reddit might have a post.List endpoint that returns the list of posts, but if you're logged in it also includes whether or not you have upvoted or downvoted each post.\nTo support such use cases, Encore runs the auth handler for public API endpoints if (and only if) the request includes any authentication information (such as the Authorization header).\nIn that case, the request processing behavior varies depending on the value of the error returned from the auth handler:\nIf the error is nil, the request is considered to be an authenticated request and auth.UID() and auth.Data() will include the information the auth handler returned.\nIf the error is non-nil and the error code is errs.Unauthenticated (like shown above), the request continues as an unauthenticated request, behaving exactly as if there was no authentication data provided at all.\nIf the error is non-nil and the error code is anything else, the request is aborted and Encore returns that error to the caller.\nTo be able to determine if the request has an authenticated user, check the second return value from auth.UserID().\nOverriding auth information\nEncore supports overriding the auth information for an outgoing request using the auth.WithContext function. This function returns a new context with the auth information set to the specified values.\nNote that this only affects the auth information passed along with the request, and not the current request being processed (if any).\nThis function is often useful when testing APIs that use authentication. For example:\nctx := auth.WithContext(context.Background(), auth.UID(\"my-user-id\"), &MyAuthData{Email: \"hello@example.com\"}) // ... Make an API call using `ctx` to override the auth information for that API call."
  },
  {
    "url": "https://encore.dev/docs/develop/config",
    "text": "Configuration files let you define default behavior for your application, and override it for specific environments. This allows you to make changes without affecting deployments in other environments.\nEncore supports configuration files written in CUE, which is a superset of JSON. It adds the following:\nC-style comments\nQuotes may be omitted from field names without special characters\nCommas at the end of fields are optional\nA comma after last element in list is allowed\nThe outer curly braces on the file are optional\nExpressions such as interpolation, comprehensions and conditionals are supported.\nTake care\nFor sensitive data use Encore's secrets management functionality instead of configuration.\nUsing Config\nInside your service, you can call config.Load[*SomeConfigType]() to load the config. This must be done at the package level, and not inside a function. See more in the package documentation.\nHere's an example implementation:\npackage mysvc import ( \"encore.dev/config\" ) type SomeConfigType struct { ReadOnly config.Bool // Put the system into read-only mode Example config.String } var cfg *SomeConfigType = config.Load[*SomeConfigType]() \nThe type you pass as a type parameter to this function will be used to generate a encore.gen.cue file in your services directory. This file will contain both the CUE definition for your configuration type, and some metadata that Encore will provide to your service at runtime. This allows you to change the final value of your configuration based on the environment the application is running in.\nAny files ending with .cue in your service directory or sub-directories will be loaded by Encore and given to CUE to unify and compute a final configuration.\nExample CUE files\nmysvc/encore.gen.cue\nmysvc/myconfig.cue\n// Code generated by encore. DO NOT EDIT. package mysvc #Meta: { APIBaseURL: string Environment: { Name: string Type: \"production\" | \"development\" | \"ephemeral\" | \"test\" Cloud: \"aws\" | \"gcp\" | \"encore\" | \"local\" } } #Config: { ReadOnly: bool // Put the system into read-only mode Example: string } #Config \nPlease note\nLoading configuration is only supported in services and the loaded data can not be referenced from packages outside that service.\nCUE tags in Go Structs\nYou can use the cue tag in your Go to specify additional constraints on your configuration. For example:\ntype FooBar { A int `cue:\">100\"` B int `cue:\"A-50\"` // If A is set, B can be inferred by CUE C int `cue:\"A+B\"` // Which then allows CUE to infer this too } var _ = config.Load[*FooBar]() \nWill result in the following CUE type definition being generated:\n#Config: { A: int & >100 B: int & A-50 // If A is set, B can be inferred by CUE C: int & A+B // Which then allows CUE to infer this too } \nConfig Wrappers\nEncore provides type wrappers for config in the form of config.Value[T] and config.Values[T] which expand into functions of type T and []T respectively. These functions allow you to override the default value of your configuration in your CUE files inside tests, where only code run from that test will see the override.\nIn the future we plan to support real-time updating of configuration values on running applications, thus using these wrappers in your configuration today will future proof your code and allow you to automatically take advantage of this feature when it is available.\nAny type supported in API requests and responses can be used as the type for a config wrapper. However for convenience, Encore ships with the following inbuilt aliases for the config wrappers:\nconfig.String, config.Bool, config.Int, config.Uint, config.Int8, config.Int16, config.Int32, config.In64, config.Uint8, config.Uint16, config.Uint32, config.Uint64, config.Float32, config.Float64, config.Bytes, config.Time, config.UUID\nExample Application using Wrappers\nsvc/svc.go\nsvc/servers.cue\ntype mysvc import ( \"encore.dev/config\" ) type Server struct { // The config wrappers do not have to be in the top level struct Enabled config.Bool Port config.Int } type SvcConfig struct { GameServerPorts config.Values[Server] } var cfg = config.Load[*SvcConfig]() func startServers() { for _, server := range cfg.GameServerPorts() { if server.Enabled() { go startServer(server.Port()) } } } func startServer(port int) { // ... } \nWhen your application is running, Encore will provide information about that environment to your CUE files, which you can use to filter on. These fields can be found in the encore.gen.cue file which Encore will generate when you add a call to load config. Encore provides the following meta values:\nAPIBaseURL: The base URL of the Encore API, which can be used to make API calls to the application.\nEnvironment: A struct containing information about the environment the application is running in.\nName: The name of the environment\nType: One of production, development, ephemeral or test.\nCloud: The cloud the app is running on, which is one of aws, gcp, encore or local.\nThe following are useful conditionals you can use in your CUE files:\n// An application running due to `encore run` if #Meta.Environment.Type == \"development\" && #Meta.Environment.Cloud == \"local\" {} // An application running in a development environment in the Cloud if #Meta.Environment.Type == \"development\" && #Meta.Environment.Cloud != \"local\" {} // An application running in a production environment if #Meta.Environment.Type == \"production\" {} // An application running in an environment that Encore has created // for an open Pull Request on Github if #Meta.Environment.Type == \"ephemeral\" {} \nTesting with Config\nThrough the provided meta values, your applications configuration can have different values in tests, compared to when the application is running. This can be useful to prevent external side effects from your tests, such as emailing customers across all test.\nSometimes however, you may want to test specific behaviours based on different configurations (such as disabling user signups), in this scenario using the Meta data does not give you fine enough control. To allow you to set a configuration value at a per test level, Encore provides the helper function et.SetCfg. You can use this function to set a new value only in the current test and any sub tests, while all other tests will continue to use the value defined in the CUE files.\nconfig.cue\nsignup.go\nsignup_test.go\n// By default we want to sent emails SendEmails: bool | *true // But in all tests we want to disable emails if #Meta.Environment.Type == \"test\" { SendEmails: false } \nUseful CUE Patterns\nIf you're new the CUE, we'd recommend checking out the CUE documentation and cuetorials, however to get you started, here are some useful patterns you can use in your CUE files.\nCUE supports the concept of a default value, which it will use if no other concrete value is provided. This can be useful for when you normally want one value, but occasionally might want to provide an override in a certain scenario. A default value is specified by prefixing it with a *.\n// ReadOnlyMode is a boolean and if we don't provide a value, it // will default to false. ReadOnlyMode: bool | *false if #Meta.Environment.Name == \"old-prod\" { // On this environment, we want to set ReadOnlyMode to true ReadOnlyMode: true } \nAny field prefixed with an _ will not be exported to the concrete configuration once evaluated by CUE and can be used to hold intermediate values. Because CUE allows you to define the same field as many times as you want, as long as the values unify, we can build complex validation logic.\nimport ( \"list\" // import CUE's list package ) // Set some port numbers defaulting just to 8080 // but in development including 8443 portNumbers: [...int] | *[8080] if #Meta.Environment.Type == \"development\" { portNumbers: [8080, 8443] } // Port numbers must be an array and all values // are integers 1024 or above. portNumbers: [...int & >= 1024] // The ports are considered valid if they contain the port number 8080. _portsAreValid: list.Contains(portNumbers, 8080) // Ensure that the ports are valid by constraining the value to be true. // CUE will report an error if the value is false (that is if the portNumbers list // does not contain the value 8080). _portsAreValid: true \nIf statements in CUE do not have else branches, which can make it difficult to write complex conditionals, we however can use an array to emulate a switch statement, where the first value that matches the condition is returned. The following example will set SendEmailsFrom to a single string.\nSendEmailsFrom: [ // These act as individual case statements if #Meta.Environment.Type == \"production\" { \"[email protected]\" }, if #Meta.Environment.Name == \"staging\" { \"[email protected]\" }, // This last value without a condition acts as the default case \"[email protected]\", ][0] // Return the first value which matches the condition \nCUE allows us to extract map keys and use them as values to simply the config we need to write and minimize duplication.\n// Define the type we want to use #Server: { server: string port: int & > 1024 enabled: bool | *true } // Specify that servers is a map of strings to #Server // where they key we assign the the variable Name servers: [Name=string]: #Server & { // Then we union the key with the value of server server: Name } servers: { \"Foo\": { port: 8080 }, \"Bar\": { port: 8081 enabled: false }, } \nThis will result in the concrete configuration of:\n{ \"servers\": { \"Foo\": { \"server\": \"Foo\", \"port\": 8080, \"enabled\": true }, \"Bar\": { \"server\": \"Bar\", \"port\": 8081, \"enabled\": false } } }"
  },
  {
    "url": "https://encore.dev/docs/develop/cors",
    "text": "CORS is a web security concept that defines which website origins are allowed to access your API.\nA deep-dive into CORS is out of scope for this documentation, but MDN provides a good overview. In short, CORS affects requests made by browsers to resources hosted on other origins (a combination of the scheme, domain, and port).\nConfiguring CORS\nEncore provides a default CORS configuration that is suitable for many APIs. You can override these settings by specifying the global_cors key in the encore.app file, which has the following structure:\n{ // debug enables CORS debug logging. \"debug\": true | false, // allow_headers allows an app to specify additional headers that should be // accepted by the app. // // If the list contains \"*\", then all headers are allowed. \"allow_headers\": [...string], // expose_headers allows an app to specify additional headers that should be // exposed from the app, beyond the default set always recognized by Encore. // // If the list contains \"*\", then all headers are exposed. \"expose_headers\": [...string], // allow_origins_without_credentials specifies the allowed origins for requests // that don't include credentials. If nil it defaults to allowing all domains // (equivalent to [\"*\"]). \"allow_origins_without_credentials\": [...string], // allow_origins_with_credentials specifies the allowed origins for requests // that include credentials. If a request is made from an Origin in this list // Encore responds with Access-Control-Allow-Origin: <Origin>. // // The URLs in this list may include wildcards (e.g. \"https://*.example.com\" // or \"https://*-myapp.example.com\"). \"allow_origins_with_credentials\": [...string], } \nAllowed origins\nThe main CORS configuration is the list of allowed origins, meaning which websites are allowed to access your API (via browsers).\nFor this purpose, CORS makes a distinction between requests that contain authentication information (cookies, HTTP authentication, or client certificates) and those that do not. CORS applies stricter rules to authenticated requests.\nBy default, Encore allows unauthenticated requests from all origins but disallows requests that do include authorization information from other origins. This is a good default for many APIs. This can be changed by setting the allow_origins_without_credentials key (see above). For convenience Encore also allows all origins when developing locally.\nFor security reasons it's necessary to explicitly specify which origins are allowed to make authenticated requests. This is done by setting the allow_origins_with_credentials key (see above).\nAllowed headers and exposed headers\nCORS also lets you specify which headers are allowed to be sent by the client (\"allowed headers\"), and which headers are exposed to scripts running in the browser (\"exposed headers\").\nEncore automatically configures headers by parsing your program using static analysis. If your API defines a request or response type that contains a header field, Encore automatically adds the header to the list of exposed and allowed headers in request types respectively.\nTo add additional headers to these lists, you can set the allow_headers and expose_headers keys (see above). This can be useful when your application relies on custom headers in e.g. raw endpoints that aren't seen by Encore's static analysis."
  },
  {
    "url": "https://encore.dev/docs/develop/metadata",
    "text": "While Encore tries to provide a cloud-agnostic environment, sometimes it's helpful to know more about the environment your application is running in. For this reason Encore provides an API for accessing metadata about the application and the environment it's running in, as well as information about the current request as part of the encore.dev package.\nCalling encore.Meta() will return an encore.AppMetadata instance which contains information about the application, including:\nAppID - the application name.\nAPIBaseURL - the URL the application API can be publicly accessed on.\nEnvironment - the environment the application is currently running in.\nBuild - the revision information of the build from the version control system.\nDeploy - the deployment ID and when this version of the app was deployed.\nCurrent Request\nencore.CurrentRequest() can be called from anywhere within your application and will return an encore.Request instance which will provides information about why the current code is running.\nThe encore.Request type contains information about the running request, such as:\nThe service and endpoint being called\nPath and path parameter information\nWhen the request started\nThis works automatically as a result of Encore's request tracking, and works even in other goroutines that were spawned during request handling. If no request is processed by the caller, which can happen if you call it during service initialization, the Type field returns None. If CurrentRequest() is called from a goroutine spawned during request processing it will continue to report the same request even if the request handler has already returned.\nThis can be useful on raw endpoints with path parameters as the standard http.Request object passed into the raw endpoint does not provide access to the parsed path parameters, however by calling encore.CurrentRequest().PathParams() you can get access to the parsed path parameters.\nExample Use Cases\nUsing Cloud Specific Services\nAll the clouds contain a large number of services, not all of which Encore natively supports. By using information about the environment, you can define the implementation of these and use different services for each environment's provider. For instance if you are pushing audit logs into a data warehouse, when running on GCP you could use BigQuery, but when running on AWS you could use Redshift, when running locally you could simply write them to a file.\npackage audit import ( \"encore.dev\" \"encore.dev/beta/auth\" ) func Audit(ctx context.Context, action message, user auth.UID) error { switch encore.Meta().Environment.Cloud { case encore.CloudAWS: return writeIntoRedshift(ctx, action, user) case encore.CloudGCP: return writeIntoBigQuery(ctx, action, user) case encore.CloudLocal: return writeIntoFile(ctx, action, user) default: return fmt.Errorf(\"unknown cloud: %s\", encore.Meta().Environment.Cloud) } } \nChecking Environment type\nWhen implementing a signup system, you may want to skip email verification on user signups when developing the application. Using the encore.Meta() API, we can check the environment and decide whether to send an email or simply mark the user as verified upon signup.\npackage user import \"encore.dev\" //encore:api public func Signup(ctx context.Context, params *SignupParams) (*SignupResponse, error) { // ... // If this is a testing environment, skip sending the verification email switch encore.Meta().Environment.Type { case encore.EnvTest, encore.EnvDevelopment: if err := MarkEmailVerified(ctx, userID); err != nil { return nil, err } default: if err := SendVerificationEmail(ctx, userID); err != nil { return nil, err } } // ... }"
  },
  {
    "url": "https://encore.dev/docs/how-to/cgo",
    "text": "Cgo is a feature of the Go compiler that enables Go programs to interface with libraries written in other languages using C bindings.\nBy default, for improved portability Encore builds applications with cgo support disabled.\nTo enable cgo for your application, add \"build\": {\"cgo_enabled\": true} to your encore.app file.\nFor example:\n{ \"id\": \"my-app-id\", \"build\": { \"cgo_enabled\": true } } \nWith this setting Encore's build system will compile the application using an Ubuntu builder image with gcc pre-installed.\nStatic linking\nTo keep the resulting Docker images as minimal as possible, Encore compiles applications with static linking. This happens even with cgo enabled. As a result the cgo libraries you use must support static linking.\nIn some cases, you may need to add additional linker flags to properly work with static linking of cgo libraries. See the official cgo docs for more information on how to do this."
  },
  {
    "url": "https://encore.dev/docs/develop/validation",
    "text": "When receiving incoming requests it's best practice to validate the payload to make sure it meets your expectations, contains all the necessary fields, and so on.\nEncore provides an out-of-the-box middleware that automatically validates incoming requests if the request type implements the method Validate() error.\nIf it does, Encore will call this method after deserializing the request payload, and only call your API handler (and other middleware) if the validation function returns nil.\nIf the validation function returns an *errs.Error that error is reported unmodified to the caller. Other errors are converted to an *errs.Error with code InvalidArgument, which results in a HTTP response with status code 400 Bad Request.\nThis design means that it's easy to use your validation library of choice. In the future we're looking to provide an out-of-the-box validation library for an even better developer experience."
  },
  {
    "url": "https://encore.dev/docs/develop/middleware",
    "text": "Middleware is a way to write reusable code that runs before or after (or both) the handling of API requests, often across several (or all) API endpoints.\nIt's commonly used to implement cross-cutting concerns like request logging, authentication, tracing, and so on. One of the benefits of Encore is that all of these use cases are already handled out-of-the-box, so there's no need to use middleware for those things.\nNonetheless, there are several use cases where it can be useful to write reusable functionality that applies to multiple API endpoints, and middleware is a good solution in those cases.\nEncore provides built-in support for middleware by defining a function with the //encore:middleware directive. The middleware directive takes a target parameter that specifies which API endpoints it applies to.\nMiddleware functions\nA typical middleware implementation looks like this:\nimport ( \"encore.dev/beta/errs\" \"encore.dev/middleware\" ) //encore:middleware global target=all func ValidationMiddleware(req middleware.Request, next middleware.Next) middleware.Response { // If the payload has a Validate method, use it to validate the request. payload := req.Data().Payload if validator, ok := payload.(interface { Validate() error }); ok { if err := validator.Validate(); err != nil { // If the validation fails, return an InvalidArgument error. err = errs.WrapCode(err, errs.InvalidArgument, \"validation failed\") return middleware.Response{Err: err} } } return next(req) } \nMiddleware forms a chain, allowing each middleware to introspect and process the incoming request before handing it off to the next middleware by calling the next function that's passed in as an argument. For the last middleware in the chain, calling next results in the actual API handler being called.\nThe req parameter provides information about the incoming request (see package docs).\nThe next function returns a middleware.Response object which contains the response from the API, describing whether there was an error, and on success the actual response payload.\nThis enables middleware to also introspect and even modify the outgoing response, like this:\n//encore:middleware target=tag:cache func CachingMiddleware(req middleware.Request, next middleware.Next) middleware.Response { data := req.Data() // Check if we have the response cached. Use the request path as the cache key. cacheKey := data.Path if cached, err := loadFromCache(cacheKey, data.API.ResponseType); err == nil && cached != nil { return middleware.Response{Payload: cached} } // Otherwise forward the request to the handler return next(req) } \nThis uses target=tag:cache to have the middleware only apply to APIs that have that tag. More on this below in Targeting APIs.\nTake care\nMiddleware functions can also be defined as methods on a Dependency Injection struct declared with //encore:service. For example:\n//encore:service type Service struct{} //encore:middleware target=all func (s *Service) MyMiddleware(req middleware.Request, next middleware.Next) middleware.Response { // ... } \nSee the Dependency Injection docs for more information.\nMiddleware ordering\nMiddleware can either be defined inside a service, in which case it only runs for APIs within that service, or it can be defined as a global middleware, in which case it applies to all services. For global middleware the target directive still applies and enables you to easily match a subset of APIs.\nTake care\nGlobal middleware always run before all service-specific middleware, and then run in the order they are defined in the source code based on file name lexicographic ordering.\nTo avoid surprises it's best to define all middleware in a file called middleware.go in each service, and to create a single top-level package to contain all global middleware.\nTargeting APIs\nThe target directive can either be provided as target=all (meaning it applies to all APIs) or a list of tags, in the form target=tag:foo,tag:bar. Note that these tags are evaluated with OR, meaning the middleware applies to an API if the API has at least one of those tags.\nAPIs can be defined with tags by adding tag:foo at the end of the //encore:api directive:\n//encore:api public method=GET path=/user/:id tag:cache func GetUser(ctx context.Context, id string) (*User, error) { // ... }"
  },
  {
    "url": "https://encore.dev/docs/how-to/debug",
    "text": "Encore makes it easy to debug your application using Delve.\nFirst, make sure you have dlv installed by running (Go 1.16 and later):\n$ go install github.com/go-delve/delve/cmd/dlv@latest\nEnable debugging mode\nNext, run your Encore application with encore run --debug. This will cause Encore to print the Process ID to the terminal, which you will use to attach your debugger:\n$ encore run --debug\nAPI Base URL: http://localhost:4000\nDev Dashboard URL: http://localhost:9400/hello-world-cgu2\nProcess ID: 51894\n1:48PM INF registered endpoint path=/hello/:name service=hello endpoint=Hello\n(Your process id will differ).\nAttach your debugger\nWhen your Encore application is running, it’s time to attach the debugger. The instructions differ depending on how you would like to debug (in your terminal or in your editor). If instructions for your editor aren’t listed below, consult your editor for information on how to attach a debugger to a running process.\nTerminal debugging\nTo debug in your terminal, run dlv attach $PID (replace $PID with your Process ID from the previous step). You should see:\n$ dlv attach 51894\nType 'help' for list of commands.\n(dlv)\nHow to use Delve’s terminal interface for debugging is out of scope for this guide, but there are great resources available. For a good introduction, see .\nVisual Studio Code\nTo debug with VS Code you must first add a debug configuration. Press Run -> Add Configuration, choose Go -> Attach to local process. In the generated configuration, you should see \"processId\": 0 as a field. Replace 0 with the process id from above.\nNext, open the Run and Debug menu in the toolbar on the left, select Attach to Process (the configuration you just created), and then press the green arrow.\nThat’s it! You should be able to set breakpoints and have the Encore application pause when they’re hit like you would expect."
  },
  {
    "url": "https://encore.dev/docs/how-to/http-requests",
    "text": "Encore makes it easy to define APIs and expose them, but it works best when you are in charge of the API schema.\nSometimes you need more control over the underlying HTTP request, such as to accept incoming webhooks from other services, or to use WebSockets to stream data to/from the client.\nFor these use cases Encore lets you define raw endpoints. Raw endpoints operate at a lower abstraction level, giving you access to the underlying HTTP request.\nDefining raw endpoints\nTo define a raw endpoint, change the //encore:api annotation and function signature like so:\npackage service import \"net/http\" // Webhook receives incoming webhooks from Some Service That Sends Webhooks. //encore:api public raw method=POST path=/webhook func Webhook(w http.ResponseWriter, req *http.Request) { // ... operate on the raw HTTP request ... } \nIf you're an experienced Go developer, this is just a regular Go HTTP handler.\nSee the net/http documentation for more information on how Go HTTP handlers work.\nReading path parameters\nSometimes webhooks have information in the path that you may be interested in retrieving or validating.\nTo do so, define the path with a path parameter, and then use encore.CurrentRequest to access the path parameters. For example:\npackage service import ( \"net/http\" \"encore.dev\" ) //encore:api public raw method=POST path=/webhook/:id func Webhook(w http.ResponseWriter, req *http.Request) { id := encore.CurrentRequest().PathParams.Get(\"id\") // ... Do something with id }"
  },
  {
    "url": "https://encore.dev/docs/how-to/atlas-gorm",
    "text": "Atlas is a popular tool for managing database migrations. GORM is a popular ORM for Go.\nEncore provides excellent support for using them together to easily manage database schemas and migrations. Encore executes database migrations using golang-migrate, which Atlas supports out-of-the-box. This means that you can use Atlas to manage your Encore database migrations.\nThe easiest way to use Atlas + GORM together is with Atlas's support for external schemas.\nSetting up GORM\nTo set up your Encore application with GORM, start by installing the GORM package and associated Postgres driver:\ngo get -u gorm.io/gorm gorm.io/driver/postgres\nThen, in the service that you want to use GORM for, add the *gorm.DB as a dependency in your service struct (create a service struct if you don't already have one).\nFor example, if you had a service called blog:\npackage blog import ( \"encore.dev/storage/sqldb\" \"gorm.io/driver/postgres\" \"gorm.io/gorm\" ) //encore:service type Service struct { db *gorm.DB } var blogDB = sqldb.NewDatabase(\"blog\", sqldb.DatabaseConfig{ Migrations: \"./migrations\", }) // initService initializes the site service. // It is automatically called by Encore on service startup. func initService() (*Service, error) { db, err := gorm.Open(postgres.New(postgres.Config{ Conn: blogDB.Stdlib(), })) if err != nil { return nil, err } return &Service{db: db}, nil } \nFinally, create the migrations directory inside the blog directory if it doesn't already exist. This is where Atlas will put your database migrations.\nSetting up Atlas\nFirst install Atlas.\nThen, add an atlas.hcl file inside the blog directory:\ndata \"external_schema\" \"gorm\" { program = [\"env\", \"ENCORERUNTIME_NOPANIC=1\", \"go\", \"run\", \"./scripts/atlas-gorm-loader.go\"] } env \"local\" { src = data.external_schema.gorm.url migration { dir = \"file://migrations\" format = golang-migrate } format { migrate { diff = \"{{ sql . \\\" \\\" }}\" } } } \nNext, we need to create the atlas-gorm-loader script referenced above. It will use the atlas-provider-gorm library provided by Atlas.\nCreate the file as follows:\nblog/scripts/atlas-gorm-loader.go\npackage main import ( \"fmt\" \"io\" \"os\" _ \"ariga.io/atlas-go-sdk/recordriver\" \"ariga.io/atlas-provider-gorm/gormschema\" \"encore.app/blog\" ) // Define the models to generate migrations for. var models = []any{ &blog.Post{}, &blog.Comment{}, } func main() { stmts, err := gormschema.New(\"postgres\").Load(models...) if err != nil { fmt.Fprintf(os.Stderr, \"failed to load gorm schema: %v\\n\", err) os.Exit(1) } io.WriteString(os.Stdout, stmts) } \nCreating migrations\nTo wrap things up, let's create a script to automate the process of generating migrations:\nblog/scripts/generate-migration\n#!/bin/bash set -eu DB_NAME=blog MIGRATION_NAME=${1:-} SCRIPT_DIR=$( cd -- \"$( dirname -- \"${BASH_SOURCE[0]}\" )\" &> /dev/null && pwd ) # Reset the shadow database encore db reset --shadow $DB_NAME # GORM executes Go code without initializing Encore when generating migrations, # so configure the Encore runtime to be aware that this is expected. export ENCORERUNTIME_NOPANIC=1 # Generate the migration atlas migrate diff $MIGRATION_NAME --env local --dev-url \"$(encore db conn-uri --shadow $DB_NAME)&search_path=public\" \nFinally let's make the script executable, and generate our first migration:\n$ chmod +x blog/scripts/generate-migration\n$ cd blog && ./scripts/generate-migration init\nThis will generate a new migration file in the blog/migrations directory, which will be automatically applied when running encore run."
  },
  {
    "url": "https://encore.dev/docs/how-to/entgo-orm",
    "text": "Encore has all the tools needed to support ORMs and migration frameworks out-of-the-box through named databases and migration files. Writing plain SQL might not work for your use case, or you may not want to use SQL in the first place. \nORMs like ent and migration frameworks like Atlas can be used with Encore by integrating their logic with a system's database. Encore is not restrictive, it uses plain SQL migration files for its migrations. \nIf your ORM of choice can connect to any database using a standard SQL driver, then it can be used with Encore.\nIf your migration framework can generate SQL migration files without any modifications, then it can be used with Encore.\nLet's take a look at how you can integrate ent with Encore, using Atlas for generating the migration files.\nAdd ent schemas to a service\nInstall ent, then initialize your first schema in the service where you want to use it. For example, if you had the following app structure:\n/my-app ├── encore.app └── user // user service \nYou can then use this command to generate a user schema along with the ent directory that will contain that schema and all future generated files:\n$ go run entgo.io/ent/cmd/ent@latest new --target user/ent/schema User\nThe --target option sets the schema directory within your Encore system. Each system should contain its own models and schemas, and its own migration files. Like you would when using plain SQL.\nAdd the fields and edges for your new model in the generated file under user/ent/schema/user.go.\nNow, run the following command:\n$ go run entgo.io/ent/cmd/ent@latest generate ./user/ent/schema\nThis generates the ent client files. Run this command again whenever you change the schemas.\nIntegrating ent with an Encore database\nEncore automates database provisioning, and automatically runs migrations in all environments.\nTo integrate ent with Encore, we need to do three things:\nCreate the Encore database\nSet up the ent client to use that database.\nGenerate migration files for the ent schema, using Atlas.\nCreate the Encore database\nCreate the database using sqldb.NewDatabase in user/user.go:\npackage user import \"encore.dev/storage/sqldb\" var userDB = sqldb.NewDatabase(\"user\", sqldb.DatabaseConfig{ Migrations: \"./migrations\", }) \nNow, create the migrations directory, and leave it empty for now:\n$ mkdir user/migrations\nConnect ent to the database\nNext, extend the user service with a Service Struct that creates an ent client connected to the database.\nReplace the contents of the user/user.go file with:\npackage user import ( \"encore.dev/storage/sqldb\" \"entgo.io/ent/dialect\" entsql \"entgo.io/ent/dialect/sql\" \"encore.app/user/ent\" ) var userDB = sqldb.NewDatabase(\"user\", sqldb.DatabaseConfig{ Migrations: \"./migrations\", }) //encore:service type Service struct{ ent *ent.Client } func initService() (*Service, error) { driver := entsql.OpenDB(dialect.Postgres, userDB.Stdlib()) entClient := ent.NewClient(ent.Driver(driver)) return &Service{ent: entClient}, nil } \nNow ent is fully wired up to the Encore database, and can be used from the service struct in any API endpoint.\nUsing Atlas for database migrations\nFinally, we'll set up Atlas to generate database migrations for the ent schema.\nFirst, make sure you have Atlas installed.\nThen, create the file user/atlas.hcl containing the following:\nenv \"local\" { src = \"ent://ent/schema\" migration { dir = \"file://migrations\" format = golang-migrate } format { migrate { diff = \"{{ sql . \\\" \\\" }}\" } } } \nThis tells Atlas to generate migrations for the ent schema, and to output them to the migrations directory.\nAtlas works by comparing the desired ent schema with the current database schema, and generating a migration to bring the database schema in line with the ent schema. This relies on a so-called \"shadow database\", which is an empty database that Atlas uses to compare the ent schema against.\nFortunately for us, Encore has built-in support for shadow databases.\nCreate the file user/scripts/generate-migration containing the following:\nuser/scripts/generate-migration\n#!/bin/bash set -eu DB_NAME=user MIGRATION_NAME=${1:-} # Reset the shadow database encore db reset --shadow $DB_NAME # ent executes Go code without initializing Encore when generating migrations, # so configure the Encore runtime to be aware that this is expected. export ENCORERUNTIME_NOPANIC=1 # Generate the migration atlas migrate diff $MIGRATION_NAME --env local --dev-url \"$(encore db conn-uri --shadow $DB_NAME)&search_path=public\" \nFinally, make the script executable, and generate our first migration:\n$ chmod +x user/scripts/generate-migration\n$ cd user && ./scripts/generate-migration init\nYou should see a new migration file being added to the user/migrations directory, containing the schema changes to create the ent models.\nYou can now run the service with encore run, and everything should be ready to go!"
  },
  {
    "url": "https://encore.dev/docs/how-to/dependency-injection",
    "text": "Dependency Injection is a fancy name for a simple concept: when you depend on some functionality, add that dependency as a field on your struct and refer to it that way instead of directly calling it. By doing so it becomes easier to test your services by swapping out certain dependencies for other implementations (often with the use of interfaces).\nEncore provides built-in support for dependency injection in services through the use of the //encore:service directive and a service struct. See the service structs docs more information on how to define service structs.\nAs an example, consider an email service that has a SendGrid API client that is dependency injected. It might look like this:\npackage email //encore:service type Service struct { sendgridClient *sendgrid.Client } func initService() (*Service, error) { client, err := sendgrid.NewClient() if err != nil { return nil, err } return &Service{sendgridClient: client}, nil } \nYou can then define APIs as methods on this struct:\n//encore:api private func (s *Service) Send(ctx context.Context, p *SendParams) error { // ... use s.sendgridClient to send emails ... } \nMocking dependencies\nIf you wish to mock out the SendGrid client for testing purposes you can change the field to an interface:\ntype sendgridClient interface { SendEmail(...) // a hypothetical signature, for illustration purposes } //encore:service type Service struct { sendgridClient sendgridClient } \nThen during your tests you can instantiate the service object by hand:\nfunc TestFoo(t *testing.T) { svc := &Service{sendgridClient: &myMockClient{}} // ... }"
  },
  {
    "url": "https://encore.dev/docs/how-to/auth0-auth",
    "text": "In this guide you will learn how to set up an Encore auth handler that makes use of Auth0 in order to add a seamless signup and login experience to your web app.\nFor all the code and instructions of how to clone and run this example locally, see the Auth0 Example in our examples repo.\nCommunicate with Auth0\nIn your Encore app, install two modules:\n$ go get github.com/coreos/go-oidc/v3/oidc golang.org/x/oauth2\nCreate a folder and naming it auth, this is where our authentication related backend code will live.\nNext, let's set up the Auth0 Authenticator that will be used by our auth handler. The Authenticator has a method to configure and return OAuth2 and oidc clients, and another one to verify an ID Token. \nCreate auth/authenticator.go and paste the following:\npackage auth import ( \"context\" \"crypto/rand\" \"encoding/base64\" \"encore.dev/config\" \"errors\" \"github.com/coreos/go-oidc/v3/oidc\" \"golang.org/x/oauth2\" ) type Auth0Config struct { ClientID config.String Domain config.String CallbackURL config.String LogoutURL config.String } var cfg = config.Load[*Auth0Config]() var secrets struct { Auth0ClientSecret string } // Authenticator is used to authenticate our users. type Authenticator struct { *oidc.Provider oauth2.Config } // New instantiates the *Authenticator. func New() (*Authenticator, error) { provider, err := oidc.NewProvider( context.Background(), \"https://\"+cfg.Domain()+\"/\", ) if err != nil { return nil, err } conf := oauth2.Config{ ClientID: cfg.ClientID(), ClientSecret: secrets.Auth0ClientSecret, RedirectURL: cfg.CallbackURL(), Endpoint: provider.Endpoint(), Scopes: []string{oidc.ScopeOpenID, \"profile\", \"email\"}, } return &Authenticator{ Provider: provider, Config: conf, }, nil } // VerifyIDToken verifies that an *oauth2.Token is a valid *oidc.IDToken. func (a *Authenticator) VerifyIDToken(ctx context.Context, token *oauth2.Token) (*oidc.IDToken, error) { rawIDToken, ok := token.Extra(\"id_token\").(string) if !ok { return nil, errors.New(\"no id_token field in oauth2 token\") } oidcConfig := &oidc.Config{ ClientID: a.ClientID, } return a.Verifier(oidcConfig).Verify(ctx, rawIDToken) } func generateRandomState() (string, error) { b := make([]byte, 32) _, err := rand.Read(b) if err != nil { return \"\", err } state := base64.StdEncoding.EncodeToString(b) return state, nil } \nSet up the auth handler\nIt's time to define your auth handler and the endpoints needed for the login and logout flow.\nCreate the auth/auth.go file and paste the following:\npackage auth import ( \"context\" \"net/url\" \"encore.dev/beta/auth\" \"encore.dev/beta/errs\" \"github.com/coreos/go-oidc/v3/oidc\" ) // Service struct definition. // Learn more: encore.dev/docs/primitives/services-and-apis/service-structs // //encore:service type Service struct { auth *Authenticator } // initService is automatically called by Encore when the service starts up. func initService() (*Service, error) { authenticator, err := New() if err != nil { return nil, err } return &Service{auth: authenticator}, nil } type LoginResponse struct { State string `json:\"state\"` AuthCodeURL string `json:\"auth_code_url\"` } //encore:api public method=POST path=/auth/login func (s *Service) Login(ctx context.Context) (*LoginResponse, error) { state, err := generateRandomState() if err != nil { return nil, &errs.Error{ Code: errs.Internal, Message: err.Error(), } } return &LoginResponse{ State: state, // add the audience to the auth code url AuthCodeURL: s.auth.AuthCodeURL(state), }, nil } type CallbackRequest struct { Code string `json:\"code\"` } type CallbackResponse struct { Token string `json:\"token\"` } //encore:api public method=POST path=/auth/callback func (s *Service) Callback( ctx context.Context, req *CallbackRequest, ) (*CallbackResponse, error) { // Exchange an authorization code for a token. token, err := s.auth.Exchange(ctx, req.Code) if err != nil { return nil, &errs.Error{ Code: errs.PermissionDenied, Message: \"Failed to convert an authorization code into a token.\", } } idToken, err := s.auth.VerifyIDToken(ctx, token) if err != nil { return nil, &errs.Error{ Code: errs.Internal, Message: \"Failed to verify ID Token.\", } } var profile map[string]interface{} if err := idToken.Claims(&profile); err != nil { return nil, &errs.Error{ Code: errs.Internal, Message: err.Error(), } } return &CallbackResponse{ Token: token.Extra(\"id_token\").(string), }, nil } type LogoutResponse struct { RedirectURL string `json:\"redirect_url\"` } //encore:api public method=GET path=/auth/logout func (s *Service) Logout(ctx context.Context) (*LogoutResponse, error) { logoutUrl, err := url.Parse(\"https://\" + cfg.Domain() + \"/v2/logout\") if err != nil { return nil, &errs.Error{ Code: errs.Internal, Message: err.Error(), } } returnTo, err := url.Parse(cfg.LogoutURL()) if err != nil { return nil, &errs.Error{ Code: errs.Internal, Message: err.Error(), } } parameters := url.Values{} parameters.Add(\"returnTo\", returnTo.String()) parameters.Add(\"client_id\", cfg.ClientID()) logoutUrl.RawQuery = parameters.Encode() return &LogoutResponse{ RedirectURL: logoutUrl.String(), }, nil } type ProfileData struct { Email string `json:\"email\"` Picture string `json:\"picture\"` } // The `encore:authhandler` annotation tells Encore to run this function for all // incoming API call that requires authentication. // Learn more: encore.dev/docs/develop/auth#the-auth-handler // //encore:authhandler func (s *Service) AuthHandler( ctx context.Context, token string, ) (auth.UID, *ProfileData, error) { oidcConfig := &oidc.Config{ ClientID: s.auth.ClientID, } t, err := s.auth.Verifier(oidcConfig).Verify(ctx, token) if err != nil { return \"\", nil, &errs.Error{ Code: errs.Unauthenticated, Message: \"invalid token\", } } var profile map[string]interface{} if err := t.Claims(&profile); err != nil { return \"\", nil, &errs.Error{ Code: errs.Internal, Message: err.Error(), } } // Extract profile data returned from the identity provider. // auth0.com/docs/manage-users/user-accounts/user-profiles/user-profile-structure profileData := &ProfileData{ Email: profile[\"email\"].(string), Picture: profile[\"picture\"].(string), } return auth.UID(profile[\"sub\"].(string)), profileData, nil } // Endpoints annotated with `auth` are public and requires authentication // Learn more: encore.dev/docs/primitives/services-and-apis#access-controls // //encore:api auth method=GET path=/profile func GetProfile(ctx context.Context) (*ProfileData, error) { return auth.Data().(*ProfileData), nil } \nAuth0 settings\nThe Authenticator class requires some values that are specific your Auth0 application, namely the ClientID, ClientSecret, Domain, CallbackURL and LogoutURL.\nCreate an Auth0 account if you haven't already. Then, in the Auth0 dashboard, create a new Single Page Web Applications.\nNext, go to the Application Settings section. There you will find the Domain, Client ID, and Client Secret that you need to communicate with Auth0. Copy these values, we will need them shortly.\nA callback URL is where Auth0 redirects the user after they have been authenticated. Add http://localhost:3000/callback to the Allowed Callback URLs. You will need to add more URLs to this list when you have a production or staging environments. \nThe same goes for the logout URL (were the user will get redirected after logout). Add http://localhost:3000/ to the Allowed Logout URLs. \nConfig and secrets\nCreate a configuration file in the auth service and name it auth-config.cue. Add the following:\nClientID: \"<your client_id from above>\" Domain: \"<your domain from above>\" // An application running locally if #Meta.Environment.Type == \"development\" && #Meta.Environment.Cloud == \"local\" { CallbackURL: \"http://localhost:3000/callback\" LogoutURL: \"http://localhost:3000/\" } \nReplace the values for the ClientID and Domain that you got from the Auth0 dashboard.\nThe ClientSecret is especially sensitive and should not be hardcoded in your code/config. Instead, you should store that as an Encore secret.\nFrom your terminal (inside your Encore app directory), run:\n$ encore secret set --prod Auth0ClientSecret\nNow you should do the same for the development secret. The most secure way is to set up a different Auth0 application and use that for development. Depending on your security requirements you could also use the same secret for development and production.\nOnce you have a client secret for development, set it similarly to before:\n$ encore secret set --dev Auth0ClientSecret\nThat's it! Encore will run your auth handler and validate the token against Auth0.\nFrontend\nNow that the backend is set up, we can create a frontend application that uses the login flow.\nHere's an example using React together with React Router. This example also makes use of a Encores ability to generate request clients to make the communication with our backend simple and typesafe.\nApp.tsx\nlib/auth.ts\ncomponents/LoginStatus.tsx\nlib/getRequestClient.ts\nimport { PropsWithChildren } from \"react\"; import { createBrowserRouter, Link, Outlet, redirect, RouterProvider, useRouteError, } from \"react-router-dom\"; import { Auth0Provider } from \"./lib/auth\"; import AdminDashboard from \"./components/AdminDashboard.tsx\"; import IndexPage from \"./components/IndexPage.tsx\"; import \"./App.css\"; import LoginStatus from \"./components/LoginStatus.tsx\"; // Application routes const router = createBrowserRouter([ { id: \"root\", path: \"/\", Component: Layout, errorElement: ( <Layout> <ErrorBoundary /> </Layout> ), children: [ { Component: Outlet, children: [ { index: true, Component: IndexPage, }, { // Login route path: \"login\", loader: async ({ request }) => { const url = new URL(request.url); const searchParams = new URLSearchParams(url.search); const returnToURL = searchParams.get(\"returnTo\") ?? \"/\"; if (Auth0Provider.isAuthenticated()) return redirect(returnToURL); try { const returnURL = await Auth0Provider.login(returnToURL); return redirect(returnURL); } catch (error) { throw new Error(\"Login failed\"); } }, }, { // Callback route, redirected to from Auth0 after login path: \"callback\", loader: async ({ request }) => { const url = new URL(request.url); const searchParams = new URLSearchParams(url.search); const state = searchParams.get(\"state\"); const code = searchParams.get(\"code\"); if (!state || !code) throw new Error(\"Login failed\"); try { const redirectURL = await Auth0Provider.validate(state, code); return redirect(redirectURL); } catch (error) { throw new Error(\"Login failed\"); } }, }, { // Logout route path: \"logout\", loader: async () => { try { const redirectURL = await Auth0Provider.logout(); return redirect(redirectURL); } catch (error) { throw new Error(\"Logout failed\"); } }, }, { element: <Outlet />, // Redirect to /login if not authenticated loader: async ({ request }) => { if (!Auth0Provider.isAuthenticated()) { const params = new URLSearchParams(); params.set(\"returnTo\", new URL(request.url).pathname); return redirect(\"/login?\" + params.toString()); } return null; }, // Protected routes children: [ { path: \"admin-dashboard\", Component: AdminDashboard, }, ], }, ], }, ], }, ]); export default function App() { return <RouterProvider router={router} fallbackElement={<p>Loading...</p>} />; } function Layout({ children }: PropsWithChildren) { return ( <div> <header> <nav className=\"nav\"> <div className=\"navLinks\"> <Link to=\"/\">Home</Link> <Link to=\"/admin-dashboard\">Admin Dashboard</Link> </div> <LoginStatus /> </nav> </header> <main className=\"main\">{children ?? <Outlet />}</main> </div> ); } function ErrorBoundary() { const error = useRouteError() as Error; return ( <div> <h1>Something went wrong</h1> <p>{error.message || JSON.stringify(error)}</p> </div> ); } \nAuth0 supports multiple social identity providers (like Google and GitHub) for web applications out of the box."
  },
  {
    "url": "https://encore.dev/docs/how-to/clerk-auth",
    "text": "In this guide you will learn how to set up an Encore auth handler that makes use of Clerk in order to add an integrated signup and login experience to your web app.\nFor all the code and instructions of how to clone and run this example locally, see the Clerk Example in our examples repo.\nSet up the auth handler\nIn your Encore app, install the following module:\n$ go get github.com/clerkinc/clerk-sdk-go/clerk\nCreate a folder and naming it auth, this is where our authentication related backend code will live.\nIt's time to define your auth handler. Create auth/auth.go and paste the following:\npackage auth import ( \"context\" \"encore.dev/beta/auth\" \"encore.dev/beta/errs\" \"github.com/clerkinc/clerk-sdk-go/clerk\" ) var secrets struct { ClientSecretKey string } // Service struct definition. // Learn more: encore.dev/docs/primitives/services-and-apis/service-structs // //encore:service type Service struct { client clerk.Client } // initService is automatically called by Encore when the service starts up. func initService() (*Service, error) { client, err := clerk.NewClient(secrets.ClientSecretKey) if err != nil { return nil, err } return &Service{client: client}, nil } type UserData struct { ID string `json:\"id\"` Username *string `json:\"username\"` FirstName *string `json:\"first_name\"` LastName *string `json:\"last_name\"` ProfileImageURL string `json:\"profile_image_url\"` PrimaryEmailAddressID *string `json:\"primary_email_address_id\"` EmailAddresses []clerk.EmailAddress `json:\"email_addresses\"` } // The `encore:authhandler` annotation tells Encore to run this function for all // incoming API call that requires authentication. // Learn more: encore.dev/docs/develop/auth#the-auth-handler // //encore:authhandler func (s *Service) AuthHandler(ctx context.Context, token string) (auth.UID, *UserData, error) { // verify the session sessClaims, err := s.client.VerifyToken(token) if err != nil { return \"\", nil, &errs.Error{ Code: errs.Unauthenticated, Message: \"invalid token\", } } user, err := s.client.Users().Read(sessClaims.Claims.Subject) if err != nil { return \"\", nil, &errs.Error{ Code: errs.Internal, Message: err.Error(), } } userData := &UserData{ ID: user.ID, Username: user.Username, FirstName: user.FirstName, LastName: user.LastName, ProfileImageURL: user.ProfileImageURL, PrimaryEmailAddressID: user.PrimaryEmailAddressID, EmailAddresses: user.EmailAddresses, } return auth.UID(user.ID), userData, nil } \nClerk credentials\nCreate a Clerk account if you haven't already. Then, in the Clerk dashboard, create a new applications.\nNext, go to the API Keys page for your app. Copy one of the \"Secret keys\" (the \"Publishable Key\" will be used by your frontend).\nThe Secret key is sensitive and should not be hardcoded in your code/config. Instead, you should store that as an Encore secret.\nFrom your terminal (inside your Encore app directory), run:\n$ encore secret set --prod ClientSecretKey\nNow you should do the same for the development secret. The most secure way is to create another secret key (Clerk allows you to have multiple). Once you have a client secret for development, set it similarly to before:\n$ encore secret set --dev ClientSecretKey\nFrontend\nClerk offers a React SDK for the frontend which makes it really simple to integrate a login/signup flow inside your web app as well as getting the token required to communicate with your Encore backend. \nYou can use the useAuth hook from @clerk/clerk-react to get the token and send it to your backend.\nimport { useAuth } from '@clerk/clerk-react'; export default function ExternalDataPage() { const { getToken, isLoaded, isSignedIn } = useAuth(); if (!isLoaded) { // Handle loading state however you like return <div>Loading...</div>; } if (!isSignedIn) { // Handle signed out state however you like return <div>Sign in to view this page</div>; } const fetchDataFromExternalResource = async () => { const token = await getToken(); // Use token to send to Encore backend when fetching data return data; } return <div>...</div>; } \nFor a fully working backend + frontend example see the Clerk Example in our examples repo."
  },
  {
    "url": "https://encore.dev/docs/how-to/firebase-auth",
    "text": "Encore's authentication support provides a simple yet powerful way of dealing with various authentication scenarios.\nFirebase Authentication\nis a common solution for quickly setting up a user store and simplifying social logins.\nEncore makes it really easy to integrate with Firebase Authentication on the backend.\nFor all the code and instructions of how to clone and run this example locally, see the Firebase Auth Example in our examples repo.\nSet up auth handler\nFirst, install two modules:\n$ go get firebase.google.com/go/v4 go4.org/syncutil\nNext it's time to define your authentication handler. It can live in whatever service you'd like, but it's usually easiest to create a designated user service.\nCreate the user/user.go file and add the following skeleton code:\npackage user import ( \"context\" \"strings\" \"encore.dev/beta/auth\" firebase \"firebase.google.com/go/v4\" fbauth \"firebase.google.com/go/v4/auth\" \"go4.org/syncutil\" \"google.golang.org/api/option\" ) // Data represents the user's data stored in Firebase Auth. type Data struct { // Email is the user's email. Email string // Name is the user's name. Name string // Picture is the user's picture URL. Picture string } // ValidateToken validates an auth token against Firebase Auth. //encore:authhandler func ValidateToken(ctx context.Context, token string) (auth.UID, *Data, error) { panic(\"Not Yet Implemented\") } \nInitialize Firebase SDK\nNext, let's set up the Firebase Auth client. We'll use syncutil.Once to do it lazily the first time we need it.\nAdd to the bottom of our file:\nvar ( fbAuth *fbauth.Client setupOnce syncutil.Once ) // setupFB ensures Firebase Auth is setup. func setupFB() error { return setupOnce.Do(func() error { opt := option.WithCredentialsJSON([]byte(secrets.FirebasePrivateKey)) app, err := firebase.NewApp(context.Background(), nil, opt) if err == nil { fbAuth, err = app.Auth(context.Background()) } return err }) } var secrets struct { // FirebasePrivateKey is the JSON credentials for calling Firebase. FirebasePrivateKey string } \nValidate token against Firebase\nNow that we have the code to initialize Firebase Auth, we can use it from our ValidateToken auth handler. Update the function to look like the following:\nfunc ValidateToken(ctx context.Context, token string) (auth.UID, *Data, error) { if err := setupFB(); err != nil { return \"\", nil, err } tok, err := fbAuth.VerifyIDToken(ctx, token) if err != nil { return \"\", nil, err } email, _ := tok.Claims[\"email\"].(string) name, _ := tok.Claims[\"name\"].(string) picture, _ := tok.Claims[\"picture\"].(string) uid := auth.UID(tok.UID) usr := &Data{ Email: email, Name: name, Picture: picture, } return uid, usr, nil } \nGreat! We're done with the code. Now we just need to set up the secret.\nSet Firebase secret credentials\nIf you haven't already, set up a Firebase project.\nThen, go to Project settings and navigate to Service accounts. Select Go as the language of choice and click Generate new private key. Download the generated key and take note where it is stored.\nNext, store the private key as your firebase secret. From your terminal (inside your Encore app directory), run:\n$ encore secret set --type prod FirebasePrivateKey < /path/to/firebase-private-key.json\nSuccessfully updated production secret FirebasePrivateKey\nNow you should do the same for the development secret. The most secure way is to set up a different Firebase project and use that for development.\nDepending on your security requirements you could also use the same Firebase project, but we recommend generating a new private key for development in that case.\nOnce you have a private key for development, set it similarly to before:\n$ encore secret set --type dev,local,pr FirebasePrivateKey < /path/to/firebase-private-key.json\nSuccessfully updated development secret FirebasePrivateKey\nThat's it! You can now call your Encore application and pass in Firebase tokens. Encore will run your auth handler and validate the token against Firebase Auth.\nFrontend\nFirebase offers a npm package for your web frontend which makes it really simple to create a login/signup flow inside your web app as well as getting the token required to communicate with your Encore backend. \nFor a fully working backend + frontend example see the Firebase Auth Example in our examples repo."
  },
  {
    "url": "https://encore.dev/docs/ts/primitives/secrets",
    "text": "Wouldn't it be nice to store secret values like API keys, database passwords, and private keys directly in the source code? Of course, we can’t do that – it's horrifyingly insecure! (Unfortunately, it's also very common.)\nEncore's built-in secrets manager makes it simple to store secrets in a secure way and lets you use them in your program like regular variables.\nUsing secrets in your application\nTo use a secret in your application, define a top-level variable directly in your code by calling the secret function from encore.dev/config.\nFor example:\nimport { secret } from \"encore.dev/config\"; // Personal access token for deployments const githubToken = secret(\"GitHubAPIToken\"); // Then, resolve the secret value by calling `githubToken()`. \nWhen you've defined a secret in your program, the Encore compiler will check that they are set before running or deploying your application.\nWhen running your application locally, if a secret is not set, you will get a warning notifying you that a secret value is missing.\nWhen deploying to a cloud environment, all secrets must be defined, otherwise the deploy will fail.\nOnce you've provided values for all secrets, call the secret as a function. For example:\nasync function callGitHub() { const resp = await fetch(\"https:///api.github.com/user\", { credentials: \"include\", headers: { Authorization: `token ${githubToken()}`, }, }); // ... handle resp } \nPlease note\nSecret keys are globally unique for your whole application. If multiple services use the same secret name they both receive the same secret value at runtime.\nStoring secret values\nUsing the Cloud Dashboard\nThe simplest way to set up secrets is with the Secrets Manager in the Encore Cloud Dashboard. Open your app in app.encore.dev, go to Settings in the main navigation, and then click on Secrets in the settings menu.\nFrom here you can create secrets, save secret values, and configure different values for different environments.\nUsing the CLI\nIf you prefer, you can also set up secrets from the CLI using:\nencore secret set --type <types> <secret-name>\n<types> defines which environment types the secret value applies to. Use a comma-separated list of production, development, preview, and local. Shorthands: prod, dev, pr.\nFor example encore secret set --type prod SSHPrivateKey sets the secret value for production environments,\nand encore secret set --type dev,preview,local GitHubAPIToken sets the secret value for development, preview, and local environments.\nIn some cases, it can be useful to define a secret for a specific environment instead of an environment type. You can do so with encore secret set --env <env-name> <secret-name>. Secret values for specific environments take precedence over values for environment types.\nEnvironment settings\nEach secret can only have one secret value for each environment type. For example: If you have a secret value that's shared between development, preview and local, and you want to override the value for local, you must first edit the existing secret and remove local using the Secrets Manager in the Cloud Dashboard. You can then add a new secret value for local. The end result should look something like the picture below.\nOverriding local secrets\nWhen setting secrets via the encore secret set command, they are automatically synced to all developers working on the same application, courtesy of the Encore Platform.\nIn some cases, however, you want to override a secret only for your local machine. This can be done by creating a file named .secrets.local.cue in the root of your Encore application, next to the encore.app file.\nThe file contains key-value pairs of secret names to secret values. For example:\nGitHubAPIToken: \"my-local-override-token\" SSHPrivateKey: \"custom-ssh-private-key\" \nHow it works: Where secrets are stored\nWhen you store a secret Encore stores it encrypted using Google Cloud Platform's Key Management Service (KMS).\nProduction / Your own cloud: When you deploy to production using your own cloud account on GCP or AWS, Encore provisions a secrets manager in your account (using either KMS or AWS Secrets Manager) and replicates your secrets to it. The secrets are then injected into the container using secret environment variables.\nLocal: For local secrets Encore automatically replicates them to developers' machines when running encore run.\nDevelopment / Encore Cloud: Environments on Encore's development cloud (running on GCP under the hood) work the same as self-hosted GCP environments, using GCP Secrets Manager."
  },
  {
    "url": "https://encore.dev/docs/how-to/grpc-connect",
    "text": "The Connect protocol is an HTTP/2-based protocol for RPC communication. It's conceptually similar to gRPC, but with better support for using from browsers and JavaScript clients.\nThis guide shows how to use Encore for setting up a Connect service for external clients to use:\nFirst, we'll define a simple gRPC service using Protobuf and Connect.\nThen, we'll implement the service in Go, using connect-go.\nThen, we'll mount the Connect service into Encore with a raw endpoint.\nFinally, we'll call the Connect service from cURL using its JSON mapping.\nDefine a Connect service\nWe'll largely follow the connect-go getting started guide with some small tweaks.\nStart by installing the necessary tools:\n$ go install github.com/bufbuild/buf/cmd/buf@latest\n$ go install github.com/fullstorydev/grpcurl/cmd/grpcurl@latest\n$ go install google.golang.org/protobuf/cmd/protoc-gen-go@latest\n$ go install connectrpc.com/connect/cmd/protoc-gen-connect-go@latest\nNext, inside your Encore application (create one if you haven't already) create a new file at greet/v1/greet.proto with the following contents:\nsyntax = \"proto3\"; package greet.v1; option go_package = \"encore.app/gen/greet/v1;greetv1\"; message GreetRequest { string name = 1; } message GreetResponse { string greeting = 1; } service GreetService { rpc Greet(GreetRequest) returns (GreetResponse) {} } \nNext, add a buf.gen.yaml in the repository root, containing:\nversion: v1 plugins: - plugin: go out: gen opt: paths=source_relative - plugin: connect-go out: gen opt: paths=source_relative \nNow it's time to generate the connect-go service code. Run:\n$ buf lint\n$ buf generate\nIf all went well, you should see a new gen directory in the repository root containing some generated Go code:\ngen └── greet └── v1 ├── greet.pb.go └── greetv1connect └── greet.connect.go \nImplement the service\nNow that we have the service definition, we can implement the Connect service in Go.\nAdd the file greet/greet.go with the following contents:\npackage greet import ( \"context\" \"fmt\" \"log\" \"connectrpc.com/connect\" greetv1 \"encore.app/gen/greet/v1\" // generated by protoc-gen-go ) type GreetServer struct{} func (s *GreetServer) Greet( ctx context.Context, req *connect.Request[greetv1.GreetRequest], ) (*connect.Response[greetv1.GreetResponse], error) { log.Println(\"Request headers: \", req.Header()) res := connect.NewResponse(&greetv1.GreetResponse{ Greeting: fmt.Sprintf(\"Hello, %s!\", req.Msg.Name), }) res.Header().Set(\"Greet-Version\", \"v1\") return res, nil } \nPlease note\nThe sample code is straight from the getting started guide; there are no Encore specific changes required here.\nMount the service in Encore\nNow we'll create an Encore service struct that initializes the Connect service, and a raw endpoint that forwards incoming requests to the Connect service.\nAdd the file greet/service.go with the following contents:\npackage greet import ( \"net/http\" \"encore.app/gen/greet/v1/greetv1connect\" \"golang.org/x/net/http2\" \"golang.org/x/net/http2/h2c\" ) //encore:service type Service struct { routes http.Handler } //encore:api public raw path=/greet.v1.GreetService/*endpoint func (s *Service) GreetService(w http.ResponseWriter, req *http.Request) { s.routes.ServeHTTP(w, req) } func initService() (*Service, error) { greeter := &GreetServer{} mux := http.NewServeMux() path, handler := greetv1connect.NewGreetServiceHandler(greeter) mux.Handle(path, handler) routes := h2c.NewHandler(mux, &http2.Server{}) return &Service{routes: routes}, nil } \nThat's it! We're ready to run the service and check that everything works.\nRun the service\nRun the service with encore run:\n$ encore run\nOnce it starts up, open a separate terminal and use grpcurl to call the service:\n# Install grpcurl if you haven't already\n$ go install github.com/fullstorydev/grpcurl/cmd/grpcurl@latest\n# Call the service\n$ curl -H \"Content-Type: application/json\" -d '{\"name\": \"Jane\"}' http://localhost:4000/greet.v1.GreetService/Greet\n{\"greeting\":\"Hello, Jane!\"} # Expected response\nIf you see {\"greeting\":\"Hello, Jane!\"}, everything is working!\nWhat's more, Encore automatically traces the incoming requests, and adds request logging and captures request metrics."
  },
  {
    "url": "https://encore.dev/docs/ts/develop/auth",
    "text": "Almost every application needs to know who's calling it, whether the user represents a person in a consumer-facing app or an organization in a B2B app. Encore supports both use cases in a simple yet powerful way.\nAs described in the docs for defining APIs, each API endpoint can be marked as requiring authentication, using the option auth: true when defining the endpoint.\nAuthentication Handlers\nWhen an API is defined with auth: true, you must define an authentication handler in your application. The authentication handler is responsible for inspecting incoming requests to determine what user is authenticated (if any), and computing any other associated authentication information.\nThe authentication handler is defined similarly to API endpoints, using the authHandler function imported from encore.dev/auth. \nLike API endpoints, the authentication handler defines what request information it's interested in, in the form of HTTP headers, query strings, or cookies.\nA simple authentication handler that inspects the Authorization header might look like this:\nimport { Header, Gateway } from \"encore.dev/api\"; import { authHandler } from \"encore.dev/auth\"; // AuthParams specifies the incoming request information // the auth handler is interested in. In this case it only // cares about requests that contain the `Authorization` header. interface AuthParams { authorization: Header<\"Authorization\">; } // The AuthData specifies the information about the authenticated user // that the auth handler makes available. interface AuthData { userID: string; } // The auth handler itself. export const auth = authHandler<AuthParams, AuthData>( async (params) => { // TODO: Look up information about the user based on the authorization header. return {userID: \"my-user-id\"}; } ) // Define the API Gateway that will execute the auth handler: export const gateway = new Gateway({ authHandler: auth, }) \nWith this in place, Encore will provision an API Gateway that will process incoming requests to your application, and whenever a request contains an Authorization header it will first call the authentication handler to resolve information about the user.\nRejecting authentication\nIf the auth handler returns an AuthData object, Encore will consider the request authenticated. To instead reject the request, throw an exception. To signal that the credentials are not valid, throw an APIError with code Unauthenticated.\nFor example:\nimport { APIError } from \"encore.dev/api\"; export const auth = authHandler<AuthParams, AuthData>( async (params) => { throw APIError.unauthenticated(\"bad credentials\"); } ) \nUnderstanding the Authentication Process\nEncore's authentication process proceeds in two steps:\nDetermine if the request is authenticated\nCall the endpoint, if permissible\nStep 1: Determinining if the request is authenticated\nWhenever an incoming request contains any of the authentication parameters (defined by the auth handler), Encore's API Gateway calls the auth handler to resolve the authentication data.\nThis happens regardless of the endpoint the request is for. Importantly, it happens even when calling an endpoint that does not require authentication.\nThere are three possible outcomes from calling the auth handler:\nIf the auth handler succeeds, by returning AuthData, the request is considered authenticated.\nIf the auth handler throws an APIError with code Unauthenticated, the request is considered unauthenticated, exactly as if there was no authentication parameters in the request to begin with.\nIf the auth handler throws any other exception, the API Gateway aborts the request and returns the error to the caller.\nFinally, if the request does not contain authentication data, the request is considered unauthenticated.\nStep 2: Calling the endpoint, if permissible\nOnce the API Gateway has determined whether the request is authenticated, it checks whether the API Endpoint being called requires authentication data.\nIf it does require authentication, and the request is not authenticated, the API Gateway aborts the request and returns an \"unauthenticated\" error to the caller.\nIn all other situations, the API Gateway proceeds by calling the target endpoint.\nIf the request was successfully authenticated, the authentication data is passed along to the endpoint, regardless of whether the endpoint requires authentication or not.\nUsing auth data\nIf a request has been successfully authenticated, the API Gateway forwards the authentication data to the target endpoint. The endpoint can query the available auth data from the getAuthData function, available from the ~encore/auth module.\nThis module is dynamically generated by Encore to enable type-safe resolution of the auth data.\nPropagating auth data\nEncore automatically propagates the auth data when you make API calls to other Encore API endpoints using the generated ~encore/clients package.\nPlease note\nIf an endpoint calls another endpoint during its processing, and the target endpoint requires authentication while the original request does not have any authentication data, the API call will fail with error code Unauthenticated.\nThis behavior preserves the guarantee that endpoints that require authentication always have valid authentication data present."
  },
  {
    "url": "https://encore.dev/docs/ts/develop/cors",
    "text": "CORS is a web security concept that defines which website origins are allowed to access your API.\nA deep-dive into CORS is out of scope for this documentation, but MDN provides a good overview. In short, CORS affects requests made by browsers to resources hosted on other origins (a combination of the scheme, domain, and port).\nConfiguring CORS\nEncore provides a default CORS configuration that is suitable for many APIs. You can override these settings by specifying the global_cors key in the encore.app file, which has the following structure:\n{ // debug enables CORS debug logging. \"debug\": true | false, // allow_headers allows an app to specify additional headers that should be // accepted by the app. // // If the list contains \"*\", then all headers are allowed. \"allow_headers\": [...string], // expose_headers allows an app to specify additional headers that should be // exposed from the app, beyond the default set always recognized by Encore. // // If the list contains \"*\", then all headers are exposed. \"expose_headers\": [...string], // allow_origins_without_credentials specifies the allowed origins for requests // that don't include credentials. If nil it defaults to allowing all domains // (equivalent to [\"*\"]). \"allow_origins_without_credentials\": [...string], // allow_origins_with_credentials specifies the allowed origins for requests // that include credentials. If a request is made from an Origin in this list // Encore responds with Access-Control-Allow-Origin: <Origin>. // // The URLs in this list may include wildcards (e.g. \"https://*.example.com\" // or \"https://*-myapp.example.com\"). \"allow_origins_with_credentials\": [...string], } \nAllowed origins\nThe main CORS configuration is the list of allowed origins, meaning which websites are allowed to access your API (via browsers).\nFor this purpose, CORS makes a distinction between requests that contain authentication information (cookies, HTTP authentication, or client certificates) and those that do not. CORS applies stricter rules to authenticated requests.\nBy default, Encore allows unauthenticated requests from all origins but disallows requests that do include authorization information from other origins. This is a good default for many APIs. This can be changed by setting the allow_origins_without_credentials key (see above). For convenience Encore also allows all origins when developing locally.\nFor security reasons it's necessary to explicitly specify which origins are allowed to make authenticated requests. This is done by setting the allow_origins_with_credentials key (see above).\nAllowed headers and exposed headers\nCORS also lets you specify which headers are allowed to be sent by the client (\"allowed headers\"), and which headers are exposed to scripts running in the browser (\"exposed headers\").\nEncore automatically configures headers by parsing your program using static analysis. If your API defines a request or response type that contains a header field, Encore automatically adds the header to the list of exposed and allowed headers in request types respectively.\nTo add additional headers to these lists, you can set the allow_headers and expose_headers keys (see above). This can be useful when your application relies on custom headers in e.g. raw endpoints that aren't seen by Encore's static analysis."
  },
  {
    "url": "https://encore.dev/docs/ts/develop/metadata",
    "text": "While Encore tries to provide a cloud-agnostic environment, sometimes it's helpful to know more about the environment your application is running in. For this reason Encore provides an API for accessing metadata about the application and the environment it's running in as part of the encore.dev package.\nCalling appMeta() from the encore.dev package returns an object that contains information about the application, including:\nappID - the application name.\napiBaseURL - the URL the application API can be publicly accessed on.\nenvironment - the environment the application is currently running in.\nbuild - the revision information of the build from the version control system.\ndeploy - the deployment ID and when this version of the app was deployed.\nExample Use Cases\nUsing Cloud Specific Services\nAll the clouds contain a large number of services, not all of which Encore natively supports.\nBy using information about the environment, you can define the implementation of these and use different services for each environment's provider.\nFor instance if you are pushing audit logs into a data warehouse, when running on GCP you could use BigQuery, but when running on AWS you could use Redshift, when running locally you could simply write them to a file.\nimport { appMeta } from \"encore.dev\"; // Emit an audit event. async function audit(userID: string, event: Record<string, any>) { const cloud = appMeta().environment.cloud; switch (cloud) { case \"aws\": return writeIntoRedshift(userID, event); case \"gcp\": return writeIntoBigQuery(userID, event); case \"local\": return writeIntoFile(userID, event); default: throw new Error(`unknown cloud: ${cloud}`); } } \nChecking Environment type\nWhen implementing a signup system, you may want to skip email verification on user signups when developing the application. Using the appMeta API, we can check the environment and decide whether to send an email or simply mark the user as verified upon signup.\nimport { appMeta } from \"encore.dev\"; export const signup = api( { expose: true }, async (params: SignupParams): Promise<SignupResponse> => { // more code... // If this is a testing environment, skip sending the verification email. switch (appMeta().environment.type) { case (\"test\", \"development\"): await markEmailVerified(userID); break; default: await sendVerificationEmail(userID); break; } // more code... }, );"
  },
  {
    "url": "https://encore.dev/docs/ts/develop/testing",
    "text": "Encore provides a suite of built-in tooling to simplify testing your application.\nTo run your tests, configure the test command in your package.json to the test runner of your choice, and then use encore test from the CLI. The encore test command sets up all the necessary infrastructure in test mode before handing over to the test runner. \nTest Runners\nWe recommend using Vitest as the test runner. It's very fast, has native support for ESM and TypeScript, and has a built-in compatibility layer for Jest's API.\nIntegration testing\nSince Encore removes almost all boilerplate, most of the code you write is business logic that involves databases and calling APIs between services. Such behavior is most easily tested with integration tests.\nWhen running tests, Encore automatically sets up the databases you need in a separate database cluster. They are additionally configured to skip fsync and to use an in-memory filesystem since durability is not a concern for automated tests.\nThis drastically reduces the speed overhead of writing integration tests.\nIn general, Encore applications tend to focus more on integration tests compared to traditional applications that are heavier on unit tests. This is nothing to worry about and is the recommended best practice.\nTesting from your IDE\nVisual Studio Code (VS Code)\nIf you're using Vitest, install the official Vitest VS Code extension and then add to the .vscode/settings.json file:\n\"vitest.commandLine\": \"encore test\""
  },
  {
    "url": "https://encore.dev/docs/how-to/integrate-frontend",
    "text": "Encore is not opinionated about where you host your frontend, pick the platform that suits your situation best.\nIf your frontend and backend use different domains, often the case when using PR preview environments for your frontend, you may need to configure CORS.\nTake a look at our React starter template for an example of deploying a frontend to Vercel or the Meeting Notes tutorial deployed to GitHub Pages.\nGenerating a request client\nEncore is able to generate frontend request clients (TypeScript or JavaScript). This lets you to keep the request/response types in sync without manual work and assists you in calling the APIs. Generate a client by running:\n$ encore gen client <ENCORE-APP-ID> --output=./src/client.ts --env=<ENV_NAME> \nAdding this as a script to your package.json is often a good idea to be able to run it whenever a change is made to your Encore API:\n{ ... \"scripts\": { ... \"generate-client:staging\": \"encore gen client <ENCORE-APP-ID> --output=./src/client.ts --env=staging\", \"generate-client:local\": \"encore gen client <ENCORE-APP-ID> --output=./src/client.ts --env=local\" } } \nAfter that you are ready to use the request client in your code. Here is an example from the Meeting Notes tutorial for calling the GetNote endpoint on the note service in order to retrieve a specific meeting note (which has the properties id, cover_url & text):\nimport Client, { Environment, Local } from \"src/client.ts\"; // Making request to locally running backend... const client = new Client(Local); // or to a specific deployed environment const client = new Client(Environment(\"staging\")); // Calling APIs as typesafe functions 🌟 const response = await client.note.GetNote(\"note-uuid\"); console.log(response.id); console.log(response.cover_url); console.log(response.text); \nSee more in the client generation docs.\nAsynchronous state management\nWhen building something a bit more complex, you will likely need to deal with caching, refetching, and data going stale. TanStack Query is a popular library that was built to solve exactly these problems and works well with the Encore request client.\nHere is a simple example of using an Encore request client together with TanStack Query:\nimport { useQuery, useMutation, useQueryClient, QueryClient, QueryClientProvider, } from '@tanstack/react-query' import Client, { todo } from '../encore-client' // Create a Encore client const encoreClient = new Client(window.location.origin); // Create a react-query client const queryClient = new QueryClient() function App() { return ( // Provide the client to your App <QueryClientProvider client={queryClient}> <Todos /> </QueryClientProvider> ) } function Todos() { // Access the client const queryClient = useQueryClient() // Queries const query = useQuery({ queryKey: ['todos'], queryFn: () => encoreClient.todo.List() }) // Mutations const mutation = useMutation({ mutationFn: (params: todo.AddParams) => encoreClient.todo.Add(params), onSuccess: () => { // Invalidate and refetch queryClient.invalidateQueries({ queryKey: ['todos'] }) }, }) return ( <div> <ul> {query.data?.map((todo) => ( <li key={todo.id}>{todo.title}</li> ))} </ul> <button onClick={() => { mutation.mutate({ id: Date.now(), title: 'Do Laundry', }) }} > Add Todo </button> </div> ) } render(<App />, document.getElementById('root')) \nThis example assumes that we have a todo service with a List and Add endpoint. When adding the new todo, TanStack Query will automatically invalidate the todos query and refetch it.\nFor a real-world example, take a look at the Uptime Monitoring app which also makes use of TanStack Query's refetchInterval option for polling the backend.\nTesting\nWhen unit testing a component that interacts with your Encore API you can mock methods on the request client to return a value suitable for the test. This makes your test URL agnostic because you are not intercepting specific requests on the fetch layer. You also get type errors in your tests if the request client gets updated.\nHere is an example from the Uptime Monitoring Starter where we are mocking a GET request method and spying on a POST request method:\nimport { render, waitForElementToBeRemoved } from \"@testing-library/react\"; import App from \"./App\"; import { site } from \"./client\"; import { userEvent } from \"@testing-library/user-event\"; describe(\"App\", () => { beforeEach(() => { // Return mocked data from the List (GET) endpoint jest .spyOn(site.ServiceClient.prototype, \"List\") .mockReturnValue(Promise.resolve({ sites: [{ id: 1, url: \"test.dev\" }] })); // Spy on the Add (POST) endpoint jest.spyOn(site.ServiceClient.prototype, \"Add\"); }); it(\"render sites\", async () => { render(<App />); await waitForElementToBeRemoved(() => screen.queryByText(\"Loading...\")); // Verify that the List endpoint has been called expect(site.ServiceClient.prototype.List).toBeCalledTimes(1); // Verify that the sites are rendered with our mocked data screen.getAllByText(\"test.dev\"); }); it(\"add site\", async () => { render(<App />); await waitForElementToBeRemoved(() => screen.queryByText(\"Loading...\")); // Interact with the page and add 'another.com' await userEvent.click(screen.getByText(\"Add website\")); await userEvent.type( screen.getByPlaceholderText(\"google.com\"), \"another.com\", ); await userEvent.click(screen.getByText(\"Save\")); // Verify that the Add endpoint has been called with the correct parameters expect(site.ServiceClient.prototype.Add).toHaveBeenCalledWith({ url: \"another.com\", }); }); }) \nPlease note\nIn the example above we need to mock the List method on site.ServiceClient.prototype because the request client has not yet been initialized when we're creating the mock. If you have access to the instance of the request client in your test (which could be the case if you are passing the client around in your components) you can instead do jest.spyOn(client.site, \"List\") and expect(client.site.List).toHaveBeenCalled() which would give you the same result.\nMore examples of tests can be found in the Uptime Monitoring Starter repo.\nMonorepo or Multi repo\nEncore is not opinionated about where your frontend lives, pick the approach that fits your application best.\nIf you use a monorepo then it is often a good idea to place your backend and frontend in separate folders. There are two approaches to moving your Encore backend to a subfolder:\nPlace your microservices together with the encore.app file in a subfolder. When moving encore.app to a subfolder you will need to configure the \"Root Directory\" in app settings in the Cloud Dashboard.\nPlace your microservices in a subfolder and keep the encore.app in the repo root directory. No configuration change is needed, but you will need to update the import paths if your services are calling each other.\nREST vs. GraphQL\nEncore allows for building backends using both REST and GraphQL, you should pick the approach that suits your use case best.\nTake a look at the GraphQL tutorial for an example of building a GraphQL backend with Encore.\nHosting a frontend on Encore for development\nEncore is primarily designed for backend development and does not (at the moment) support building or testing frontends in the deploy pipeline. For production use, we recommend that you deploy your frontend using Vercel, Netlify, or a similar service.\nFor development purposes, you can create a raw endpoint that serves static frontend assets. It would look something like the example below (taken from the Uptime Monitoring tutorial), but keep in mind that you need to have the compiled frontend assets under version control (dist folder in the example below).\npackage frontend import ( \"embed\" \"io/fs\" \"net/http\" ) var ( //go:embed dist dist embed.FS assets, _ = fs.Sub(dist, \"dist\") handler = http.StripPrefix(\"/frontend/\", http.FileServer(http.FS(assets))) ) //encore:api public raw path=/frontend/*path func Serve(w http.ResponseWriter, req *http.Request) { handler.ServeHTTP(w, req) } \nHandling CORS\nIf you are running into CORS issues when calling your Encore API from your frontend you may need to specify which origins are allowed to access your API (via browsers). Do this by specifying the global_cors key in the encore.app file, which has the following structure:\nglobal_cors: { // allow_origins_without_credentials specifies the allowed origins for requests // that don't include credentials. If nil it defaults to allowing all domains // (equivalent to [\"*\"]). \"allow_origins_without_credentials\": [ \"<ORIGIN-GOES-HERE>\" ], // allow_origins_with_credentials specifies the allowed origins for requests // that include credentials. If a request is made from an Origin in this list // Encore responds with Access-Control-Allow-Origin: <Origin>. // // The URLs in this list may include wildcards (e.g. \"https://*.example.com\" // or \"https://*-myapp.example.com\"). \"allow_origins_with_credentials\": [ \"<DOMAIN-GOES-HERE>\" ] } \nSee more in the CORS docs."
  },
  {
    "url": "https://encore.dev/docs/develop/errors",
    "text": "Encore supports returning structured error information from your APIs using the encore.dev/beta/errs package.\nErrors are propagated across the network to the generated clients and can be used within your front-ends without having to build any custom marshalling code.\nThe errs.Error type\nStructured errors are represented by the errs.Error type:\ntype Error struct { // Code is the error code to return. Code ErrCode `json:\"code\"` // Message is a descriptive message of the error. Message string `json:\"message\"` // Details are user-defined additional details. Details ErrDetails `json:\"details\"` // Meta are arbitrary key-value pairs for use within // the Encore application. They are not exposed to external clients. Meta Metadata `json:\"-\"` } \nReturning an *errs.Error from an Encore API endpoint will result in Encore serializing this struct to JSON and returning it in the response. Additionally Encore will set the HTTP status code to match the error code (see the mapping table below).\nFor example:\nreturn &errs.Error{ Code: errs.NotFound, Message: \"sprocket not found\", } \nCauses Encore to respond with a HTTP 404 error with body:\n{ \"code\": \"not_found\", \"message\": \"sprocket not found\", \"details\": null } \nError Wrapping\nEncore applications are encouraged to always use the errs package to manipulate errors. It supports wrapping errors to gradually add more error information, and lets you easily define both structured error details to return to external clients, as well as internal key-value metadata for debugging and error handling.\nfunc Wrap(err error, msg string, metaPairs ...interface{}) error \nUse errs.Wrap to conveniently wrap an error, adding additional context and converting it to an *errs.Error. If err is nil it returns nil. If err is already an *errs.Error it copies the Code, Details, and Meta fields over.\nThe variadic metaPairs parameter must be key-value pairs, where the key is always a string and the value can be any built-in type. Existing key-value pairs from the err are merged into the new *Error.\nfunc WrapCode(err error, code ErrCode, msg string, metaPairs ...interface{}) error \nerrs.WrapCode is like errs.Wrap but also sets the error code.\nfunc Convert(err error) error \nerrs.Convert converts an error to an *errs.Error. If the error is already an *errs.Error it returns it unmodified. If err is nil it returns nil.\nError Codes\nThe errs package defines error codes for common error scenarios. They are identical to the codes defined by gRPC for interoperability.\nThe table below summarizes the error codes. You can find additional documentation about when to use them in the package documentation.\nCodeStringHTTP Status\nOK\t\"ok\"\t200 OK\t\nCanceled\t\"canceled\"\t499 Client Closed Request\t\nUnknown\t\"unknown\"\t500 Internal Server Error\t\nInvalidArgument\t\"invalid_argument\"\t400 Bad Request\t\nDeadlineExceeded\t\"deadline_exceeded\"\t504 Gateway Timeout\t\nNotFound\t\"not_found\"\t404 Not Found\t\nAlreadyExists\t\"already_exists\"\t409 Conflict\t\nPermissionDenied\t\"permission_denied\"\t403 Forbidden\t\nResourceExhausted\t\"resource_exhausted\"\t429 Too Many Requests\t\nFailedPrecondition\t\"failed_precondition\"\t400 Bad Request\t\nAborted\t\"aborted\"\t409 Conflict\t\nOutOfRange\t\"out_of_range\"\t400 Bad Request\t\nUnimplemented\t\"unimplemented\"\t501 Not Implemented\t\nInternal\t\"internal\"\t500 Internal Server Error\t\nUnavailable\t\"unavailable\"\t503 Unavailable\t\nDataLoss\t\"data_loss\"\t500 Internal Server Error\t\nUnauthenticated\t\"unauthenticated\"\t401 Unauthorized\t\nError Building\nIn cases where you have complex business logic, or multiple error returns, it's convenient to gradually add metadata to your error.\nFor this purpose Encore provides errs.Builder. The builder lets you gradually set aspects of the error, using a chaining API design. Use errs.B() to get a new builder that you can start chaining with directly.\nWhen you want to return the constructed error call the .Err() method.\nFor example:\nfunc getBoard(ctx context.Context, boardID int64) (*Board, error) { // Construct a new error builder with errs.B() eb := errs.B().Meta(\"board_id\", params.ID) b := &Board{ID: params.ID} err := sqldb.QueryRow(ctx, ` SELECT name, created FROM board WHERE id = $1 `, params.ID).Scan(&b.Name, &b.Created) if errors.Is(err, sqldb.ErrNoRows) { // Return a \"board not found\" error with code == NotFound return nil, eb.Code(errs.NotFound).Msg(\"board not found\").Err() } else if err != nil { // Return a general error return nil, eb.Cause(err).Msg(\"could not get board\").Err() } // ... } \nInspecting API Errors\nWhen you call another API within Encore, the returned errors are always wrapped in *errs.Error.\nYou can inspect the error information either by casting to *errs.Error, or using the below helper methods.\nfunc Code(err error) ErrCode \nerrs.Code returns the error code. If the error was not an *errs.Error it returns errs.Unknown.\nfunc Meta(err error) Metadata type Metadata map[string]interface{} \nerrs.Meta returns any structured metadata present in the error. If the error was not an *errs.Error it returns nil. Unlike when you return error information to external clients, all the metadata is sent to the calling service, making debugging even easier.\nfunc Details(err error) ErrDetails \nerrs.Details returns the structured error details. If the error was not an *errs.Error or the error lacked details, it returns nil."
  },
  {
    "url": "https://encore.dev/docs/develop/api-schemas",
    "text": "APIs in Encore are regular functions with request and response data types. These types are structs (or pointers to structs) with optional field tags, which Encore uses to encode API requests to HTTP messages. The same struct can be used for requests and responses, but the query tag is ignored when generating responses.\nAll tags except json are ignored for nested tags, which means you can only define header and query parameters for root level fields.\nFor example, this struct:\ntype NestedRequestResponse struct { Header string `header:\"X-Header\"`// this field will be read from the http header Query string `query:\"query\"`// this field will be read from the query string Body1 string `json:\"body1\"` Nested struct { Header2 string `header:\"X-Header2\"`// this field will be read from the body Query2 string `query:\"query2\"`// this field will be read from the body Body2 string `json:\"body2\"` } `json:\"nested\"` } \nWould be unmarshalled from this request:\nPOST /example?query=a%20query HTTP/1.1 Content-Type: application/json X-Header: A header { \"body1\": \"a body\", \"nested\": { \"Header2\": \"not a header\", \"Query2\": \"not a query\", \"body2\": \"a nested body\" } } \nAnd marshalled to this response:\nHTTP/1.1 200 OK Content-Type: application/json X-Header: A header { \"Query\": \"not a query\", \"body1\": \"a body\", \"nested\": { \"Header2\": \"not a header\", \"Query2\": \"not a query\", \"body2\": \"a nested body\" } } \nPath parameters\nPath parameters are specified by the path field in the //encore:api annotation. To specify a placeholder variable, use :name and add a function parameter with the same name to the function signature. Encore parses the incoming request URL and makes sure it matches the type of the parameter. The last segment of the path can be parsed as a wildcard parameter by using *name with a matching function parameter.\n// GetBlogPost retrieves a blog post by id. //encore:api public method=GET path=/blog/:id/*path func GetBlogPost(ctx context.Context, id int, path string) (*BlogPost, error) { // Use id to query database... } \nFallback routes\nEncore supports defining fallback routes that will be called if no other endpoint matches the request, using the syntax path=/!fallback.\nThis is often useful when migrating an existing backend service over to Encore, as it allows you to gradually migrate endpoints over to Encore while routing the remaining endpoints to the existing HTTP router using a raw endpoint with a fallback route.\nFor example:\n//encore:service type Service struct { oldRouter *gin.Engine // existing HTTP router } // Route all requests to the existing HTTP router if no other endpoint matches. //encore:api public raw path=/!fallback func (s *Service) Fallback(w http.ResponseWriter, req *http.Request) { s.oldRouter.ServeHTTP(w, req) } \nHeaders are defined by the header field tag, which can be used in both request and response data types. The tag name is used to translate between the struct field and http headers. In the example below, the Language field of ListBlogPost will be fetched from the Accept-Language HTTP header.\ntype ListBlogPost struct { Language string `header:\"Accept-Language\"` Author string // Not a header } \nQuery parameters\nFor GET, HEAD and DELETE requests, parameters are read from the query string by default. The query parameter name defaults to the snake-case encoded name of the corresponding struct field (e.g. BlogPost becomes blog_post).\nThe query field tag can be used to parse a field from the query string for other HTTP methods (e.g. POST) and to override the default parameter name. \nQuery strings are not supported in HTTP responses and therefore query tags in response types are ignored.\nIn the example below, the PageLimit field will be read from the limit query parameter, whereas the Author field will be parsed from the query string (as author) only if the method of the request is GET, HEAD or DELETE.\ntype ListBlogPost struct { PageLimit int `query:\"limit\"` // always a query parameter Author string // query if GET, HEAD or DELETE, otherwise body parameter } \nBody parameters\nEncore will default to reading request parameters from the body (as JSON) for all HTTP methods except GET, HEAD or DELETE. The name of the body parameter defaults to the field name, but can be overridden by the json tag. Response fields will be serialized as JSON in the HTTP body unless the header tag is set.\nThere is no tag to force a field to be read from the body, as some infrastructure entities do not support body content in GET, HEAD or DELETE requests.\ntype CreateBlogPost struct { Subject string `json:\"limit\"` // query if GET, HEAD or DELETE, otherwise body parameter Author string // query if GET, HEAD or DELETE, otherwise body parameter } \nSupported types\nThe table below lists the data types supported by each HTTP message location.\nTypeHeaderPathQueryBody\nbool\tX\tX\tX\tX\t\nnumeric\tX\tX\tX\tX\t\nstring\tX\tX\tX\tX\t\ntime.Time\tX\tX\tX\tX\t\nuuid.UUID\tX\tX\tX\tX\t\njson.RawMessage\tX\tX\tX\tX\t\nlist\t\t\tX\tX\t\nstruct\t\t\t\tX\t\nmap\t\t\t\tX\t\npointer\t\t\t\tX\t\nRaw endpoints\nIn some cases you may need to fulfill an API schema that is defined by someone else, for instance when you want to accept webhooks. This often requires you to parse custom HTTP headers and do other low-level things that Encore usually lets you skip.\nFor these circumstances Encore lets you define raw endpoints. Raw endpoints operate at a lower abstraction level, giving you access to the underlying HTTP request.\nLearn more in the raw endpoints documentation.\nSensitive data\nEncore's built-in tracing functionality automatically captures request and response payloads to simplify debugging. That's not desirable if a request or response payload contains sensitive data, such as API keys or personally identifiable information (PII).\nFor those use cases Encore supports marking a field as sensitive using the struct tag encore:\"sensitive\". Encore's tracing system will automatically redact fields tagged as sensitive. This works for both individual values as well as nested fields.\nNote that inputs to auth handlers are automatically marked as sensitive and are always redacted.\nRaw endpoints lack a schema, which means there's no way to add a struct tag to mark certain data as sensitive. For this reason Encore supports tagging the whole API endpoint as sensitive by adding sensitive to the //encore:api annotation. This will cause the whole request and response payload to be redacted, including all request and response headers.\nPlease note\nThe encore:\"sensitive\" tag is ignored for local development environments to make development and debugging with the Local Development Dashboard easier.\nExample\npackage blog // service name import ( \"time\" \"encore.dev/types/uuid\" ) type Updates struct { Author string `json:\"author,omitempty\"` PublishTime time.Time `json:\"publish_time,omitempty\"` } // BatchUpdateParams is the request data for the BatchUpdate endpoint. type BatchUpdateParams struct { Requester string `header:\"X-Requester\"` RequestTime time.Time `header:\"X-Request-Time\"` CurrentAuthor string `query:\"author\"` Updates *Updates `json:\"updates\"` MySecretKey string `encore:\"sensitive\"` } // BatchUpdateResponse is the response data for the BatchUpdate endpoint. type BatchUpdateResponse struct { ServedBy string `header:\"X-Served-By\"` UpdatedIDs []uuid.UUID `json:\"updated_ids\"` } //encore:api public method=POST path=/section/:sectionID/posts func BatchUpdate(ctx context.Context, sectionID string, params *BatchUpdateParams) (*BatchUpdateResponse, error) { // Update blog posts for section return &BatchUpdateResponse{ServedBy: hostname, UpdatedIDs: ids}, nil }"
  },
  {
    "url": "https://encore.dev/docs/how-to/import-kubernetes-cluster",
    "text": "When you deploy your application to your own cloud, Encore can provision infrastructure for it in many different ways – including setting up a Kubernetes cluster.\nHowever, if you already have a Kubernetes cluster, you may want to deploy your Encore application into this pre-existing cluster. This is often useful if you want to integrate your Encore application with other parts of your system that are not built using Encore.\nTo support this use case, Encore enables you to import existing Kubernetes clusters on Google Cloud Platform (AWS coming soon).\nImporting a cluster\nTo import your cluster, go to Create Environment in the Cloud Dashboard, select Kubernetes: Existing GKE Cluster as the compute platform, and then specify your cluster's Project ID, Region, and Cluster Name.\nWhen you deploy to this environment, Encore will use your imported cluster as the compute instance."
  },
  {
    "url": "https://encore.dev/docs/how-to/temporal",
    "text": "Temporal is a workflow orchestration system for building highly reliable systems. Encore works great with Temporal, and this guide shows you how to integrate Temporal into your Encore application.\nSet up Temporal clusters\nYou'll need at least two Temporal clusters: one for local development and one for cloud environments.\nWe recommend using Temporalite for local development, and Temporal Cloud for cloud environments. \nSet up Temporal Workflow\nNext it's time to create a Temporal Workflow. We'll base this on the Temporal Hello World example.\nCreate a new Encore service named greeting:\npackage greeting import ( \"context\" \"fmt\" \"go.temporal.io/sdk/client\" \"go.temporal.io/sdk/worker\" \"encore.dev\" ) // Use an environment-specific task queue so we can use the same // Temporal Cluster for all cloud environments. var ( envName = encore.Meta().Environment.Name greetingTaskQueue = envName + \"-greeting\" ) //encore:service type Service struct { client client.Client worker worker.Worker } func initService() (*Service, error) { c, err := client.Dial(client.Options{}) if err != nil { return nil, fmt.Errorf(\"create temporal client: %v\", err) } w := worker.New(c, greetingTaskQueue, worker.Options{}) err = w.Start() if err != nil { c.Close() return nil, fmt.Errorf(\"start temporal worker: %v\", err) } return &Service{client: c, worker: w}, nil } func (s *Service) Shutdown(force context.Context) { s.client.Close() s.worker.Stop() } \nNext it's time to define some workflows. These need to be in the same service, so add a new workflow package inside the greeting service, containing a workflow and activity definition in separate files:\ngreeting/workflow/workflow.go\ngreeting/workflow/activity.go\npackage workflow import ( \"time\" \"go.temporal.io/sdk/workflow\" ) func Greeting(ctx workflow.Context, name string) (string, error) { options := workflow.ActivityOptions{ StartToCloseTimeout: time.Second * 5, } ctx = workflow.WithActivityOptions(ctx, options) var result string err := workflow.ExecuteActivity(ctx, ComposeGreeting, name).Get(ctx, &result) return result, err } \nThen, go back to the greeting service and register the workflow and activity:\n// Import the package at the top: import \"encore.app/greeting/workflow\" // Add these lines to `initService`, below the call to `worker.New`: w.RegisterWorkflow(workflow.Greeting) w.RegisterActivity(workflow.ComposeGreeting) \nNow let's create an Encore API that triggers this workflow.\nAdd a new file greeting/greet.go:\npackage greeting import ( \"context\" \"encore.app/greeting/workflow\" \"encore.dev/rlog\" \"go.temporal.io/sdk/client\" ) type GreetResponse struct { Greeting string } //encore:api public path=/greet/:name func (s *Service) Greet(ctx context.Context, name string) (*GreetResponse, error) { options := client.StartWorkflowOptions{ ID: \"greeting-workflow\", TaskQueue: greetingTaskQueue, } we, err := s.client.ExecuteWorkflow(ctx, options, workflow.Greeting, name) if err != nil { return nil, err } rlog.Info(\"started workflow\", \"id\", we.GetID(), \"run_id\", we.GetRunID()) // Get the results var greeting string err = we.Get(ctx, &greeting) if err != nil { return nil, err } return &GreetResponse{Greeting: greeting}, nil } \nRun it locally\nNow we're ready to test it out. Start up temporalite and your Encore application (in separate terminals):\n$ temporalite start --namespace default $ encore run \nNow try calling it, either from the Local Development Dashboard or using cURL:\n$ curl 'http://localhost:4000/greeting/Temporal' {\"Greeting\": \"Hello Temporal!\"} \nIf you see this, it works!\nRun in the cloud\nTo run it in the cloud, you will need to use Temporal Cloud or your own, self-hosted Temporal cluster. The easiest way to automatically pick up the correct cluster address is to use Encore's config functionality.\nAdd two new files:\ngreeting/config.go\ngreeting/config.cue\npackage greeting import \"encore.dev/config\" type Config struct { TemporalServer string } var cfg = config.Load[*Config]() \nFinally go back to greeting/greeting.go and update the client.Dial call to look like:\nclient.Dial(client.Options{HostPort: cfg.TemporalServer}) \nWith that, Encore will automatically connect to the correct Temporal cluster, using a local cluster for local development and your cloud-hosted cluster for everything else."
  },
  {
    "url": "https://encore.dev/docs/how-to/submit-template",
    "text": "Templates help and inspire developers to build applications using Encore.\nYou are welcome to contribute your own templates!\nTwo types of templates that are especially useful:\nStarters: Runnable Encore applications for others to use as is, or take inspiration from.\nBits: Re-usable code samples to solve common development patterns or integrate Encore applications with third-party APIs and services.\nSubmit your contribution\nContribute a template by submitting a Pull Request to the Open Source Examples Repo: https://github.com/encoredev/examples\nSubmitting Starters\nFollow these steps to submit a Starter:\nFork the repo.\nCreate a new folder in the root directory of the repo, this is where you will place your template. — Use a short folder name as your template will be installable via the CLI, like so: encore app create APP-NAME --example=<TEMPLATE_FOLDER_NAME>\nInclude a README.md with instructions for how to use the template. We recommend following this format.\nOnce your Pull Request has been approved, it may be featured on the Templates page on the Encore website.\nSubmitting Bits\nFollow these steps to submit your Bits:\nFork the repo.\nCreate a new folder inside the bits folder in the repo and place your template inside it. Use a short folder name as your template will soon be installable via the CLI.\nInclude a README.md with instructions for how to use the template.\nOnce your Pull Request has been approved, it may be featured on the Templates page on the Encore website.\nContribute from your own repo\nIf you don't want to contribute code to the examples repo, but still want to be featured on the Templates page, please contact us at [email protected].\nDynamic Encore AppID\nIn most cases, you should avoid hardcoding an AppID in your template's source code. Instead, use the notation {{ENCORE_APP_ID}}.\nWhen a developer creates an app using the template, {{ENCORE_APP_ID}} will be dymically replaced with their new and unique AppID, meaning they will not need to make any manual code adjustments."
  },
  {
    "url": "https://encore.dev/docs/other/vs-heroku",
    "text": "In the early days of the cloud, Heroku was seen as an innovative platform that made deployments and infrastructure management very simple using a Platform as a Service (PaaS) approach. Ultimately, Heroku lost momentum and, as cloud services rapidly evolved in the past decade, the platform didn't manage to provide enough flexibility to support users' needs.\nFans of Heroku will recognize much of the same simplicity in Encore's push to deploy workflow — the big difference is that Encore deploys to your own cloud on AWS/GCP. This means you keep full flexibility to scale your application using battle-tested services from the major cloud providers, and can leverage their full arsenal of thousands of different services.\nLet's take a look at how Encore compares to PaaS tools like Heroku:\nEncoreHeroku\nInfrastructure approach?\tInfrastructure from Code\tPlatform as a Service\t\nBuilt-in CI/CD?\t✅︎ Yes\t✅︎ Yes\t\nBuilt-in Preview Environments?\t✅︎ Yes\t✅︎ Yes\t\nBuilt-in local dev environment?\t✅︎ Yes\t❌ No\t\nBuilt-in Distributed Tracing?\t✅︎ Yes\t❌ No\t\nDeploys to major cloud providers like AWS & GCP?\t✅︎ Yes\t❌ No\t\nAvoids cloud lock-in?\t✅︎ Yes\t❌ No\t\nSupports Kubernetes and custom infra?\t✅︎ Yes\t❌ No\t\nInfrastructure is Type-Safe?\t✅︎ Yes\t❌ No\t\nCharges for hosting?\tNo\tYes\t\nEncore is the simplest way of accessing the full power and flexibility of the major cloud providers\nWith Encore you don't need to be a cloud expert to make full use of the services offered by major cloud providers like AWS and GCP.\nYou simply use Encore's Infrastructure SDK to declare the infrastructure semantics directly in your application code, and Encore then automatically provisions the necessary infrastructure in your cloud, and provides a local development environment that matches your cloud environment.\nYou get the same, easy to use, \"push to deploy\" workflow that many developers appreciate with Heroku, while still being able to build large-scale distributed systems and event-driven applications deployed to AWS and GCP.\nEncore's local development workflow lets application developers focus\nWhen using PaaS service like Heroku to deploy your application, you're not at all solving for an efficient local development workflow.\nThis means, with Heroku, developers need to manually set up and maintain their local environment and observability tools, in order to facilitate local development and testing.\nThis can be a major distraction for application developers, because it forces them to spend time learning how to setup and maintain various local versions of cloud infrastructure, e.g. by using Docker Compose. This work is a continuous effort as the system evolves, and becomes more and more complex as the service and infrastructure footprint grows.\nAll this effort takes time away from product development and slows down onboarding time for new developers.\nWhen using Encore, your local and cloud environments are both defined by the same code base: your application code. This means developers only need to use encore run to start their local dev envioronments. Encore's Open Source CLI takes care of setting up local version of all infrastructure and provides a local development dashboard with built-in observability tools.\nThis greately speeds up development iterations as developers can start using new infrastructure immediately, which makes building new services and event-driven systems extremely efficient.\nEncore provides an end-to-end purpose-built workflow for cloud backend developement\nEncore does a lot more than just automate infrastructure provisioning and configuration. It's designed as a purpose-built tool for cloud backend development and comes with out-of-the-box tooling for both development and DevOps.\nEncore's built-in developer tools\nCross-service type-safety with IDE auto-complete\nDistributed Tracing\nTest Tracing\nAutomatic API Documentation\nAutomatic Architecture Diagrams\nAPI Client Generation\nSecrets Management\nService/API mocking\nEncore's built-in DevOps tools\nAutomatic Infrastructure provisioning on AWS/GCP\nInfrastructure Tracking & Approvals workflow\nCloud Configuration 2-way sync between Encore and AWS/GCP\nAutomatic least privilege IAM\nPreview Environments per Pull Request\nCost Analytics Dashboard\nEncore Terraform provider for extending Encore with infrastructure that is not currently part of Encore's Infrastructure SDK"
  },
  {
    "url": "https://encore.dev/docs/other/vs-supabase",
    "text": "Supabase and Firebase are two popular Backend as a Service providers, that provide developers with an easy way to get a database up and running for their applications. They also bundle some built-in services for common use cases like authentication. \nThis can be a great way of getting off the ground quickly. But as many developers have come to learn, you risk finding yourself boxed into a corner if you're not in full control of your own backend when new use cases arise.\nEncore is not a Backend as a Service, it's a platform for backend development. It gives you many of the same benefits that Supabase and Firebase offer, like not needing to manually provision your databases (or any other infrastructure for that matter). The key difference is, Encore provisions your infrastructure in your own cloud account on AWS/GCP. This also lets you easily use any cloud service offered by the major cloud providers, and you don't risk being limited by the platform and and having to start over from scratch.\nLet's take a look at how Encore compares to BaaS platforms like Supabase and Firebase:\nEncoreSupabaseFirebase\nApproach?\tBackend Development Platform\tBackend as a Service\tBackend as a Service\t\nNative PostgreSQL support?\t✅︎ Yes\t✅︎ Yes\t❌ No\t\nSupport pgvector for AI use cases?\t✅︎ Yes\t✅︎ Yes\t❌ No\t\nSupports major cloud providers like AWS/GCP?\t✅︎ Yes\t❌ No\t✅︎ Yes (GCP only)\t\nSupports Microservices?\t✅︎ Yes\t❌ No\t❌ No\t\nSupports Event-Driven systems?\t✅︎ Yes\t❌ No\t❌ No\t\nSupports Kubernetes and custom infra?\t✅︎ Yes\t❌ No\t❌ No\t\nInfrastructure is Type-Safe?\t✅︎ Yes\t❌ No\t❌ No\t\nBuilt-in local dev environment?\t✅︎ Yes\t❌ No\t❌ No\t\nBuilt-in Preview Environments per Pull Request?\t✅︎ Yes\t❌ No\t❌ No\t\nBuilt-in Distributed Tracing?\t✅︎ Yes\t❌ No\t❌ No\t\nCharges for hosting?\tNo\tYes\tYes\t\nEncore is the simplest way of accessing the full power and flexibility of the major cloud providers\nWith Encore you don't need to be a cloud expert to make full use of the services offered by major cloud providers like AWS and GCP.\nYou simply use Encore's Infrastructure SDK to declare the infrastructure semantics directly in your application code, and Encore then automatically provisions the necessary infrastructure in your cloud, and provides a local development environment that matches your cloud environment.\nExample: Using PostgreSQL with Encore\nHere's an example of how to use Encore's Infrastructure SDK to define a PostgreSQL database (Go is used in the example, TypeScript support is also available):\nTo create a database, import encore.dev/storage/sqldb and call sqldb.NewDatabase, assigning the result to a package-level variable. Databases must be created from within an Encore service.\nFor example:\ntodo/db.go\ntodo/migrations/1_create_table.up.sql\npackage todo // Create the todo database and assign it to the \"tododb\" variable var tododb = sqldb.NewDatabase(\"todo\", sqldb.DatabaseConfig{ Migrations: \"./migrations\", }) // Then, query the database using db.QueryRow, db.Exec, etc. \nAs seen above, the sqldb.DatabaseConfig specifies the directory containing the database migration files, which is how you define the database schema.\nWith this code in place Encore will automatically create the database when starting encore run (locally) or on the next deployment (in the cloud). Encore automatically injects the appropriate configuration to authenticate and connect to the database, so once the application starts up the database is ready to be used.\nLearn more about using databases with Encore\nEncore makes it simple to build type-safe event-driven systems\nUnlike BaaS platforms like Supabase and Firebase, Encore has extensive support for building microservices backends and event-driven systems.\nFor example, Encore lets you define APIs using regular functions and enables cross-service type-safety with IDE auto-complete when making API calls between services.\nWith Encore's Infrastructure SDK, you can build event-driven systems by defining Pub/Sub topcis and subscriptions as type-safe objects in your application. This gives you type-safety for Pub/Sub with compilation errors for any type-errors.\nEncore's local development workflow lets application developers focus\nWhen using BaaS service like Supabase to handle your infrastructure, you're not at all solving for local development.\nThis means, with Supabase, developers need to manually set up and maintain their local environment in order to facilitate local development and testing.\nThis can be a major distraction for application developers, because it forces them to spend time learning how to setup and maintain various local versions of cloud infrastructure, e.g. by using Docker Compose. This work is a continuous effort as the system evolves, and becomes more and more complex as the service and infrastructure footprint grows.\nAll this effort takes time away from product development and slows down onboarding time for new developers.\nWhen using Encore, your local and cloud environments are both defined by the same code base: your application code. This means developers only need to use encore run to start their local dev envioronments. Encore's Open Source CLI takes care of setting up local version of all infrastructure and provides a local development dashboard with built-in observability tools.\nThis greately speeds up development iterations as developers can start using new infrastructure immediately, which makes building new services and event-driven systems extremely efficient.\nEncore provides an end-to-end purpose-built workflow for cloud backend developement\nEncore does a lot more than just automate infrastructure provisioning and configuration. It's designed as a purpose-built tool for cloud backend development and comes with out-of-the-box tooling for both development and DevOps.\nEncore's built-in developer tools\nCross-service type-safety with IDE auto-complete\nDistributed Tracing\nTest Tracing\nAutomatic API Documentation\nAutomatic Architecture Diagrams\nAPI Client Generation\nSecrets Management\nService/API mocking\nEncore's built-in DevOps tools\nAutomatic Infrastructure provisioning on AWS/GCP\nInfrastructure Tracking & Approvals workflow\nCloud Configuration 2-way sync between Encore and AWS/GCP\nAutomatic least privilege IAM\nPreview Environments per Pull Request\nCost Analytics Dashboard\nEncore Terraform provider for extending Encore with infrastructure that is not currently part of Encore's Infrastructure SDK"
  },
  {
    "url": "https://encore.dev/docs/how-to/try-encore",
    "text": "Making changes to your backend requires a thoughtful approach and how you best evaluate a new tool, like Encore, depends on your situation and priorities. Here we’ll explore three approaches and introduce the common scenarios and procedures for each:\nExtend: Using Encore to speed up building an independent new system or creating a proof of concept.\nRefactor: Using Encore when refactoring an existing backend to unlock productivity benefits and remove complexity.\nRebuild: Using Encore when rebuilding an existing application from the ground up, ensuring modern best practices and cloud-portability.\nExtend\nExtending your existing backend best suits teams who are mostly satisfied with their current setup, but are on the lookout for more efficient workflows to cut down delivery times for new projects, or wish to improve the developer experience for ongoing development.\nUse cases\nExtending an existing application with a new service or system, integrated using APIs.\nReducing effort when building a new system in an isolated domain, such as a new product experiment.\nTackling an independent project that demands fast delivery times.\nWhen to consider Encore\nIf your existing setup feels right but you’re curious about Encore, evaluating it in an independent project is the right move. For example when:\nYou want to create a new service or system and deploy it to your cloud in AWS or GCP, without manual infrastructure setup.\nYou want to try out development tools like preview environments, and local tracing, without any manual instrumentation.\nYou want to validate Encore’s workflow and reliability without making changes to existing systems.\nHow to adopt Encore when Extending\n1. Identify Extension Points: Decide on an upcoming project or proof of concept, that is relatively independent of your existing application and is appropriate for building as a new service or system.\n2. Create New Services: Develop new services or systems using Encore’s API Framework and Infrastructure SDK to get off the ground quickly. This lets you try out all Encore features and enables you to design your new system with Encore’s automatic architecture diagrams.\n3. Integrate via APIs: Where relevant, integrate your new system with your existing backend application using APIs. This can be made simpler by using Encore’s generated API clients.\n4. Validate & Iterate: Deploy the new services to a cloud environment, automatically provisioned by Encore, and validate their performance and interoperability. Use Encore’s distributed tracing to find bugs or performance issues.\n5. Connect cloud and Deploy: When you are satisfied that your application is working as expected, connect your cloud account (AWS or GCP) and create a production environment for your application. Encore automatically provisions the infrastructure needed using each cloud’s native services, or you can deploy your application into an existing Kubernetes cluster.\nRefactor\nRefactoring can serve as a breath of fresh air for your existing code, revitalizing it by optimizing existing structures. In this approach, your goal is to improve on your existing backend application, often focusing on shedding unnecessary complexity and enabling new opportunities.\nUse cases\nTransforming a monolith into microservices.\nChanging system architecture, e.g. moving to an event-driven architecture.\nCloud migration, e.g. from AWS to GCP.\nChanging foundational infrastructure, e.g. migrating to Kubernetes.\nRemoving unwanted complexity that’s become engrained as you’ve scaled up quickly.\nWhen to consider Encore\nYour application is already built using a supported programming language like Go or TypeScript. and you want to unlock modern development tools like infrastructure automation, preview environments, and distributed tracing, with minimal adjustments to your existing backend and no manual setup.\nHow to adopt Encore in a Refactor\n1. Assess Your Goal: Start by evaluating what changes you want to make to your existing application, and look for unnecessary complexities and bottlenecks that can be eliminated. Depending on your goal, you can decide if you want to fully implement Encore’s API Framework or if you prefer to minimize changes by using a catch-all handler on your current router. Keep in mind that in order to use features like the Service Catalog and API Explorer, you need to use the API Framework. (Learn more about the different options)\n2. Implement Infrastructure SDK: Implement Encore's Infrastructure SDK in your application by replacing existing infrastructure configuration and boilerplate. This enables you to use Encore's infrastructure automation and removes the hassle of manual infrastructure setup. Tip: Existing databases can be integrated so you don’t need to migrate existing data.\n3. Resolve compile-time errors: Encore comes with a parser and compiler that ensures your application correctly implements the API Framework and Infrastructure SDK. This lets you discover problems at compile time and provides insightful error messages to help you quickly resolve any errors.\n4. Test & Iterate: Test the refactored application to ensure stability and reliability using Encore’s automatically provisioned cloud environments and distributed tracing for fast debugging and iteration. If relevant, you can use a generated client to integrate with your existing application frontend.\n5. Connect cloud and Deploy: When you are satisfied that your application is working as expected, connect your cloud account (AWS or GCP) and create a production environment for your application. Encore automatically provisions the infrastructure needed using each cloud’s native services, or you can deploy your application into an existing Kubernetes cluster.\nRebuild\nThe Rebuild strategy is for those who want a fresh start by recreating an application from the ground up. It’s particularly relevant for companies looking to make a bigger change like changing programming language or migrating from legacy self-hosted infrastructure. A full rebuild, although potentially labor-intensive, opens up opportunities to harness the latest cloud services and developer tools like Encore.\nUse cases\nChanging programming languages to adopt more performant or modern ones for your project.\nMigrating from legacy self-hosted solutions to scalable cloud providers like AWS or GCP.\nStarting fresh by recreating an app from the ground up.\nWhen to consider Encore\nYou’re intending to use a supported programming language like Go or TypeScript.\nYou want to leverage the scalability and services of cloud providers like AWS or GCP, but don’t want to become locked-in to one specific provider. (Encore applications are cloud-portable by default.)\nYou want modern development tools like infrastructure automation, preview environments, and distributed tracing, without manual setup or instrumentation.\nHow to adopt Encore in a Rebuild\n1. Plan & Design: Start by creating a design, considering the application's core requirements and architecture. Decide on the programming language, keeping in mind Encore's supported languages.\n2. Develop from Scratch: Develop your new application using Encore's API Framework and Infrastructure SDK to get up and running quickly in a shared environment using Encore’s built-in development cloud.\n3. Test & Iterate: Test your new application to ensure reliability using Encore’s distributed tracing for fast debugging and iteration. Use the generated API clients to integrate with your application frontend.\n4. Connect cloud and Deploy: When you are satisfied that your application is working as expected, connect your cloud account (AWS or GCP) and create a production environment for your application. Encore automatically provisions the infrastructure needed using each cloud’s native services, or you can deploy your application into an existing Kubernetes cluster.\nGet support adopting Encore\nEach approach has different benefits and is relevant in different scenarios. Which one is right for your team depends on your priorities and existing setup.\nWhether it’s expanding your horizons with Extend, revitalizing existing structures through Refactor, or starting afresh with Rebuild, we’re available to support as you explore Encore to unlock improved productivity and developer experience.\nWe're happy to chat through your use case in a call. You can also join Discord to ask questions and meet fellow Encore developers."
  },
  {
    "url": "https://encore.dev/docs/how-to/migrate-to-encore",
    "text": "Encore features like automatic infrastructure provisioning, distributed tracing, architecture diagrams, and API documentation, rely on the Encore application model.\nBuilding your backend using Encore's API framework and declarative Infrastructure SDK is what enables Encore to create the application model. This doesn't mean a complete rewrite is necessary to adopt Encore, and in this guide we look at strategies for both incremental adoption and fully migrating your existing backend to Encore.\nGet help with adopting Encore\nIf you'd like to ask questions or get hands on advice about how to approach adopting Encore, we're happy to chat through your use case in a call. You can also join Discord to ask questions and meet fellow Encore developers.\nIncremental adoption: Build or refactor a single service\nWe recommend using Encore to build a single service to validate if it would work well for your organization. This could be a new, relatively independent project, or a current service or system that needs refactoring. With this approach you can use all Encore features from the start, and then incrementally migrate more services over time.\nYour Encore application will talk to your existing backend through APIs, and can be provisioned in your existing cloud account as pictured below.\n1. Create an Encore app and integrate with GitHub\nThe first step in any project is to create an Encore app. If you've not tried Encore before, we recommend starting by following the Quick Start Guide.\nOnce you've created you app, integrate it with your GitHub repository and you'll get automatic Preview Environments for every Pull Request.\n2. Prototype your new backend system\nOnce you've created your app, it's time to start building. If you're new to Encore, we recommend trying out some of the tutorials.\nIf you need help or have questions, join the friendly developer community on Discord.\nDesign your APIs\nSince Encore is designed to build distributed systems, it should be straightforward to build a new system that integrates with your existing backend through APIs. See the defining APIs documentation for more details.\nShould you want to accept webhooks, that's simple to do using Encore's Raw endpoints as described in the webhooks guide.\nYou can also generate API clients in several languages, which makes it simple to integrate with frontends or other systems. See the Client Generation documentation for more details.\nStoring Secrets\nWhen you need to store secrets, you can use Encore's built-in secrets manager. It lets you store and manage secrets for all environments, and will automatically provision a secret manager in your cloud account once you deploy to production.\nConnect to an existing database\nWhen you create an Encore service and add a database to it, Encore will automatically provision the necessary infrastructure for you. When migrating, it's common to also want to connect to an existing database. See this guide for instructions on how to do that with Encore.\n3. Deploy to your cloud account\nOnce you're ready to deploy, you can connect your cloud account (GCP or AWS) and have Encore deploy and provision your new system directly in your existing account.\nSee the infrastructure documentation for details on how Encore provisions cloud infrastructure for each cloud provider.\nRinse and repeat\nOnce you're confident that Encore is a good fit, you can use this incremental migration strategy to move more services over to Encore. This will make Encore benefits like automatic provisioning, preview environments, architecture diagrams, and distributed tracing available for more parts of your system.\nForklift migration using a catch-all handler\nIf your existing backend system is built with Go, you can use a forklift migration strategy and move the entire application over to Encore in one shot by wrapping your existing HTTP router in a catch-all handler.\nThis can be relatively straightforward if your existing system is a monolith, or smaller distributed system, and does not rely on many unsupported cloud primitives.\nThe benefits of this approach is that you'll get everything in one place from the start, and you'll be able to quickly use features like Encore's CI/CD system and secrets manager, for your entire backend application.\nHowever, you will not immediately be able to use some of the powerful Encore features, like distributed tracing and architecture diagrams, which rely on the Encore application model.\nOnce your Encore app is up and running, you'll have something that looks like the image below. Notice how Encore doesn't have complete visibility into the inner workings of your application.\n1. Create an app and structure your code\nTo start, create an Encore application and copy over the code from your existing repository. In order to run your application with Encore, it needs to follow the expected application structure, which involves placing the encore.app and go.mod files in the repository root. This should be straightforward to do with minor modifications.\nAs an example, a single service application might look like this on disk:\n/my-app ├── encore.app // ... and other top-level project files │ └── hello // hello service (a Go package) ├── migrations // hello service db migrations (directory) │ └── 1_create_table.up.sql // hello service db migration ├── hello.go // hello service code └── hello_test.go // tests for hello service \nYou can also have services nested inside a backend folder if you prefer.\n2. Create a catch-all handler for your HTTP router\nNow let's mount your existing HTTP router under a Raw endpoint, which is an Encore API endpoint type that gives you access to the underlying HTTP request.\nHere's a basic code example:\n//encore:api public raw path=/api/*path func MigrationHandler(w http.ResponseWriter, req *http.Request) { // pass request to existing router } \nBy mounting your existing HTTP router in this way, it will work as a catch-all handler for all HTTP requests and responses. This should make your application deployable through Encore with little refactoring. \n3. Iteratively fix remaining compilation errors\nExactly what remains to make your application deployable with Encore will depend on your specific app. As you run your app locally, using encore run, Encore will parse and compile it, and give you compilation errors to inform what needs to be adjusted.\nBy iteratively making adjustments, you should relatively quickly be able to get your application up and running with Encore.\nIf you need help or have questions, join the developer community on Discord or send an email to [email protected].\nIncrementally start using the Encore infrastructure SDK\nOnce your application is deployed, gradually break out specific endpoints using Encore's API framework and introduce infrastructure declarations using Encore's Infrastructure SDK. This will let Encore understand your application and unlock all Encore features."
  },
  {
    "url": "https://encore.dev/docs/how-to/share-db-between-services",
    "text": "By default, each service in an Encore app has its own database. This approach has many benefits: \nWhich database is used and how it works is abstracted away from other services\nThe database is more isolated, making changes to it smaller and safer\nBy making the services more independent your application becomes more reliable by being able to more gracefully handle partial outages, such as if your database is temporarily overloaded or offline.\nBut like everything else in software engineering, there are trade-offs involved, and sometimes it's simpler and more reliable to use a single database that's accessed by multiple services. Encore makes this easy to do.\nEach database in Encore is defined within a service. That service's name becomes the name of the database. Other services can then access that database by creating a database reference with sqldb.Named(\"dbname\").\nExample\nLet's say you have a simple todo service, with only one table:\ntodo/migrations/1_create_table.up.sql\nCREATE TABLE todo_item ( id BIGSERIAL PRIMARY KEY, title TEXT NOT NULL, done BOOLEAN NOT NULL DEFAULT FALSE ); \nYou want to create a report service that produces various reports for internal business processes, but for simplicity you decide it makes sense to directly access the todo database. All that's needed is to define the todoDB variable like so:\nreport/report.go\npackage report import ( \"context\" \"encore.dev/storage/sqldb\" ) // todoDB connects to the \"todo\" service's database. var todoDB = sqldb.Named(\"todo\") type ReportResponse struct { Total int } // CountCompletedTodos generates a report with the number of completed todo items. //encore:api method=GET path=/report/todo func CountCompletedTodos(ctx context.Context) (*ReportResponse, error) { var report ReportResponse err := todoDB.QueryRow(ctx,` SELECT COUNT(*) FROM todo_item WHERE completed = TRUE `).Scan(&report.Total) return &report, err } \nWith that, Encore understands that the report service depends on the todo service's database, and orchestrates the necessary connections to make that happen. And like everything else with Encore, it works exactly the same regardless of where it's running: for local development as well as in the cloud."
  },
  {
    "url": "https://encore.dev/docs/primitives/services-and-apis/service-structs",
    "text": "Encore lets you define a type, called a service struct, to represent your running service. This lets you define an initialization function (similar to the main function in regular Go programs).\nYou can also define API endpoints as methods on the service struct type, enabling you to use dependency injection for testing purposes.\nIt works by defining a struct type of your choice (typically called Service) and declaring it with //encore:service. Then, you can define a special function named initService (or initWhatever if you named the type Whatever) that gets called by Encore to initialize your service when it starts up.\nIt looks like this:\n//encore:service type Service struct { // Add your dependencies here } func initService() (*Service, error) { // Write your service initialization code here. } //encore:api public func (s *Service) MyAPI(ctx context.Context) error { // ... } \nCalling APIs defined on service structs\nWhen using a service struct like above, Encore will create a file named encore.gen.go in your service directory. This file contains package-level functions for the APIs defined as methods on the service struct. In the example above, you would see:\n// Code generated by encore. DO NOT EDIT. package email import \"context\" // These functions are automatically generated and maintained by Encore // to simplify calling them from other services, as they were implemented as methods. // They are automatically updated by Encore whenever your API endpoints change. func Send(ctx context.Context, p *SendParams) error { // The implementation is elided here, and generated at compile-time by Encore. return nil } \nThese functions are generated in order to allow other services to keep calling your APIs as package-level functions, in the same way as before: email.Send(...). This means other services do not need to care about whether you're using Dependency Injection internally. You must always use these generated package-level functions for making API calls.\nPlease note\nEncore will automatically generate these files and keep them up to date whenever your code changes. There is no need to manually invoke anything to regenerate this code.\nEncore adds all encore.gen.go files to your .gitignore since you typically don't want to commit them to your repository; doing so ends up creating a lot of unnecessary merge conflicts.\nHowever, in some cases when running third-party linters in a CI/CD environment it can be helpful to generate these wrappers to make the linter happy. You can do that by invoking encore gen wrappers.\nGraceful Shutdown\nWhen defining a service struct, Encore supports notifying your service when it's time to gracefully shut down. This works by having your service struct implement the method func (s *Service) Shutdown(force context.Context).\nIf that method exists, Encore will call it when it's time to begin gracefully shutting down. Initially the shutdown is in \"graceful mode\", which means that you have a few seconds to complete ongoing work.\nThe provided force context is canceled when the graceful shutdown window is over, and it's time to forcefully shut down. How much time you have from when Shutdown is called to when forceful shutdown begins depends on the cloud provider and the underlying infrastructure. Typically it's in the range 5-30 seconds.\nPlease note\nEncore automatically handles graceful shutdown of all Encore-managed functionality, such as HTTP servers, database connection pools, Pub/Sub message receivers, distributed tracing recorders, and so on.\nThe graceful shutdown functionality is provided if you have additional, non-Encore-related resources that need graceful shutdown.\nNote that graceful shutdown in Encore is cooperative: Encore will wait indefinitely for your Shutdown method to return. If your Shutdown method does not return promptly after the force context is closed, the underlying infrastructure at your cloud provider will typically force-kill your service, which can lead to lingering connections and other such issues.\nIn summary, when your Shutdown(force context.Context) function is called:\nImmediately begin gracefully shutting down\nWhen the force context is canceled, you should forcefully shut down the resources that haven't yet completed their shutdown\nWait until the shutdown is complete before returning from the Shutdown function"
  },
  {
    "url": "https://encore.dev/docs/primitives/databases/extensions",
    "text": "Encore uses the encoredotdev/postgres docker image for local development, CI/CD, and for databases hosted on Encore Cloud.\nThe docker image ships with the following PostgreSQL extensions available for use (via CREATE EXTENSION):\nExtensionVersion\naddress_standardizer\t3.3.4\t\nadminpack\t2.1\t\namcheck\t1.3\t\nautoinc\t1.0\t\nbloom\t1.0\t\nbtree_gin\t1.3\t\nbtree_gist\t1.7\t\ncitext\t1.6\t\ncube\t1.5\t\ndblink\t1.2\t\ndict_int\t1.0\t\ndict_xsyn\t1.0\t\nearthdistance\t1.1\t\nfile_fdw\t1.0\t\nfuzzystrmatch\t1.1\t\nhstore\t1.8\t\ninsert_username\t1.0\t\nintagg\t1.1\t\nintarray\t1.5\t\nisn\t1.2\t\nlo\t1.1\t\nltree\t1.2\t\nmoddatetime\t1.0\t\nold_snapshot\t1.0\t\npageinspect\t1.11\t\npg_buffercache\t1.3\t\npg_freespacemap\t1.2\t\npg_prewarm\t1.2\t\npg_stat_statements\t1.10\t\npg_surgery\t1.0\t\npg_trgm\t1.6\t\npg_visibility\t1.2\t\npg_walinspect\t1.0\t\npgcrypto\t1.3\t\npgrowlocks\t1.2\t\npgstattuple\t1.5\t\nplpgsql\t1.0\t\npostgis\t3.3.4\t\npostgis-3\t3.3.4\t\npostgis_raster\t3.3.4\t\npostgis_raster-3\t3.3.4\t\npostgis_sfcgal\t3.3.4\t\npostgis_sfcgal-3\t3.3.4\t\npostgis_tiger_geocoder\t3.3.4\t\npostgis_tiger_geocoder-3\t3.3.4\t\npostgis_topology\t3.3.4\t\npostgis_topology-3\t3.3.4\t\npostgres_fdw\t1.1\t\nrefint\t1.0\t\nseg\t1.4\t\nsslinfo\t1.2\t\ntablefunc\t1.0\t\ntcn\t1.0\t\ntsm_system_rows\t1.0\t\ntsm_system_time\t1.0\t\nunaccent\t1.1\t\nuuid-ossp\t1.1\t\nvector\t0.4.4\t\nxml2\t1.1"
  },
  {
    "url": "https://encore.dev/docs/ts/develop/errors",
    "text": "Encore provides a standardized format of returning errors from API endpoints.\nIt looks like this:\n// HTTP 404 Not Found { \"code\": \"not_found\", \"message\": \"sprocket not found\", } \nTo return this, throw the APIError exception that Encore provides in the encore.dev/api module, with the appropriate error code:\nimport { APIError, ErrCode } from \"encore.dev/api\"; throw new APIError(ErrCode.NotFound, \"sprocket not found\"); // or as a shorthand you can also write: throw APIError.notFound(\"sprocket not found\"); \nError Codes\nThe ErrCode type in the encore.dev/api module defines error codes for common error scenarios. They are identical to the codes defined by gRPC for interoperability.\nThe table below summarizes the error codes.\nCodeStringHTTP Status\nOK\t\"ok\"\t200 OK\t\nCanceled\t\"canceled\"\t499 Client Closed Request\t\nUnknown\t\"unknown\"\t500 Internal Server Error\t\nInvalidArgument\t\"invalid_argument\"\t400 Bad Request\t\nDeadlineExceeded\t\"deadline_exceeded\"\t504 Gateway Timeout\t\nNotFound\t\"not_found\"\t404 Not Found\t\nAlreadyExists\t\"already_exists\"\t409 Conflict\t\nPermissionDenied\t\"permission_denied\"\t403 Forbidden\t\nResourceExhausted\t\"resource_exhausted\"\t429 Too Many Requests\t\nFailedPrecondition\t\"failed_precondition\"\t400 Bad Request\t\nAborted\t\"aborted\"\t409 Conflict\t\nOutOfRange\t\"out_of_range\"\t400 Bad Request\t\nUnimplemented\t\"unimplemented\"\t501 Not Implemented\t\nInternal\t\"internal\"\t500 Internal Server Error\t\nUnavailable\t\"unavailable\"\t503 Unavailable\t\nDataLoss\t\"data_loss\"\t500 Internal Server Error\t\nUnauthenticated\t\"unauthenticated\"\t401 Unauthorized"
  },
  {
    "url": "https://encore.dev/docs/develop/app-structure",
    "text": "Encore uses a monorepo design and it's best to use one Encore app for your entire backend application. This lets Encore build an application model that spans your entire app, necessary to get the most value out of many features like distributed tracing and Encore Flow.\nIf you have a large application, see advice on how to structure an app with several systems. \nIt's simple to integrate Encore applications with pre-existing systems you might have, using APIs and built-in tools like client generation. See more on how to approach building new functionality incrementally with Encore in the migrating to Encore documentation.\nMonolith or Microservices\nEncore is not opinionated about monoliths vs. microservices. It does however let you build microservices applications with a monolith-style developer experience. For example, you automatically get IDE auto-complete when making API calls between services, along with cross-service type-safety.\nWhen creating a cloud environment on AWS/GCP, Encore enables you to configure if you want to combine multiple services into one process or keep them separate. This can be useful for improved efficiency at smaller scales, and for co-locating services for increased performance. Learn more in the environments documentation.\nCreating services\nTo create an Encore service, you create a Go package and define an API within it. When using databases, you add database migrations in a subfolder migrations to define the structure of the database(s). Learn more in the SQL databases docs.\nOn disk it might look like this:\n/my-app ├── encore.app // ... and other top-level project files │ ├── hello // hello service (a Go package) │ ├── migrations // hello service db migration (directory) │ │ └── 1_create_table.up.sql // hello service db migration │ ├── hello.go // hello service code │ └── hello_test.go // tests for hello service │ └── world // world service (a Go package) └── world.go // world service code \nWhen preferable, you can also share databases between services.\nStructure services using sub-packages\nWithin a service, it's possible to have multiple sub-packages. This is a good way to define components, helper functions, or other code for your functions, should you wish to do that. You can create as many sub-packages, in any kind of nested structure within your service, as you want.\nTo create sub-packages, you create sub-directories within a service package. Sub-packages are internal to services, they are not themselves service packages. This means sub-packages within services cannot themselves define APIs. You can however define an API in a service package that calls a function within a sub-package.\nFor example, rather than define the entire logic for an endpoint in that endpoint's function, you can call functions from sub-packages and divide the logic in any way you want.\nhello/hello.go\npackage hello import ( \"context\" \"encore.app/hello/foo\" ) //encore:api public path=/hello/:name func World(ctx context.Context, name string) (*Response, error) { msg := foo.GenerateMessage(name) return &Response{Message: msg}, nil } type Response struct { Message string } \nhello/foo/foo.go\npackage foo import ( \"fmt\" ) func GenerateMessage(name string) string { return fmt.Sprintf(\"Hello %s!\", name) } \nOn disk it might look like this:\n/my-app ├── encore.app // ... and other top-level project files │ ├── hello // hello service (a Go package) │ ├── migrations // hello service db migrations (directory) │ │ └── 1_create_table.up.sql // hello service db migration │ ├── foo // sub-package foo (directory) │ │ └── foo.go // foo code (cannot define APIs) │ ├── hello.go // hello service code │ └── hello_test.go // tests for hello service │ └── world // world service (a Go package) └── world.go // world service code \nLarge applications with several systems\nIf you have a large application with several logical domains, each consisting of multiple services, it can be practical to separate these into distinct systems.\nSystems are not a special construct in Encore, they only help you divide your application logically around common concerns and purposes. Encore only handles services, the compiler will read your systems and extract the services of your application. As applications grow, systems help you decompose your application without requiring any complex refactoring.\nTo create systems, create a sub-directory for each system and put the relevant service packages within it. This is all you need to do, since with Encore each service consists of a Go package.\nAs an example, a company building a Trello app might divide their application into three systems: the Trello system (for the end-user facing app with boards and cards), the User system (for user and organization management), and the Premium system (for handling payments and subscriptions).\nOn disk it might look like this:\n/my-trello-clone ├── encore.app // ... and other top-level project files │ ├── trello // trello system (a directory) │ ├── board // board service (a Go package) │ │ └── board.go // board service code │ └── card // card service (a Go package) │ └── card.go // coard service code │ ├── premium // premium system (a directory) │ ├── payment // payment service (a Go package) │ │ └── payment.go // payment service code │ └── subscription // subscription service (a Go package) │ └── subscription.go // subscription service code │ └── usr // usr system (a directory) ├── org // org service (a Go package) │ └── org.go // org service code └── user // user service (a Go package) └── user.go // user service code \nThe only refactoring needed to divide an existing Encore application into systems is to move services into their respective subfolders. This is a simple way to separate the specific concerns of each system. What matters for Encore are the packages containing services, and the division in systems or subsystems will not change the endpoints or architecture of your application."
  },
  {
    "url": "https://encore.dev/docs/ts/develop/api-schemas",
    "text": "APIs in Encore for TypeScript are async functions with request and response data types.\nThese request and response data types are TypeScript interfaces, which Encore uses to encode API requests to HTTP messages.\nEncore parses the source code to understand the request and response schema of each endpoint. By default, the data is parsed as a JSON body for incoming requests, and written back as JSON responses.\nThis can be customized on a per-field basis, allowing individual fields to be parsed from query strings and HTTP headers with ease.\nFor example:\nimport { api, Header, Query } from \"encore.dev/api\"; interface Data { header: Header<\"X-Header\">; // this field will be read from the http header query: Query<string>; // this will be parsed from the '?query=...' parameter in the request url body: string; // this will be sent as part of the JSON body // These will also sent as part of the JSON body: nested: { body2: string; header2: Header<\"X-Other-Header\">; // Header has no effect inside nested fields query2: Query<string>; // Query has no effect inside nested fields }; } // A simple API endpoint that echoes the data back. export const echo = api( { method: \"POST\", path: \"/echo\" }, async (params: Data): Promise<Data> => { return params; // echo the data back }, ); \nThis API endpoint expects incoming requests to look like this:\nPOST /echo?query=hello HTTP/1.1 Content-Type: application/json X-Header: this is a header { \"body\": \"a body\", \"nested\": { \"body2\": \"nested body field\", \"header2\": \"not a header\", \"query2\": \"not a query string\" } } \nThe Encore runtime will parse this request, constructing a JavaScript object matching the TypeScript type definition for the Data type. The endpoint handler would receive this as a JavaScript object that looks like this:\n{ header: \"this is a header\", query: \"hello\", body: \"a body\", nested: { body2: \"nested body field\", header2: \"not a header\", query2: \"not a query string\" } } \nAnd when the echo endpoint returns this object back to Encore, Encore will serialize the request back to HTTP.\nFor HTTP responses the Query<string> type is considered to be part of the JSON response body, since query strings only make sense for incoming requests.\nThis data would be serialized as a HTTP response that looks like this:\nHTTP/1.1 200 OK Content-Type: application/json X-Header: this is a header { \"query\": \"hello\", \"body\": \"a body\", \"nested\": { \"body2\": \"nested body\" \"header2\": \"not a header\", \"query2\": \"not a query\" } } \nPath parameters\nPath parameters are specified by the path field in the API Options in api call. To specify a placeholder variable, use :name and add a function parameter with the same name to the function signature. Encore parses the incoming request URL and makes sure it matches the type of the parameter. The last segment of the path can be parsed as a wildcard parameter by using *name with a matching function parameter.\nEach path parameter (whether a single segment like :name or a wildcard parameter like *name) must have a matching field in the request data type.\nFor example:\n// Retrieves a blog post by its id. export const getBlogPost = api( {method: \"GET\", path: \"/blog/:id/*path\"}, async (params: {id: number; path: string}): Promise<BlogPost> { // Use id and path to query database... } ) \nHeaders are defined by setting the field type to Header<\"Name-Of-Header\">. It can be used in both request and response data types.\nIn the example below, the Language field of ListBlogPost will be fetched from the Accept-Language HTTP header.\nimport { Header } from \"encore.dev/api\"; interface ListBlogPost { language: Header<\"Accept-Language\">; // parsed from header author: string; // not a header } \nQuery parameters\nFor GET, HEAD and DELETE requests, parameters are read from the query string by default, since those HTTP methods do not support request bodies.\nFor other HTTP methods (that do support request bodies), parameters are by default read from the HTTP request body as JSON. In those cases, the Query type can be used to specify that a field should be parsed from the query string instead.\nQuery strings are not supported in HTTP responses, and are treated as being part of the HTTP response body in JSON.\nIn the example below, the limit field will be read from the limit query parameter for all HTTP methods, whereas the author field will be parsed from the query string only if the method of the request is GET, HEAD or DELETE (and otherwise from the HTTP request body as JSON).\ninterface ListBlogPost { limit: Query<number>; // always a query parameter author: string; // query if GET, HEAD or DELETE, otherwise body parameter } \nBody parameters\nEncore will default to reading request parameters from the body (as JSON) for all HTTP methods except GET, HEAD or DELETE. The name of the body parameter is the field name. Response fields will be serialized as JSON in the HTTP body unless the Header type is used to override it.\nRaw endpoints\nIn some cases you may need to fulfill an API schema that is defined by someone else, for instance when you want to accept webhooks. This often requires you to parse custom HTTP headers and do other low-level things that Encore usually lets you skip.\nFor these circumstances Encore lets you define raw endpoints. Raw endpoints operate at a lower abstraction level, giving you access to the underlying HTTP request.\nLearn more in the raw endpoints documentation."
  },
  {
    "url": "https://encore.dev/docs/how-to/change-db-schema",
    "text": "Encore database schemas are changed over time using migration files.\nEach migration file has a sequence number, and migration files are run in sequence when deploying. Encore tracks which migrations have already run and only runs new ones.\nTo change your database schema, add a new migration file using the next available migration number.\nFor example, if you have two migration files already, the next migration file should be named 3_something.up.sql where something is a short description of what the migration does.\nLook out!\nDatabase migrations are applied before the application is restarted with the new code. Always make sure the old application code works with the new database schema, so that things don't break while your new code is being rolled out.\nExample\nLet's say you have a single migration file that creates a todo_item table:\ntodo/migrations/1_create_table.up.sql\nCREATE TABLE todo_item ( id BIGSERIAL PRIMARY KEY, title TEXT NOT NULL, done BOOLEAN NOT NULL ); \nAnd now you want to add a created column to track when each todo was created. Add a new file:\ntodo/migrations/2_add_created_col.up.sql\nALTER TABLE todo_item ADD created TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(); \nThe next deploy Encore will notice the new migration file and run it, adding a new column."
  },
  {
    "url": "https://encore.dev/docs/ts/develop/app-structure",
    "text": "Encore uses a monorepo design and it's best to use one Encore app for your entire backend application. This lets Encore build an application model that spans your entire app, necessary to get the most value out of many features like distributed tracing and Encore Flow.\nIf you have a large application, see advice on how to structure an app with several systems. \nIt's simple to integrate Encore applications with pre-existing systems you might have, using APIs and built-in tools like client generation. See more on how to approach building new functionality incrementally with Encore in the migrating to Encore documentation.\nMonolith or Microservices\nEncore is not opinionated about monoliths vs. microservices. It does however let you build microservices applications with a monolith-style developer experience. For example, you automatically get IDE auto-complete when making API calls between services, along with cross-service type-safety.\nWhen creating a cloud environment on AWS/GCP, Encore enables you to configure if you want to combine multiple services into one process or keep them separate. This can be useful for improved efficiency at smaller scales, and for co-locating services for increased performance. Learn more in the environments documentation.\nCreating services\nTo create an Encore service, you create a folder and define an API in a .ts file within it.\nOn disk it might look like this:\n/my-app ├── encore.app // ... and other top-level project files ├── package.json │ ├── hello // hello service (a folder) │ ├── hello.ts // hello service code │ └── hello_test.ts // tests for hello service │ └── world // world service (a folder) └── world.ts // world service code \nStructure services using sub-modules\nWithin a service, it's possible to have multiple subdirectories. This is a good way to define components, helper functions, or other code for your functions, should you wish to do that. You can create as many subdirectories, in any kind of nested structure within your service, as you want.\nNote that currently all API endpoints must be defined in the top-level directory for the service.\nFor example, rather than define the entire logic for an endpoint in that endpoint's function, you can call functions from sub-packages and divide the logic in any way you want.\nOn disk it might look like this:\n/my-app ├── encore.app // ... and other top-level project files │ ├── hello // hello service (directory) │ ├── migrations // hello service db migrations (directory) │ │ └── 1_create_table.up.sql // hello service db migration │ ├── foo // sub-package foo (directory) │ │ └── foo.ts // foo code (cannot define APIs) │ ├── hello.ts // hello service code │ └── hello_test.ts // tests for hello service │ └── world // world service (directory) └── world.ts // world service code \nLarge applications with several systems\nIf you have a large application with several logical domains, each consisting of multiple services, it can be practical to separate these into distinct systems.\nSystems are not a special construct in Encore, they only help you divide your application logically around common concerns and purposes. Encore only handles services, the compiler will read your systems and extract the services of your application. As applications grow, systems help you decompose your application without requiring any complex refactoring.\nTo create systems, create a sub-directory for each system and put the relevant service packages within it. This is all you need to do, since with Encore each service consists of a Go package.\nAs an example, a company building a Trello app might divide their application into three systems: the Trello system (for the end-user facing app with boards and cards), the User system (for user and organization management), and the Premium system (for handling payments and subscriptions).\nOn disk it might look like this:\n/my-trello-clone ├── encore.app ├── package.json // ... and other top-level project files │ ├── trello // trello system (a directory) │ ├── board // board service (a directory) │ │ └── board.ts // board service code │ └── card // card service (a directory) │ └── card.ts // card service code │ ├── premium // premium system (a directory) │ ├── payment // payment service (a directory) │ │ └── payment.ts // payment service code │ └── subscription // subscription service (a directory) │ └── subscription.ts // subscription service code │ └── usr // usr system (a directory) ├── org // org service (a directory) │ └── org.ts // org service code └── user // user service (a directory) └── user.ts // user service code \nThe only refactoring needed to divide an existing Encore application into systems is to move services into their respective subfolders. This is a simple way to separate the specific concerns of each system. What matters for Encore are the packages containing services, and the division in systems or subsystems will not change the endpoints or architecture of your application."
  },
  {
    "url": "https://encore.dev/docs/how-to/connect-existing-db",
    "text": "Encore automatically provision the necessary infrastructure when you create a service and add a database. However, you may want to connect to an existing database for migration or prototyping purposes. It's simple to integrate your Encore app with an existing database in these cases.\nExample\nLet's say you have an external database hosted by DigitalOcean that you would like to connect to. The simplest approach is to create a dedicated package that lazily instantiates a database connection pool. We can store the password using Encore's secrets manager to make it even easier.\nThe connection string is something that looks like:\npostgresql://user:password@externaldb-do-user-1234567-0.db.ondigitalocean.com:25010/externaldb?sslmode=require \nSo we write something like:\npkg/externaldb/externaldb.go\npackage externaldb import ( \"context\" \"fmt\" \"github.com/jackc/pgx/v4/pgxpool\" \"go4.org/syncutil\" ) // Get returns a database connection pool to the external database. // It is lazily created on first use. func Get(ctx context.Context) (*pgxpool.Pool, error) { // Attempt to setup the database connection pool if it hasn't // already been successfully setup. err := once.Do(func() error { var err error pool, err = setup(ctx) return err }) return pool, err } var ( // once is like sync.Once except it re-arms itself on failure once syncutil.Once // pool is the successfully created database connection pool, // or nil when no such pool has been setup yet. pool *pgxpool.Pool ) var secrets struct { // ExternalDBPassword is the database password for authenticating // with the external database hosted on DigitalOcean. ExternalDBPassword string } // setup attempts to set up a database connection pool. func setup(ctx context.Context) (*pgxpool.Pool, error) { connString := fmt.Sprintf(\"postgresql://%s:%s@externaldb-do-user-1234567-0.db.ondigitalocean.com:25010/externaldb?sslmode=require\", \"user\", secrets.ExternalDBPassword) return pgxpool.Connect(ctx, connString) } \nBefore running, remember to use encore secrets set to store the ExternalDBPassword to use. (But don't worry, Encore will remind you if you forget.)\nOther infrastructure\nThe same pattern can easily be adapted to other infrastructure components that Encore doesn't yet provide built-in support for:\nHorizontally scalable databases like Cassandra, DynamoDB, BigTable, and so on\nDocument or graph databases like MongoDB or Neo4j\nOther cloud primitives like queues, object storage buckets, and more\nOr really any cloud services or APIs you can think of\nIn this way you can easily integrate Encore with anything you want."
  },
  {
    "url": "https://encore.dev/docs/how-to/insert-test-data-db",
    "text": "When you're developing or testing, it's often useful to seed databases with test data. This can be done is several ways depending on your use case.\nUsing go:embed\nA straightforward way to insert test data is to conditionally insert it on startup using go:embed in combination with Encore's metadata API control in which environments the data gets inserted. E.g. only in your local environment.\nExample\nCreate a file with your test data named fixtures.sql. Then, for the service where you want to insert test data, add the following to its .go file in order to run on startup.\nimport ( _ \"embed\" \"log\" \"encore.dev\" ) //go:embed fixtures.sql var fixtures string func init() { if encore.Meta().Environment.Cloud == encore.CloudLocal { if _, err := sqldb.Exec(context.Background(), fixtures); err != nil { log.Fatalln(\"unable to add fixtures:\", err) } } } \nNot included in the above example is preventing adding duplicate data. This is straightforward to do by making the fixtures idempotent, or by tracking it with a database table.\nPopulating databases in Preview Environments\nIn some cases, it can be useful to populate new Preview Environments with test data to simplify testing. \nThe best way to do this depends a bit on your use case, but a common way to do this is by using Encore's webooks functionality, which provides notifications for when a deployment is completed and includes information about the environment in question."
  },
  {
    "url": "https://encore.dev/docs/how-to/manage-db-users",
    "text": "Encore provisions your databases automatically, meaning you don't need to manually create database users. However, in some use cases you need access to the database user credentials, so Encore makes it simple to view them.\nAs an application Admin, open the Cloud Dashboard and go to the Infrastructure page for the relevant environment.\nIn the section for the relevant Database Cluster, you will find a Users sub-section which lists your database users. Click on the \"eye\" icon next to each username to decrypt the password.\nNote that databases hosted in Encore Cloud currently do not expose usernames and passwords. To connect to an Encore Cloud-hosted database, use encore db shell.\nTake care\nDo not change or remove the database users created by Encore, as this will prevent Encore from maintaining and handling connections to the databases in your application."
  },
  {
    "url": "https://encore.dev/docs/primitives/pubsub/outbox",
    "text": "One of the hardest parts of building an event-driven application is ensuring consistency between services. A common pattern is for each service to have its own database and use Pub/Sub to notify other systems of business events. Inevitably this leads to inconsistencies since the Pub/Sub publishing is not transactional with the database writes.\nWhile there are several approaches to solving this, it's important the solution doesn't add too much complexity to what is often an already complex architecture. Perhaps the best solution in this regard is the transactional outbox pattern.\nEncore provides support for the transactional outbox pattern in the x.encore.dev/infra/pubsub/outbox package.\nThe transactional outbox works by binding a Pub/Sub topic to a database transaction, translating all calls to topic.Publish into inserting a database row in an outbox table. If/when the transaction later commits, the messages are picked up by a Relay that polls the outbox table and publishes the messages to the actual Pub/Sub topic.\nPublishing messages to the outbox\nTo publish messages to the outbox, a topic must first be bound to the outbox. This is done using Pub/Sub topic references which allows you to retain complete type safety and the same interface as regular Pub/Sub topics, allowing existing code to continue to work without changes.\nPlease note\nIn regular (non-outbox) usage the message id returned by topic.Publish is the same as the message id the subscriber receives when processing the message. With the outbox, this message id is not available until the transaction commits, so topic.Publish returns an id referencing the outbox row instead.\nThe topic binding supports pluggable storage backends, enabling use of the outbox pattern with any transactional storage backend. Implementation are provided out-of-the-box for use with Encore's encore.dev/storage/sqldb package, as well as the standard library database/sql and github.com/jackc/pgx/v5 drivers, but it's easy to write your own for other use cases. See the Go package reference for more information.\nFor example, to use a transactional outbox to notify subscribers when a user is created:\noutbox.go\ndb_migration.sql\n// Create a SignupsTopic somehow. var SignupsTopic = pubsub.NewTopic[*SignupEvent](/* ... */) // Create a topic ref with publisher permissions. ref := pubsub.TopicRef[pubsub.Publisher[*SignupEvent]](SignupsTopic) // Bind it to the transactional outbox import \"x.encore.dev/infra/pubsub/outbox\" var tx *sqldb.Tx // somehow get a transaction ref = outbox.Bind(ref, outbox.TxPersister(tx)) // Calls to ref.Publish() will now insert a row in the outbox table. \nOnce the transaction commits any published messages via ref above will be stored in the outbox table.\nConsuming messages from the outbox\nOnce committed, the messages are ready to be picked up and published to the actual Pub/Sub topic.\nThat is done via the Relay. The relay continuously polls the outbox table and publishes any new messages to the actual Pub/Sub topic.\nThe relay supports pluggable storage backends, enabling use of the outbox pattern with any transactional storage backend. An implementation is provided out-of-the-box that uses Encore's built-in SQL database support, but it's easy to write your own for other databases.\nThe topics to poll must be registered with the relay, typically during service initialization. For example:\npackage user import ( \"context\" \"encore.dev/pubsub\" \"encore.dev/storage/sqldb\" \"x.encore.dev/infra/pubsub/outbox\" ) type Service struct { signupsRef pubsub.Publisher[*SignupEvent] } // db is the database the outbox table is stored in var db = sqldb.NewDatabase(...) // Create the SignupsTopic somehow. var SignupsTopic = pubsub.NewTopic[*SignupEvent](/* ... */) func initService() (*Service, error) { // Initialize the relay to poll from our database. relay := outbox.NewRelay(outbox.SQLDBStore(db)) // Register the SignupsTopic to be polled. signupsRef := pubsub.TopicRef[pubsub.Publisher[*SignupEvent]](SignupsTopic) outbox.RegisterTopic(relay, signupsRef) // Start polling. go relay.PollForMessage(context.Background(), -1) return &Service{signupsRef: signupsRef}, nil }"
  }
]
